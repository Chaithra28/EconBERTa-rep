{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f2e3a19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f2e3a19",
    "outputId": "8f636dfd-7040-479f-8ded-692a99f51824",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/apathak2/.local/lib/python3.9/site-packages (4.39.3)\n",
      "Requirement already satisfied: torch in /home/apathak2/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: tokenizers in /home/apathak2/.local/lib/python3.9/site-packages (0.15.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/apathak2/.local/lib/python3.9/site-packages (0.22.2)\n",
      "Requirement already satisfied: pytorch-crf in /home/apathak2/.local/lib/python3.9/site-packages (0.7.2)\n",
      "Requirement already satisfied: filelock in /home/apathak2/.local/lib/python3.9/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in /home/apathak2/.local/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from torch) (2.8.5)\n",
      "Requirement already satisfied: jinja2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: fsspec in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/apathak2/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers[torch]) (0.29.2)\n",
      "Requirement already satisfied: psutil in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/apathak2/.local/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/apathak2/.local/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: protobuf==3.20.3 in /home/apathak2/.local/lib/python3.9/site-packages (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers torch transformers[torch] tokenizers huggingface_hub pytorch-crf\n",
    "!pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4734ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "2e4734ec",
    "outputId": "7ce0f168-9f2b-459d-c287-3f661cddb410"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0bc84b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "9a0bc84b",
    "outputId": "feb3c753-6d26-4c70-c52b-7f2d70048f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: NVIDIA A100-SXM4-80GB MIG 3g.40gb, n_gpu: 1\n"
     ]
    }
   ],
   "source": [
    "device_name = torch.cuda.get_device_name()\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de59fcff",
   "metadata": {
    "id": "de59fcff"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aGpCRa-oQq0K",
   "metadata": {
    "id": "aGpCRa-oQq0K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_conll(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    current_sentence = []\n",
    "    current_labels = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                columns = line.split()\n",
    "                word, label = columns[0], columns[-1]\n",
    "                current_sentence.append(word)\n",
    "                current_labels.append(label)\n",
    "                \n",
    "                # Check if the current word is a sentence boundary\n",
    "                if word == '.' and label == 'O':\n",
    "                    sentences.append(' '.join(current_sentence))\n",
    "                    labels.append(current_labels)\n",
    "                    current_sentence = []\n",
    "                    current_labels = []\n",
    "\n",
    "    # Create a DataFrame from the accumulated sentences and labels\n",
    "    df = pd.DataFrame({\n",
    "        'sentences': sentences,\n",
    "        'labels': labels\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "BmsqGYy2TcHS",
   "metadata": {
    "id": "BmsqGYy2TcHS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "max_length=128\n",
    "\n",
    "def tokenize_and_format(sentences, tokenizer, max_length=max_length):\n",
    "    \"\"\"\n",
    "    Tokenizes sentences and returns formatted input IDs and attention masks.\n",
    "    \n",
    "    Parameters:\n",
    "    sentences: List of sentence strings to be tokenized.\n",
    "    tokenizer: Tokenizer instance used for tokenizing the sentences.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # Encode each sentence\n",
    "    for sentence in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=max_length,  # Adjust based on your model's maximum input length\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Store the input ID and the attention mask of this sentence\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert lists of tensors to single tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pjdFP9RFXkCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjdFP9RFXkCq",
    "outputId": "51858648-a4d7-47c0-b5ac-43272e38a953"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbekal/.local/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'worldbank/econberta'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wXPExdKtEXHh",
   "metadata": {
    "id": "wXPExdKtEXHh"
   },
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'O': 0,\n",
    "    'B-intervention': 1,\n",
    "    'I-intervention': 2,\n",
    "    'B-outcome': 3,\n",
    "    'I-outcome': 4,\n",
    "    'B-population': 5,\n",
    "    'I-population': 6,\n",
    "    'B-effect_size': 7,\n",
    "    'I-effect_size': 8,\n",
    "    'B-coreference': 9,\n",
    "    'I-coreference': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa54038d-da7f-4fd3-9ad6-029a7c560f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_label_dict = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "A49f-HWiNCCm",
   "metadata": {
    "id": "A49f-HWiNCCm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_dataset(df, tokenizer, label_dict, max_length=max_length):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame to return a dataset suitable for training/testing an NER model.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame containing 'Tokens' and 'Labels' columns.\n",
    "    tokenizer: Tokenizer to use for encoding the sentences.\n",
    "    label_dict: Dictionary mapping label names to indices.\n",
    "    max_length: Maximum length of the tokenized input.\n",
    "    \"\"\"\n",
    "    sentences = df.sentences.values\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    input_ids, attention_masks = tokenize_and_format(sentences, tokenizer, max_length)\n",
    "\n",
    "    # Prepare labels\n",
    "    label_list = []\n",
    "    for labels in df.labels.values:\n",
    "        # Initialize a list to hold the encoded labels for each sentence\n",
    "        encoded_labels = [label_dict[label] for label in labels]\n",
    "        \n",
    "        # Truncate or pad the labels to match the max_length\n",
    "        encoded_labels = encoded_labels[:max_length]  # Truncate if needed\n",
    "        encoded_labels += [label_dict['O']] * (max_length - len(encoded_labels))  # Pad with 'O' if needed\n",
    "        \n",
    "        label_list.append(encoded_labels)\n",
    "\n",
    "    # Convert label_list to a tensor\n",
    "    labels = torch.tensor(label_list, dtype=torch.long)\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = [(input_ids[i], attention_masks[i], labels[i]) for i in range(len(df))]\n",
    "\n",
    "    return dataset, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Y73hwpVwOvCi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y73hwpVwOvCi",
    "outputId": "3042abbf-6575-47cd-e570-a94f3f930ea7"
   },
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "train_df = read_conll('data/econ_ie/train.conll')\n",
    "val_df = read_conll('data/econ_ie/dev.conll')\n",
    "test_df = read_conll('data/econ_ie/test.conll')\n",
    "\n",
    "train_set, train_sentences = get_dataset(train_df, tokenizer, label_dict)\n",
    "val_set, val_sentences = get_dataset(val_df, tokenizer, label_dict)\n",
    "test_set, test_sentences = get_dataset(test_df, tokenizer, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "43ff7208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4798\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "78530c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "train_typo_df = train_df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e2980740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def introduce_typos(text, typo_rate=0.1):\n",
    "    \"\"\"\n",
    "    Introduce 1 or 2 simple typos into the given text.\n",
    "    Typos can be a character insertion or substitution.\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    num_typos = random.randint(1, 2)  # Choose to introduce either 1 or 2 typos\n",
    "    \n",
    "    for _ in range(num_typos):\n",
    "        typo_type = random.choice(['insert', 'substitute'])\n",
    "        pos = random.randint(0, len(text) - 1)\n",
    "        \n",
    "        if typo_type == 'insert':\n",
    "            char_to_add = random.choice(letters)\n",
    "            text = text[:pos] + char_to_add + text[pos:]\n",
    "        elif typo_type == 'substitute' and len(text) > 0:\n",
    "            text = text[:pos] + random.choice(letters) + text[pos + 1:]\n",
    "    \n",
    "    return ''.join(text)\n",
    "\n",
    "# Apply the typo function to the 'sentence' column\n",
    "train_typo_df['perturbated_sentence'] = train_typo_df['sentences'].apply(introduce_typos)\n",
    "\n",
    "# Create a new DataFrame with perturbated sentences and original labels\n",
    "new_train_typos_df = train_typo_df[['perturbated_sentence', 'labels']].copy()\n",
    "\n",
    "# Display the new DataFrame\n",
    "new_train_typos_df\n",
    "\n",
    "new_train_typos_df.rename(columns={'perturbated_sentence': 'sentences'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c301426b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>By integrating the process of abolishing the a...</td>\n",
       "      <td>[O, O, O, O, O, B-intervention, I-intervention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Estimated mean child dietary diversxity was si...</td>\n",
       "      <td>[O, B-outcome, I-outcome, I-outcome, I-outcome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>Interventions in rural development projects va...</td>\n",
       "      <td>[B-coreference, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Conclusions These resulgts suggest that permet...</td>\n",
       "      <td>[O, O, O, O, O, B-intervention, I-intervention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>Methods : This randomized clinical trial enrol...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-population, I-popul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>The data were analysed using sescriptive stati...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>Results show that the increase in parking pric...</td>\n",
       "      <td>[O, O, O, O, B-intervention, I-intervention, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>We observed a 41 % reduction in diarrheal morb...</td>\n",
       "      <td>[O, O, O, B-effect_size, I-effect_size, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>These findings demonstrate that a simple and i...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-coreference, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>We find no evidence of transformative impacts ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-coreference, O, O, B-core...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentences  \\\n",
       "561   By integrating the process of abolishing the a...   \n",
       "893   Estimated mean child dietary diversxity was si...   \n",
       "1684  Interventions in rural development projects va...   \n",
       "705   Conclusions These resulgts suggest that permet...   \n",
       "1873  Methods : This randomized clinical trial enrol...   \n",
       "...                                                 ...   \n",
       "2822  The data were analysed using sescriptive stati...   \n",
       "2473  Results show that the increase in parking pric...   \n",
       "4534  We observed a 41 % reduction in diarrheal morb...   \n",
       "3473  These findings demonstrate that a simple and i...   \n",
       "4407  We find no evidence of transformative impacts ...   \n",
       "\n",
       "                                                 labels  \n",
       "561   [O, O, O, O, O, B-intervention, I-intervention...  \n",
       "893   [O, B-outcome, I-outcome, I-outcome, I-outcome...  \n",
       "1684  [B-coreference, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "705   [O, O, O, O, O, B-intervention, I-intervention...  \n",
       "1873  [O, O, O, O, O, O, O, O, B-population, I-popul...  \n",
       "...                                                 ...  \n",
       "2822  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2473  [O, O, O, O, B-intervention, I-intervention, I...  \n",
       "4534  [O, O, O, B-effect_size, I-effect_size, O, O, ...  \n",
       "3473  [O, O, O, O, O, O, O, O, B-coreference, O, O, ...  \n",
       "4407  [O, O, O, O, O, O, B-coreference, O, O, B-core...  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_typos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a2fa5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_sentences = get_dataset(new_train_df, tokenizer, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "01bb6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "val_typo_df = val_df.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4087df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def introduce_typos(text, typo_rate=0.1):\n",
    "    \"\"\"\n",
    "    Introduce 1 or 2 simple typos into the given text.\n",
    "    Typos can be a character insertion or substitution.\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    num_typos = random.randint(1, 2)  # Choose to introduce either 1 or 2 typos\n",
    "    \n",
    "    for _ in range(num_typos):\n",
    "        typo_type = random.choice(['insert', 'substitute'])\n",
    "        pos = random.randint(0, len(text) - 1)\n",
    "        \n",
    "        if typo_type == 'insert':\n",
    "            char_to_add = random.choice(letters)\n",
    "            text = text[:pos] + char_to_add + text[pos:]\n",
    "        elif typo_type == 'substitute' and len(text) > 0:\n",
    "            text = text[:pos] + random.choice(letters) + text[pos + 1:]\n",
    "    \n",
    "    return ''.join(text)\n",
    "\n",
    "# Apply the typo function to the 'sentence' column\n",
    "val_typo_df['perturbated_sentence'] = val_typo_df['sentences'].apply(introduce_typos)\n",
    "\n",
    "# Create a new DataFrame with perturbated sentences and original labels\n",
    "new_val_typos_df = val_typo_df[['perturbated_sentence', 'labels']].copy()\n",
    "\n",
    "# Display the new DataFrame\n",
    "new_val_typos_df\n",
    "\n",
    "new_val_typos_df.rename(columns={'perturbated_sentence': 'sentences'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e5db901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_df = pd.concat([val_df, new_val_typos_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4ffe5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set, val_sentences = get_dataset(new_val_df, tokenizer, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "97333c9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "df = test_df.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "befe17d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set, df_sentences = get_dataset(df, tokenizer, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6da7d3f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perturbated_sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>In particular , relatively few studies have be...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>These findings suggest that risk-targeted paym...</td>\n",
       "      <td>[O, O, O, O, B-intervention, I-intervention, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>The basic idea is that while both constrained ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-population, I-populati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>All interventions significantly improved the x...</td>\n",
       "      <td>[O, O, O, O, O, B-outcome, I-outcome, I-outcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Here , we evaluated the short - , medium - and...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-core...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Data were collzcted using a well-structured qu...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>Methods : The procedure wts designed as a sing...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>Moreover , little is known about how the desig...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-intervention,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A cost-effectiveness analysis of the results v...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-intervention, I-int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>We find no evidence of crime displacement but ...</td>\n",
       "      <td>[O, O, O, O, O, B-outcome, I-outcome, O, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   perturbated_sentence  \\\n",
       "567   In particular , relatively few studies have be...   \n",
       "1326  These findings suggest that risk-targeted paym...   \n",
       "1061  The basic idea is that while both constrained ...   \n",
       "115   All interventions significantly improved the x...   \n",
       "453   Here , we evaluated the short - , medium - and...   \n",
       "...                                                 ...   \n",
       "300   Data were collzcted using a well-structured qu...   \n",
       "677   Methods : The procedure wts designed as a sing...   \n",
       "707   Moreover , little is known about how the desig...   \n",
       "30    A cost-effectiveness analysis of the results v...   \n",
       "1586  We find no evidence of crime displacement but ...   \n",
       "\n",
       "                                                 labels  \n",
       "567   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1326  [O, O, O, O, B-intervention, I-intervention, O...  \n",
       "1061  [O, O, O, O, O, O, O, B-population, I-populati...  \n",
       "115   [O, O, O, O, O, B-outcome, I-outcome, I-outcom...  \n",
       "453   [O, O, O, O, O, O, O, O, O, O, O, O, O, B-core...  \n",
       "...                                                 ...  \n",
       "300    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "677       [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "707   [O, O, O, O, O, O, O, O, O, O, B-intervention,...  \n",
       "30    [O, O, O, O, O, O, O, O, B-intervention, I-int...  \n",
       "1586  [O, O, O, O, O, B-outcome, I-outcome, O, O, O,...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def introduce_typos(text, typo_rate=0.1):\n",
    "    \"\"\"\n",
    "    Introduce 1 or 2 simple typos into the given text.\n",
    "    Typos can be a character insertion or substitution.\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    num_typos = random.randint(1, 2)  # Choose to introduce either 1 or 2 typos\n",
    "    \n",
    "    for _ in range(num_typos):\n",
    "        typo_type = random.choice(['insert', 'substitute'])\n",
    "        pos = random.randint(0, len(text) - 1)\n",
    "        \n",
    "        if typo_type == 'insert':\n",
    "            char_to_add = random.choice(letters)\n",
    "            text = text[:pos] + char_to_add + text[pos:]\n",
    "        elif typo_type == 'substitute' and len(text) > 0:\n",
    "            text = text[:pos] + random.choice(letters) + text[pos + 1:]\n",
    "    \n",
    "    return ''.join(text)\n",
    "\n",
    "# Apply the typo function to the 'sentence' column\n",
    "df['perturbated_sentence'] = df['sentences'].apply(introduce_typos)\n",
    "\n",
    "# Create a new DataFrame with perturbated sentences and original labels\n",
    "new_df = df[['perturbated_sentence', 'labels']].copy()\n",
    "\n",
    "# Display the new DataFrame\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f7a828bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rename(columns={'perturbated_sentence': 'sentences'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "78b20527",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_typos_df = pd.concat([test_df, new_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e4d9af90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_typos_set, test_typos_sentences = get_dataset(test_typos_df, tokenizer, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e9f3efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "typos_set, typos_sentences = get_dataset(new_df, tokenizer, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1a185462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    1,   267,  1070,   366,  2936,   477,  1703,   286,   331,   619,\n",
       "           277,   262, 13269,  4500,  1204,  3727,   308,  1382,   372,  1431,\n",
       "           366,  2128,  1479,  1519,   292,  4856,   272,   262,  1382,   265,\n",
       "           614, 13624, 25084,   295,  4388,  1579,   262,  7226,   289, 77580,\n",
       "         36518,   272,  2836,   349,   366,  4395,  1601,   264, 77580, 36518,\n",
       "          1137,   333, 14507, 14471,   323,     2,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typos_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e4a2e9-180d-464c-8dcf-b868546574b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    1,   287,   376,  1263,  1770,   268, 11254,   264,  5685, 17736,\n",
       "           267,  4770,  3791,   263,  3922,   323,     2,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 1, 0, 0, 3, 4, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "XghB1AiHR2Aj",
   "metadata": {
    "id": "XghB1AiHR2Aj"
   },
   "outputs": [],
   "source": [
    "# Set the hyperparameters according to Table 8\n",
    "dropout = 0.2\n",
    "learning_rates = [5e-5, 6e-5, 7e-5]  # Perform hyperparameter search\n",
    "batch_size = 12\n",
    "gradient_accumulation_steps = 4\n",
    "weight_decay = 0\n",
    "max_epochs = 10\n",
    "lr_decay = \"slanted_triangular\"\n",
    "fraction_of_steps = 0.06\n",
    "adam_epsilon = 1e-8\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7129234f-176a-482a-9b8e-06b3a8997056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entities(labels, tokens):\n",
    "    \"\"\"\n",
    "    Extract entities from token-label pairs.\n",
    "    \n",
    "    Args:\n",
    "    labels (list of int): List of label indices corresponding to each token.\n",
    "    tokens (list of str): List of tokens corresponding to each label index.\n",
    "    \n",
    "    Returns:\n",
    "    list of tuples: Each tuple represents an entity with (entity_type, start_index, end_index, entity_text).\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "        if label.startswith(\"B-\"):\n",
    "            if current_entity:\n",
    "                entities.append(current_entity)\n",
    "            entity_type = label.split(\"-\")[1]\n",
    "            current_entity = (entity_type, i, i, token)\n",
    "        elif label.startswith(\"I-\") and current_entity and label.split(\"-\")[1] == current_entity[0]:\n",
    "            current_entity = (current_entity[0], current_entity[1], i, current_entity[3] + \" \" + token)\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = None\n",
    "\n",
    "    if current_entity:\n",
    "        entities.append(current_entity)\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a900c6ef-2a3d-4e2d-8663-2f2228506f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entity_level_metrics(true_entities, pred_entities):\n",
    "    metrics = {\"EM\": 0, \"EB\": 0, \"PM\": 0, \"PB\": 0, \"ML\": 0, \"FA\": 0}\n",
    "    true_matched = set()\n",
    "    pred_matched = set()\n",
    "\n",
    "    # Check for exact and partial matches\n",
    "    for i, true_entity in enumerate(true_entities):\n",
    "        for j, pred_entity in enumerate(pred_entities):\n",
    "            if j in pred_matched:\n",
    "                continue\n",
    "            if true_entity == pred_entity:\n",
    "                metrics[\"EM\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "            elif true_entity[0] == pred_entity[0] and is_overlapping((true_entity[1], true_entity[2]), (pred_entity[1], pred_entity[2])):\n",
    "                if true_entity[1] == pred_entity[1] and true_entity[2] == pred_entity[2]:\n",
    "                    metrics[\"EB\"] += 1\n",
    "                else:\n",
    "                    metrics[\"PM\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "            elif is_overlapping((true_entity[1], true_entity[2]), (pred_entity[1], pred_entity[2])):\n",
    "                metrics[\"PB\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "\n",
    "    # Check for missed labels (entities in true but not in pred)\n",
    "    for i, true_entity in enumerate(true_entities):\n",
    "        if i not in true_matched:\n",
    "            metrics[\"ML\"] += 1\n",
    "\n",
    "    # Check for false alarms (entities in pred but not in true)\n",
    "    for j, pred_entity in enumerate(pred_entities):\n",
    "        if j not in pred_matched:\n",
    "            metrics[\"FA\"] += 1\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "421e8df6-4a33-4b28-8316-d5f5674575ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(span1, span2):\n",
    "    \"\"\"\n",
    "    Check if two spans overlap.\n",
    "    Args:\n",
    "    span1, span2 (tuple): (start_index, end_index) of the span.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if spans overlap, False otherwise.\n",
    "    \"\"\"\n",
    "    assert len(span1) == 2 and len(span2) == 2, \"Each span must be a tuple of two elements (start_index, end_index)\"\n",
    "    start1, end1 = span1\n",
    "    start2, end2 = span2\n",
    "    return max(start1, start2) <= min(end1, end2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "882fb716-ce62-4e55-be8f-a7c6d6b9bbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-intervention': 1, 'I-intervention': 2, 'B-outcome': 3, 'I-outcome': 4, 'B-population': 5, 'I-population': 6, 'B-effect_size': 7, 'I-effect_size': 8, 'B-coreference': 9, 'I-coreference': 10}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "90a7c0d6-e0d3-465f-8792-8cb1bb5b0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def analyze_generalization(model, data, tokenizer, train_words):\n",
    "    grouped_entities = defaultdict(lambda: ([], []))  # {group_name: (true_entities, pred_entities)}        \n",
    "    groups=[]\n",
    "    mtrcs=[]\n",
    "\n",
    "    for i, (input_ids, attention_mask, label_tensor) in enumerate(data):\n",
    "        input_ids = input_ids.unsqueeze(0).to(device)\n",
    "        attention_mask = attention_mask.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Call model without labels to get the decoded labels\n",
    "        with torch.no_grad():\n",
    "            decoded_labels = model(input_ids, attention_mask=attention_mask)[\"decoded\"][0]\n",
    "            # No need to use argmax since CRF.decode returns the most likely tag sequence\n",
    "        \n",
    "        # Convert the decoded labels to label names using label_dict\n",
    "        pred_labels = [reverse_label_dict.get(label) for label in decoded_labels]\n",
    "\n",
    "        # Convert input_ids to tokens\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist(), skip_special_tokens=True)\n",
    "\n",
    "        # Assuming true_labels are provided in a similar structure\n",
    "        true_labels = [reverse_label_dict.get(l.item()) for l in label_tensor]\n",
    "        \n",
    "        # Preprocess entities for true and predicted labels\n",
    "        true_entities = preprocess_entities(true_labels, tokens)\n",
    "        pred_entities = preprocess_entities(pred_labels, tokens)\n",
    "        \n",
    "        for true_entity, pred_entity in zip(true_entities, pred_entities):\n",
    "            length = true_entity[2] - true_entity[1]\n",
    "\n",
    "            seen = any(word in train_words for word in true_entity[3].split())  # Check if any word in entity text was seen in training\n",
    "\n",
    "            group_name = f\"Length {length} - {'Seen' if seen else 'Unseen'}\"\n",
    "            grouped_entities[group_name][0].append(true_entity)\n",
    "            grouped_entities[group_name][1].append(pred_entity)\n",
    "    \n",
    "    for group_name, group_data in grouped_entities.items():\n",
    "        group_true_entities, group_pred_entities = group_data\n",
    "        metrics = compute_entity_level_metrics(group_true_entities, group_pred_entities)\n",
    "        print(f\"Group: {group_name}, Metrics: {metrics}\")\n",
    "        groups.append(group_name)\n",
    "        mtrcs.append(metrics)\n",
    "        \n",
    "    return groups, mtrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "Fsd5u-jsp_N5",
   "metadata": {
    "id": "Fsd5u-jsp_N5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_validation_performance(val_set, model, device, label_dict, batch_size):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_loss = 0\n",
    "    all_pred_labels = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    num_batches = int(len(val_set) / batch_size) + (1 if len(val_set) % batch_size != 0 else 0)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        end_index = min(batch_size * (i + 1), len(val_set))\n",
    "        batch = val_set[i * batch_size:end_index]\n",
    "\n",
    "        if len(batch) == 0:\n",
    "            continue\n",
    "\n",
    "        input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "        input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "        label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = input_id_tensors.to(device)\n",
    "        b_input_mask = input_mask_tensors.to(device)\n",
    "        b_labels = label_tensors.to(device)\n",
    "        b_labels = b_labels.long()\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            logits = outputs[\"logits\"]\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Get the predicted labels\n",
    "            pred_labels = np.argmax(logits, axis=2).flatten()\n",
    "            true_labels = label_ids.flatten()\n",
    "\n",
    "            # Convert labels to their original names\n",
    "            pred_labels = [reverse_label_dict.get(label) for label in pred_labels]\n",
    "            true_labels = [reverse_label_dict.get(label) for label in true_labels]\n",
    "\n",
    "            # Filter out special tokens ('O' label is used for non-entity and special tokens)\n",
    "            filtered_pred_labels = [pred for pred, true in zip(pred_labels, true_labels) if true != 'O']\n",
    "            filtered_true_labels = [true for true in true_labels if true != 'O']\n",
    "            \n",
    "            # After filtering out special tokens\n",
    "            if not filtered_pred_labels or not filtered_true_labels:\n",
    "                print(\"Warning: No non-'O' labels found in this batch.\")\n",
    "            else:\n",
    "                all_pred_labels.extend(filtered_pred_labels)\n",
    "                all_true_labels.extend(filtered_true_labels)\n",
    "            \n",
    "    # After processing all batches, check if we have any labels to report on\n",
    "    if not all_true_labels or not all_pred_labels:\n",
    "        print(\"Error: No non-'O' labels found in the entire validation set.\")\n",
    "        default_labels = [list(label_dict.values())[0]]  # Use the first label as a placeholder\n",
    "        report = classification_report(default_labels, default_labels, digits=4, zero_division=0)\n",
    "    else:\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        report = classification_report(all_true_labels, all_pred_labels, digits=4, zero_division=0)\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ab0efc37-4ac5-41ee-81f5-66a99e012c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "from transformers import AutoModel\n",
    "\n",
    "class CRFTagger(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        # Mask should be of type 'bool' in newer PyTorch versions\n",
    "        mask = attention_mask.type(torch.bool) if hasattr(torch, 'bool') else attention_mask.byte()\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = -self.crf(logits, labels, mask=mask, reduction='mean')\n",
    "            return {'loss': loss, 'logits': logits, 'decoded': self.crf.decode(logits, mask=mask)}\n",
    "        else:\n",
    "            decoded_labels = self.crf.decode(logits, mask=mask)\n",
    "            return {'decoded': decoded_labels, 'logits': logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eCm6d0FKqFSW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "eCm6d0FKqFSW",
    "outputId": "7a07ee72-afe7-453a-ba34-ef75a74a4b8c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRFTagger(\n",
       "  (bert): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  (crf): CRF(num_tags=11)\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = CRFTagger(model_name, len(label_dict))\n",
    "model.dropout = torch.nn.Dropout(dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f41a6c0c-b1e6-4ff9-ab65-686e985a6460",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate: 7e-05\n",
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "Total loss: 20006.89262008667\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.0000    0.0000    0.0000       285\n",
      " B-effect_size     0.0000    0.0000    0.0000       158\n",
      "B-intervention     0.0000    0.0000    0.0000       796\n",
      "     B-outcome     0.0000    0.0000    0.0000      1169\n",
      "  B-population     0.0000    0.0000    0.0000       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.0000    0.0000    0.0000       305\n",
      "I-intervention     0.7060    0.3227    0.4429      1816\n",
      "     I-outcome     0.5833    0.0246    0.0473      1988\n",
      "  I-population     0.0000    0.0000    0.0000       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.0803      7906\n",
      "     macro avg     0.1172    0.0316    0.0446      7906\n",
      "  weighted avg     0.3089    0.0803    0.1136      7906\n",
      "\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 1, 'ML': 0, 'FA': 0}\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "Total loss: 10809.218560218811\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8000    0.1684    0.2783       285\n",
      " B-effect_size     0.0000    0.0000    0.0000       158\n",
      "B-intervention     0.7625    0.3266    0.4573       796\n",
      "     B-outcome     0.6978    0.1343    0.2253      1169\n",
      "  B-population     0.7470    0.0900    0.1606       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.0000    0.0000    0.0000       305\n",
      "I-intervention     0.7687    0.5710    0.6553      1816\n",
      "     I-outcome     0.7564    0.2077    0.3260      1988\n",
      "  I-population     0.7953    0.2919    0.4271       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.2756      7906\n",
      "     macro avg     0.4843    0.1627    0.2300      7906\n",
      "  weighted avg     0.7103    0.2756    0.3732      7906\n",
      "\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 12, 'EB': 42, 'PM': 21, 'PB': 186, 'ML': 53, 'FA': 53}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 5, 'EB': 4, 'PM': 42, 'PB': 61, 'ML': 7, 'FA': 7}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 8, 'EB': 1, 'PM': 34, 'PB': 12, 'ML': 5, 'FA': 5}\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 24, 'EB': 11, 'PM': 107, 'PB': 106, 'ML': 18, 'FA': 18}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 14, 'PB': 6, 'ML': 5, 'FA': 5}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 23, 'PB': 12, 'ML': 3, 'FA': 3}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 13, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 9, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 2, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 1, 'ML': 2, 'FA': 2}\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "Total loss: 9426.938446044922\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8707    0.3544    0.5037       285\n",
      " B-effect_size     0.0000    0.0000    0.0000       158\n",
      "B-intervention     0.7995    0.3706    0.5064       796\n",
      "     B-outcome     0.6802    0.3293    0.4438      1169\n",
      "  B-population     0.8056    0.2525    0.3845       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.0000    0.0000    0.0000       305\n",
      "I-intervention     0.7927    0.5771    0.6679      1816\n",
      "     I-outcome     0.7257    0.6162    0.6665      1988\n",
      "  I-population     0.7584    0.4899    0.5953       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.4512      7906\n",
      "     macro avg     0.4939    0.2718    0.3426      7906\n",
      "  weighted avg     0.7136    0.4512    0.5414      7906\n",
      "\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 34, 'EB': 30, 'PM': 186, 'PB': 257, 'ML': 27, 'FA': 27}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 53, 'EB': 84, 'PM': 59, 'PB': 429, 'ML': 40, 'FA': 40}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 18, 'PB': 15, 'ML': 3, 'FA': 3}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 10, 'EB': 3, 'PM': 78, 'PB': 86, 'ML': 8, 'FA': 8}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 9, 'EB': 2, 'PM': 40, 'PB': 52, 'ML': 9, 'FA': 9}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 6, 'PB': 11, 'ML': 3, 'FA': 3}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 23, 'PB': 15, 'ML': 4, 'FA': 4}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 4, 'EB': 1, 'PM': 34, 'PB': 23, 'ML': 7, 'FA': 7}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 4, 'ML': 2, 'FA': 2}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 6, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 5, 'PB': 6, 'ML': 2, 'FA': 2}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 24 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "Total loss: 8712.99832868576\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8594    0.3860    0.5327       285\n",
      " B-effect_size     0.6744    0.1835    0.2886       158\n",
      "B-intervention     0.8253    0.3857    0.5257       796\n",
      "     B-outcome     0.6783    0.4636    0.5508      1169\n",
      "  B-population     0.7403    0.3890    0.5100       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.8095    0.1672    0.2772       305\n",
      "I-intervention     0.8171    0.5804    0.6787      1816\n",
      "     I-outcome     0.7149    0.7213    0.7181      1988\n",
      "  I-population     0.8190    0.5231    0.6384       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5258      7906\n",
      "     macro avg     0.6307    0.3454    0.4291      7906\n",
      "  weighted avg     0.7627    0.5258    0.6068      7906\n",
      "\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 64, 'EB': 27, 'PM': 244, 'PB': 346, 'ML': 19, 'FA': 19}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 20, 'EB': 4, 'PM': 88, 'PB': 120, 'ML': 12, 'FA': 12}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 78, 'EB': 111, 'PM': 76, 'PB': 509, 'ML': 59, 'FA': 59}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 17, 'PB': 24, 'ML': 4, 'FA': 4}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 5, 'EB': 2, 'PM': 71, 'PB': 69, 'ML': 8, 'FA': 8}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 4, 'PB': 18, 'ML': 4, 'FA': 4}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 25, 'PB': 30, 'ML': 4, 'FA': 4}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 4, 'EB': 0, 'PM': 46, 'PB': 53, 'ML': 4, 'FA': 4}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 2, 'ML': 3, 'FA': 3}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 5, 'PB': 7, 'ML': 1, 'FA': 1}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 1, 'ML': 2, 'FA': 2}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 5, 'PB': 0, 'ML': 3, 'FA': 3}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 1, 'ML': 1, 'FA': 1}\n",
      "Group: Length 24 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 1, 'ML': 2, 'FA': 2}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 1, 'ML': 0, 'FA': 0}\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "Total loss: 8011.899600505829\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8794    0.4351    0.5822       285\n",
      " B-effect_size     0.7917    0.1203    0.2088       158\n",
      "B-intervention     0.8599    0.3932    0.5397       796\n",
      "     B-outcome     0.8295    0.3747    0.5162      1169\n",
      "  B-population     0.8494    0.3846    0.5295       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.7955    0.1148    0.2006       305\n",
      "I-intervention     0.8137    0.5942    0.6868      1816\n",
      "     I-outcome     0.8006    0.5755    0.6696      1988\n",
      "  I-population     0.7773    0.4942    0.6042       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.4755      7906\n",
      "     macro avg     0.6724    0.3169    0.4125      7906\n",
      "  weighted avg     0.8177    0.4755    0.5887      7906\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Length 1 - Unseen, Metrics: {'EM': 70, 'EB': 26, 'PM': 146, 'PB': 265, 'ML': 14, 'FA': 14}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 67, 'EB': 108, 'PM': 40, 'PB': 402, 'ML': 33, 'FA': 33}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 13, 'PB': 14, 'ML': 3, 'FA': 3}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 20, 'EB': 5, 'PM': 77, 'PB': 78, 'ML': 7, 'FA': 7}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 13, 'EB': 1, 'PM': 39, 'PB': 54, 'ML': 6, 'FA': 6}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 8, 'PB': 13, 'ML': 3, 'FA': 3}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 3, 'EB': 1, 'PM': 21, 'PB': 19, 'ML': 3, 'FA': 3}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 8, 'EB': 1, 'PM': 32, 'PB': 30, 'ML': 3, 'FA': 3}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 1, 'PB': 5, 'ML': 2, 'FA': 2}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 7, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 4, 'PB': 4, 'ML': 1, 'FA': 1}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 2, 'FA': 2}\n",
      "Group: Length 24 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 1, 'ML': 0, 'FA': 0}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 1, 'ML': 0, 'FA': 0}\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "Total loss: 7384.514130115509\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8699    0.4456    0.5893       285\n",
      " B-effect_size     0.7941    0.1709    0.2812       158\n",
      "B-intervention     0.8149    0.5088    0.6265       796\n",
      "     B-outcome     0.8031    0.4919    0.6101      1169\n",
      "  B-population     0.8248    0.4920    0.6164       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.7742    0.3148    0.4476       305\n",
      "I-intervention     0.8522    0.6635    0.7461      1816\n",
      "     I-outcome     0.8093    0.6640    0.7295      1988\n",
      "  I-population     0.8240    0.6358    0.7178       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5735      7906\n",
      "     macro avg     0.6697    0.3988    0.4877      7906\n",
      "  weighted avg     0.8211    0.5735    0.6688      7906\n",
      "\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 82, 'EB': 41, 'PM': 216, 'PB': 322, 'ML': 14, 'FA': 14}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 23, 'EB': 8, 'PM': 78, 'PB': 123, 'ML': 10, 'FA': 10}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 99, 'EB': 109, 'PM': 59, 'PB': 484, 'ML': 45, 'FA': 45}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 6, 'EB': 0, 'PM': 19, 'PB': 19, 'ML': 6, 'FA': 6}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 11, 'EB': 2, 'PM': 59, 'PB': 80, 'ML': 3, 'FA': 3}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 10, 'PB': 14, 'ML': 2, 'FA': 2}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 3, 'EB': 1, 'PM': 23, 'PB': 28, 'ML': 2, 'FA': 2}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 7, 'EB': 1, 'PM': 45, 'PB': 51, 'ML': 5, 'FA': 5}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 5, 'PB': 1, 'ML': 3, 'FA': 3}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 8, 'PB': 6, 'ML': 1, 'FA': 1}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 6, 'PB': 1, 'ML': 1, 'FA': 1}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 5, 'PB': 1, 'ML': 1, 'FA': 1}\n",
      "Group: Length 24 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 1, 'ML': 0, 'FA': 0}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "Total loss: 7127.22931432724\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8774    0.4772    0.6182       285\n",
      " B-effect_size     0.7273    0.2025    0.3168       158\n",
      "B-intervention     0.7807    0.5503    0.6455       796\n",
      "     B-outcome     0.7627    0.5252    0.6221      1169\n",
      "  B-population     0.8111    0.4862    0.6080       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.7500    0.4721    0.5795       305\n",
      "I-intervention     0.8672    0.6691    0.7554      1816\n",
      "     I-outcome     0.8653    0.6107    0.7160      1988\n",
      "  I-population     0.8628    0.5636    0.6818       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5715      7906\n",
      "     macro avg     0.6641    0.4143    0.5039      7906\n",
      "  weighted avg     0.8295    0.5715    0.6742      7906\n",
      "\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 57, 'EB': 41, 'PM': 194, 'PB': 384, 'ML': 20, 'FA': 20}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 35, 'EB': 10, 'PM': 80, 'PB': 123, 'ML': 10, 'FA': 10}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 108, 'EB': 135, 'PM': 57, 'PB': 500, 'ML': 35, 'FA': 35}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 8, 'EB': 1, 'PM': 23, 'PB': 20, 'ML': 4, 'FA': 4}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 15, 'EB': 1, 'PM': 64, 'PB': 80, 'ML': 8, 'FA': 8}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 12, 'PB': 15, 'ML': 3, 'FA': 3}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 5, 'EB': 0, 'PM': 31, 'PB': 21, 'ML': 4, 'FA': 4}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 11, 'EB': 2, 'PM': 46, 'PB': 42, 'ML': 2, 'FA': 2}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 2, 'PB': 5, 'ML': 3, 'FA': 3}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 11, 'PB': 3, 'ML': 1, 'FA': 1}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 2, 'ML': 2, 'FA': 2}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 2, 'ML': 1, 'FA': 1}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 1, 'ML': 2, 'FA': 2}\n",
      "Group: Length 24 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "Total loss: 7028.0442316532135\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8590    0.4702    0.6077       285\n",
      " B-effect_size     0.6207    0.2278    0.3333       158\n",
      "B-intervention     0.7704    0.5565    0.6462       796\n",
      "     B-outcome     0.7896    0.5201    0.6271      1169\n",
      "  B-population     0.8062    0.5254    0.6362       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.7744    0.4164    0.5416       305\n",
      "I-intervention     0.8729    0.6735    0.7603      1816\n",
      "     I-outcome     0.8599    0.6610    0.7474      1988\n",
      "  I-population     0.8560    0.6185    0.7181       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5913      7906\n",
      "     macro avg     0.6554    0.4245    0.5107      7906\n",
      "  weighted avg     0.8295    0.5913    0.6882      7906\n",
      "\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 58, 'EB': 43, 'PM': 175, 'PB': 406, 'ML': 15, 'FA': 15}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 33, 'EB': 9, 'PM': 87, 'PB': 112, 'ML': 9, 'FA': 9}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 108, 'EB': 119, 'PM': 56, 'PB': 515, 'ML': 45, 'FA': 45}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 5, 'EB': 1, 'PM': 19, 'PB': 27, 'ML': 3, 'FA': 3}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 21, 'EB': 0, 'PM': 65, 'PB': 75, 'ML': 6, 'FA': 6}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 14, 'PB': 11, 'ML': 3, 'FA': 3}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 8, 'EB': 1, 'PM': 27, 'PB': 25, 'ML': 3, 'FA': 3}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 10, 'EB': 0, 'PM': 47, 'PB': 47, 'ML': 4, 'FA': 4}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 3, 'EB': 0, 'PM': 6, 'PB': 1, 'ML': 3, 'FA': 3}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 9, 'PB': 4, 'ML': 1, 'FA': 1}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 2, 'ML': 3, 'FA': 3}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 4, 'ML': 1, 'FA': 1}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 2, 'ML': 1, 'FA': 1}\n",
      "Group: Length 24 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 6838.122786283493\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8679    0.4842    0.6216       285\n",
      " B-effect_size     0.6111    0.2785    0.3826       158\n",
      "B-intervention     0.7442    0.6068    0.6685       796\n",
      "     B-outcome     0.7454    0.5885    0.6577      1169\n",
      "  B-population     0.7660    0.5747    0.6567       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.7872    0.6066    0.6852       305\n",
      "I-intervention     0.8894    0.6641    0.7604      1816\n",
      "     I-outcome     0.8810    0.6258    0.7318      1988\n",
      "  I-population     0.8711    0.5665    0.6865       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.6041      7906\n",
      "     macro avg     0.6512    0.4541    0.5319      7906\n",
      "  weighted avg     0.8278    0.6041    0.6970      7906\n",
      "\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 41, 'EB': 47, 'PM': 234, 'PB': 441, 'ML': 23, 'FA': 23}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 36, 'EB': 8, 'PM': 98, 'PB': 136, 'ML': 9, 'FA': 9}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 114, 'EB': 122, 'PM': 57, 'PB': 570, 'ML': 52, 'FA': 52}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 4, 'EB': 0, 'PM': 24, 'PB': 33, 'ML': 4, 'FA': 4}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 8, 'EB': 1, 'PM': 65, 'PB': 103, 'ML': 12, 'FA': 12}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 13, 'PB': 19, 'ML': 4, 'FA': 4}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 10, 'EB': 1, 'PM': 24, 'PB': 33, 'ML': 4, 'FA': 4}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 16, 'EB': 0, 'PM': 47, 'PB': 59, 'ML': 5, 'FA': 5}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 7, 'PB': 1, 'ML': 3, 'FA': 3}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 3, 'EB': 0, 'PM': 10, 'PB': 3, 'ML': 1, 'FA': 1}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 2, 'ML': 3, 'FA': 3}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 3, 'ML': 1, 'FA': 1}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 7, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 24 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "Total loss: 6748.976680755615\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8675    0.5053    0.6386       285\n",
      " B-effect_size     0.6301    0.2911    0.3983       158\n",
      "B-intervention     0.7539    0.6080    0.6732       796\n",
      "     B-outcome     0.7605    0.5731    0.6537      1169\n",
      "  B-population     0.7822    0.5733    0.6616       689\n",
      " I-coreference     0.0000    0.0000    0.0000         8\n",
      " I-effect_size     0.7968    0.4885    0.6057       305\n",
      "I-intervention     0.8930    0.6663    0.7632      1816\n",
      "     I-outcome     0.8755    0.6333    0.7350      1988\n",
      "  I-population     0.8658    0.5968    0.7066       692\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.6033      7906\n",
      "     macro avg     0.6568    0.4487    0.5305      7906\n",
      "  weighted avg     0.8322    0.6033    0.6984      7906\n",
      "\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 55, 'EB': 45, 'PM': 212, 'PB': 435, 'ML': 24, 'FA': 24}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 37, 'EB': 12, 'PM': 81, 'PB': 140, 'ML': 10, 'FA': 10}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 115, 'EB': 133, 'PM': 63, 'PB': 540, 'ML': 46, 'FA': 46}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 3, 'EB': 0, 'PM': 29, 'PB': 32, 'ML': 3, 'FA': 3}\n",
      "Group: Length 3 - Unseen, Metrics: {'EM': 14, 'EB': 1, 'PM': 65, 'PB': 95, 'ML': 11, 'FA': 11}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 13, 'PB': 14, 'ML': 6, 'FA': 6}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 14, 'EB': 1, 'PM': 26, 'PB': 28, 'ML': 3, 'FA': 3}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 12, 'EB': 0, 'PM': 41, 'PB': 62, 'ML': 6, 'FA': 6}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 7, 'PB': 1, 'ML': 3, 'FA': 3}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 9, 'PB': 6, 'ML': 1, 'FA': 1}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 5, 'PB': 1, 'ML': 3, 'FA': 3}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 3, 'ML': 2, 'FA': 2}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 7, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 24 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 1, 'ML': 1, 'FA': 1}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "\n",
      "Training complete at learning rate: 7e-05!\n",
      "EconBERTa Model saved at: 20240503-190205\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "import time\n",
    "\n",
    "# Calculate the total number of training steps\n",
    "total_steps = (len(train_set) // (batch_size * gradient_accumulation_steps)) * max_epochs\n",
    "\n",
    "lr = learning_rates[2]\n",
    "# for lr in learning_rates:\n",
    "print(f\"Current learning rate: {lr}\")\n",
    "\n",
    "# Create the optimizer with the specified hyperparameters\n",
    "optimizer = AdamW(model.parameters(), lr=lr, eps=adam_epsilon, betas=(adam_beta1, adam_beta2), weight_decay=weight_decay, no_deprecation_warning=True)\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * fraction_of_steps), num_training_steps=total_steps)\n",
    "\n",
    "# Training loop\n",
    "for epoch_i in range(max_epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, max_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    num_batches = int(len(train_set) / batch_size) + (1 if len(train_set) % batch_size != 0 else 0)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        end_index = min(batch_size * (i + 1), len(train_set))\n",
    "        batch = train_set[i * batch_size:end_index]\n",
    "\n",
    "        if len(batch) == 0:\n",
    "            continue\n",
    "\n",
    "        input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "        input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "        label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "        b_input_ids = input_id_tensors.to(device)\n",
    "        b_input_mask = input_mask_tensors.to(device)\n",
    "        b_labels = label_tensors.long().to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[\"loss\"]\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Accumulate gradients\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimizer step after accumulating gradients for gradient_accumulation_steps\n",
    "        if (i + 1) % gradient_accumulation_steps == 0 or i == num_batches - 1:  # Ensure step is taken on the last batch\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "    print(f\"Total loss: {total_train_loss}\")\n",
    "    report = get_validation_performance(val_set, model, device, label_dict, batch_size)\n",
    "    print(report)\n",
    "    analyze_generalization(model, val_set, tokenizer, train_sentences)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Training complete at learning rate: {lr}!\")\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(f\"EconBERTa Model saved at: {timestamp}\")\n",
    "torch.save(model.state_dict(), f'econberta_typos_lr-{lr}_{timestamp}.pth')\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a97d7bc8-61b0-4cda-bd70-309d7b57b5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load state_dict of the model\n",
    "model.load_state_dict(torch.load(f'econmodel_lr-7e-05_20240429-114015.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0e00e95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'econberta_typos_lr-7e-05_20240503-190205.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0e7b47ed-5523-4097-b121-ed3156040f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8980    0.4800    0.6256       550\n",
      " B-effect_size     0.5833    0.2188    0.3182       320\n",
      "B-intervention     0.7150    0.5414    0.6162      1330\n",
      "     B-outcome     0.6911    0.5105    0.5872      1718\n",
      "  B-population     0.7334    0.5432    0.6242      1018\n",
      " I-coreference     0.0000    0.0000    0.0000        22\n",
      " I-effect_size     0.7917    0.3548    0.4900       482\n",
      "I-intervention     0.8651    0.6309    0.7296      2663\n",
      "     I-outcome     0.8764    0.5787    0.6971      3235\n",
      "  I-population     0.8525    0.6218    0.7191      1227\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5547     12565\n",
      "     macro avg     0.6370    0.4073    0.4916     12565\n",
      "  weighted avg     0.8064    0.5547    0.6547     12565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_validation_performance(test_set, model, device, label_dict, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a77ec088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8000    0.2286    0.3556        35\n",
      " B-effect_size     0.2000    0.0323    0.0556        31\n",
      "B-intervention     0.5833    0.4023    0.4762        87\n",
      "     B-outcome     0.6279    0.3140    0.4186        86\n",
      "  B-population     0.5000    0.4390    0.4675        41\n",
      " I-coreference     0.0000    0.0000    0.0000         3\n",
      " I-effect_size     0.6923    0.1875    0.2951        48\n",
      "I-intervention     0.9216    0.5839    0.7148       161\n",
      "     I-outcome     0.8649    0.4571    0.5981       140\n",
      "  I-population     0.8571    0.4918    0.6250        61\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.4127       693\n",
      "     macro avg     0.5497    0.2851    0.3642       693\n",
      "  weighted avg     0.7423    0.4127    0.5222       693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_validation_performance(typos_set, model, device, label_dict, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f2d3c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8947    0.4650    0.6119       585\n",
      " B-effect_size     0.5680    0.2023    0.2983       351\n",
      "B-intervention     0.7076    0.5328    0.6079      1417\n",
      "     B-outcome     0.6890    0.5011    0.5802      1804\n",
      "  B-population     0.7228    0.5392    0.6176      1059\n",
      " I-coreference     0.0000    0.0000    0.0000        25\n",
      " I-effect_size     0.7860    0.3396    0.4743       530\n",
      "I-intervention     0.8679    0.6282    0.7288      2824\n",
      "     I-outcome     0.8760    0.5736    0.6933      3375\n",
      "  I-population     0.8527    0.6157    0.7151      1288\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5473     13258\n",
      "     macro avg     0.6332    0.3998    0.4843     13258\n",
      "  weighted avg     0.8038    0.5473    0.6483     13258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_validation_performance(test_typos_set, model, device, label_dict, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "26b1e4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8831    0.4906    0.6308       585\n",
      " B-effect_size     0.6667    0.3533    0.4618       351\n",
      "B-intervention     0.7271    0.5716    0.6401      1417\n",
      "     B-outcome     0.6884    0.5671    0.6219      1804\n",
      "  B-population     0.7445    0.6025    0.6660      1059\n",
      " I-coreference     0.0000    0.0000    0.0000        25\n",
      " I-effect_size     0.8175    0.4057    0.5422       530\n",
      "I-intervention     0.8669    0.6183    0.7218      2824\n",
      "     I-outcome     0.8829    0.5899    0.7073      3375\n",
      "  I-population     0.8776    0.5955    0.7095      1288\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5733     13258\n",
      "     macro avg     0.6504    0.4359    0.5183     13258\n",
      "  weighted avg     0.8148    0.5733    0.6707     13258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_validation_performance(test_typos_set, model, device, label_dict, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2e35a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     1.0000    0.6667    0.8000        24\n",
      " B-effect_size     0.6250    0.3125    0.4167        16\n",
      "B-intervention     0.6364    0.5632    0.5976        87\n",
      "     B-outcome     0.6264    0.4750    0.5403       120\n",
      "  B-population     0.7358    0.5652    0.6393        69\n",
      " I-effect_size     0.7273    0.5333    0.6154        30\n",
      "I-intervention     0.8333    0.6928    0.7566       166\n",
      "     I-outcome     0.7951    0.5052    0.6178       192\n",
      "  I-population     0.8333    0.4386    0.5747        57\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5506       761\n",
      "     macro avg     0.6813    0.4753    0.5558       761\n",
      "  weighted avg     0.7564    0.5506    0.6337       761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_validation_performance(df_set, model, device, label_dict, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "182b32c6-b772-4fbf-ab3d-26186ae685db",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Length 3 - Unseen, Metrics: {'EM': 1, 'EB': 4, 'PM': 100, 'PB': 171, 'ML': 12, 'FA': 12}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 7, 'EB': 0, 'PM': 58, 'PB': 95, 'ML': 10, 'FA': 10}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 107, 'EB': 253, 'PM': 82, 'PB': 1059, 'ML': 72, 'FA': 72}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 8, 'EB': 11, 'PM': 138, 'PB': 287, 'ML': 25, 'FA': 25}\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 41, 'EB': 40, 'PM': 323, 'PB': 609, 'ML': 33, 'FA': 33}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 3, 'EB': 2, 'PM': 55, 'PB': 60, 'ML': 6, 'FA': 6}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 8, 'PB': 10, 'ML': 6, 'FA': 6}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 19, 'PB': 24, 'ML': 3, 'FA': 3}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 6, 'PB': 6, 'ML': 3, 'FA': 3}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 22, 'PB': 20, 'ML': 5, 'FA': 5}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 2, 'ML': 3, 'FA': 3}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 31, 'PB': 60, 'ML': 7, 'FA': 7}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 1, 'ML': 1, 'FA': 1}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 1, 'ML': 1, 'FA': 1}\n",
      "Group: Length 17 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 1, 'ML': 0, 'FA': 0}\n",
      "Group: Length 18 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 32 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 19 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n"
     ]
    }
   ],
   "source": [
    "bert_lengths, bert_metrics = analyze_generalization(model, test_set, tokenizer, train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64d9d97a-92c2-4962-8977-92147cd93d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Length 3 - Unseen',\n",
       " 'Length 4 - Unseen',\n",
       " 'Length 0 - Unseen',\n",
       " 'Length 2 - Unseen',\n",
       " 'Length 1 - Unseen',\n",
       " 'Length 5 - Unseen',\n",
       " 'Length 9 - Unseen',\n",
       " 'Length 7 - Unseen',\n",
       " 'Length 10 - Unseen',\n",
       " 'Length 8 - Unseen',\n",
       " 'Length 11 - Unseen',\n",
       " 'Length 6 - Unseen',\n",
       " 'Length 12 - Unseen',\n",
       " 'Length 13 - Unseen',\n",
       " 'Length 16 - Unseen',\n",
       " 'Length 17 - Unseen',\n",
       " 'Length 18 - Unseen',\n",
       " 'Length 32 - Unseen',\n",
       " 'Length 14 - Unseen',\n",
       " 'Length 19 - Unseen']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a977c78a-c648-4607-b827-d0a01d303d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'EM': 1, 'EB': 4, 'PM': 100, 'PB': 171, 'ML': 12, 'FA': 12},\n",
       " {'EM': 7, 'EB': 0, 'PM': 58, 'PB': 95, 'ML': 10, 'FA': 10},\n",
       " {'EM': 107, 'EB': 253, 'PM': 82, 'PB': 1059, 'ML': 72, 'FA': 72},\n",
       " {'EM': 8, 'EB': 11, 'PM': 138, 'PB': 287, 'ML': 25, 'FA': 25},\n",
       " {'EM': 41, 'EB': 40, 'PM': 323, 'PB': 609, 'ML': 33, 'FA': 33},\n",
       " {'EM': 3, 'EB': 2, 'PM': 55, 'PB': 60, 'ML': 6, 'FA': 6},\n",
       " {'EM': 1, 'EB': 0, 'PM': 8, 'PB': 10, 'ML': 6, 'FA': 6},\n",
       " {'EM': 1, 'EB': 0, 'PM': 19, 'PB': 24, 'ML': 3, 'FA': 3},\n",
       " {'EM': 0, 'EB': 0, 'PM': 6, 'PB': 6, 'ML': 3, 'FA': 3},\n",
       " {'EM': 1, 'EB': 0, 'PM': 22, 'PB': 20, 'ML': 5, 'FA': 5},\n",
       " {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 2, 'ML': 3, 'FA': 3},\n",
       " {'EM': 1, 'EB': 0, 'PM': 31, 'PB': 60, 'ML': 7, 'FA': 7},\n",
       " {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 1, 'FA': 1},\n",
       " {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 1, 'ML': 1, 'FA': 1},\n",
       " {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 1, 'ML': 1, 'FA': 1},\n",
       " {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 1, 'ML': 0, 'FA': 0},\n",
       " {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 0, 'FA': 0},\n",
       " {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0},\n",
       " {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 0, 'ML': 0, 'FA': 0},\n",
       " {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f50e605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be7fa71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract sequence lengths and sort data by sequence length\n",
    "sequence_lengths = [int(s.split()[1]) for s in bert_lengths]\n",
    "sorted_indices = sorted(range(len(sequence_lengths)), key=lambda x: sequence_lengths[x])\n",
    "sequence_lengths = [sequence_lengths[i] for i in sorted_indices]\n",
    "\n",
    "# Calculate proportions for each metric\n",
    "metrics_keys = ['EM', 'EB', 'PM', 'PB', 'ML', 'FA']  # Add other metric keys if needed\n",
    "proportions = {key: [] for key in metrics_keys}\n",
    "\n",
    "for key in metrics_keys:\n",
    "    metric_values = [bert_metrics[i][key] for i in sorted_indices]\n",
    "    metric_total = sum(metric_values)\n",
    "    proportions[key] = [value / metric_total for value in metric_values]\n",
    "\n",
    "# Plot each metric using stacked bar graphs for the first 15 sequence lengths\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  # Adjust the figure size as needed\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "indices = range(len(sequence_lengths[:15]))\n",
    "\n",
    "# Initialize the bottom for the stack\n",
    "bottom = [0] * 15\n",
    "\n",
    "for key in metrics_keys:\n",
    "    ax.bar(indices, proportions[key][:15], bottom=bottom, label=key)\n",
    "    # Update the bottom position for the next metric\n",
    "    bottom = [bottom[i] + proportions[key][i] for i in range(15)]\n",
    "\n",
    "# Labeling\n",
    "ax.set_xlabel('Entity Length')\n",
    "ax.set_ylabel('Proportion of Entities')\n",
    "ax.set_title('Proportion of Entities by Sequence Length (First 15)')\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels(sequence_lengths[:15])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f5649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177246f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcff725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ff82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb60fd7-9d27-4fbc-bcd8-03135bf9aa3c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: checklist in /home/cbekal/.local/lib/python3.9/site-packages (0.0.11)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from checklist) (1.22.3)\n",
      "Requirement already satisfied: spacy>=2.2 in /home/cbekal/.local/lib/python3.9/site-packages (from checklist) (3.7.4)\n",
      "Requirement already satisfied: munch>=2.5 in /home/cbekal/.local/lib/python3.9/site-packages (from checklist) (4.0.0)\n",
      "Requirement already satisfied: dill>=0.3.1 in /home/cbekal/.local/lib/python3.9/site-packages (from checklist) (0.3.8)\n",
      "Requirement already satisfied: jupyter>=1.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from checklist) (1.0.0)\n",
      "Requirement already satisfied: ipywidgets>=7.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from checklist) (7.7.0)\n",
      "Requirement already satisfied: transformers>=2.8 in /home/cbekal/.local/lib/python3.9/site-packages (from checklist) (4.39.3)\n",
      "Requirement already satisfied: patternfork-nosql in /home/cbekal/.local/lib/python3.9/site-packages (from checklist) (3.6)\n",
      "Requirement already satisfied: iso-639 in /home/cbekal/.local/lib/python3.9/site-packages (from checklist) (0.4.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (6.9.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (5.1.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (5.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (3.6.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (8.1.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (1.1.0)\n",
      "Requirement already satisfied: notebook in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter>=1.0->checklist) (6.4.10)\n",
      "Requirement already satisfied: qtconsole in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter>=1.0->checklist) (5.2.2)\n",
      "Requirement already satisfied: jupyter-console in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter>=1.0->checklist) (6.4.3)\n",
      "Requirement already satisfied: nbconvert in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter>=1.0->checklist) (6.4.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (4.63.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (2.27.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (61.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/cbekal/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (3.4.0)\n",
      "Requirement already satisfied: filelock in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers>=2.8->checklist) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/cbekal/.local/lib/python3.9/site-packages (from transformers>=2.8->checklist) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers>=2.8->checklist) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers>=2.8->checklist) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/cbekal/.local/lib/python3.9/site-packages (from transformers>=2.8->checklist) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/cbekal/.local/lib/python3.9/site-packages (from transformers>=2.8->checklist) (0.4.3)\n",
      "Requirement already satisfied: future in /home/cbekal/.local/lib/python3.9/site-packages (from patternfork-nosql->checklist) (1.0.0)\n",
      "Requirement already satisfied: backports.csv in /home/cbekal/.local/lib/python3.9/site-packages (from patternfork-nosql->checklist) (1.0.7)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from patternfork-nosql->checklist) (4.10.0)\n",
      "Requirement already satisfied: lxml in /home/cbekal/.local/lib/python3.9/site-packages (from patternfork-nosql->checklist) (4.9.2)\n",
      "Requirement already satisfied: feedparser in /home/cbekal/.local/lib/python3.9/site-packages (from patternfork-nosql->checklist) (6.0.11)\n",
      "Requirement already satisfied: pdfminer.six in /home/cbekal/.local/lib/python3.9/site-packages (from patternfork-nosql->checklist) (20231228)\n",
      "Requirement already satisfied: scipy in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from patternfork-nosql->checklist) (1.9.1)\n",
      "Requirement already satisfied: nltk in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from patternfork-nosql->checklist) (3.6.7)\n",
      "Requirement already satisfied: python-docx in /home/cbekal/.local/lib/python3.9/site-packages (from patternfork-nosql->checklist) (1.1.1)\n",
      "Requirement already satisfied: cherrypy in /home/cbekal/.local/lib/python3.9/site-packages (from patternfork-nosql->checklist) (18.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/cbekal/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=2.8->checklist) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/cbekal/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=2.8->checklist) (4.11.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (1.6.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (7.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (0.1.3)\n",
      "Requirement already satisfied: psutil in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (5.9.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (1.5.4)\n",
      "Requirement already satisfied: backcall in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (3.0.28)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.8.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/cbekal/.local/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.2->checklist) (1.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist) (4.9.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from packaging>=20.0->spacy>=2.2->checklist) (3.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/cbekal/.local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.2->checklist) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/cbekal/.local/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.2->checklist) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy>=2.2->checklist) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/cbekal/.local/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.2->checklist) (0.16.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (22.3.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (0.13.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (0.13.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.4)\n",
      "Requirement already satisfied: bleach in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.5.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jinja2->spacy>=2.2->checklist) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from beautifulsoup4->patternfork-nosql->checklist) (2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cheroot>=8.2.1 in /home/cbekal/.local/lib/python3.9/site-packages (from cherrypy->patternfork-nosql->checklist) (10.0.1)\n",
      "Requirement already satisfied: portend>=2.1.1 in /home/cbekal/.local/lib/python3.9/site-packages (from cherrypy->patternfork-nosql->checklist) (3.2.0)\n",
      "Requirement already satisfied: more-itertools in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from cherrypy->patternfork-nosql->checklist) (8.12.0)\n",
      "Requirement already satisfied: zc.lockfile in /home/cbekal/.local/lib/python3.9/site-packages (from cherrypy->patternfork-nosql->checklist) (3.0.post1)\n",
      "Requirement already satisfied: jaraco.collections in /home/cbekal/.local/lib/python3.9/site-packages (from cherrypy->patternfork-nosql->checklist) (5.0.1)\n",
      "Requirement already satisfied: sgmllib3k in /home/cbekal/.local/lib/python3.9/site-packages (from feedparser->patternfork-nosql->checklist) (1.0.0)\n",
      "Requirement already satisfied: joblib in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nltk->patternfork-nosql->checklist) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from pdfminer.six->patternfork-nosql->checklist) (36.0.2)\n",
      "Requirement already satisfied: qtpy in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from qtconsole->jupyter>=1.0->checklist) (2.0.1)\n",
      "Requirement already satisfied: jaraco.functools in /home/cbekal/.local/lib/python3.9/site-packages (from cheroot>=8.2.1->cherrypy->patternfork-nosql->checklist) (4.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (1.15.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist) (0.18.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (2.8.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /home/cbekal/.local/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.2->checklist) (1.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.0)\n",
      "Requirement already satisfied: tempora>=1.8 in /home/cbekal/.local/lib/python3.9/site-packages (from portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (5.5.1)\n",
      "Requirement already satisfied: wcwidth in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from argon2-cffi->notebook->jupyter>=1.0->checklist) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from bleach->nbconvert->jupyter>=1.0->checklist) (0.5.1)\n",
      "Requirement already satisfied: jaraco.text in /home/cbekal/.local/lib/python3.9/site-packages (from jaraco.collections->cherrypy->patternfork-nosql->checklist) (3.12.0)\n",
      "Requirement already satisfied: executing in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5->checklist) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (2.21)\n",
      "Requirement already satisfied: pytz in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (2019.3)\n",
      "Requirement already satisfied: jaraco.context>=4.1 in /home/cbekal/.local/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (5.3.0)\n",
      "Requirement already satisfied: autocommand in /home/cbekal/.local/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (2.2.2)\n",
      "Requirement already satisfied: inflect in /home/cbekal/.local/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (7.2.1)\n",
      "Requirement already satisfied: backports.tarfile in /home/cbekal/.local/lib/python3.9/site-packages (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (1.1.1)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in /home/cbekal/.local/lib/python3.9/site-packages (from inflect->jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (4.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from typeguard>=4.0.1->inflect->jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from importlib-metadata>=3.6->typeguard>=4.0.1->inflect->jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (3.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c317a4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydantic in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (1.8.2)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic)\n",
      "  Downloading pydantic_core-2.18.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/cbekal/.local/lib/python3.9/site-packages (from pydantic) (4.11.0)\n",
      "Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pydantic-core, annotated-types, pydantic\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "label-studio 1.4.1.post1 requires pydantic<=1.8.2,>=1.7.3, but you have pydantic 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.6.0 pydantic-2.7.1 pydantic-core-2.18.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1504dcdf-ce60-4cd2-968f-80aac642aede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/cbekal/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "407ec42d-2a8e-4032-9258-e2882fa3d315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.expect import Expect\n",
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91d248ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from checklist.test_types import MFT, INV, DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d284ea11-3d4b-471c-96c1-3f56e06611b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(df):\n",
    "    # Assuming df has columns 'sentences' and 'labels'\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['sentences']\n",
    "        labels = row['labels']\n",
    "        words = sentence.split()\n",
    "\n",
    "        for i, (word, label) in enumerate(zip(words, labels)):\n",
    "            if label.startswith('B-'):\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                current_entity = {'type': label[2:], 'start_idx': i, 'end_idx': i, 'text': word}\n",
    "            elif label.startswith('I-') and current_entity and label[2:] == current_entity['type']:\n",
    "                current_entity['end_idx'] = i\n",
    "                current_entity['text'] += ' ' + word\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "\n",
    "        if current_entity:\n",
    "            entities.append(current_entity)\n",
    "            current_entity = None\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b4058c6-47a1-4a37-8e76-d0e256960791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15872\n"
     ]
    }
   ],
   "source": [
    "entities = extract_entities(train_df)\n",
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb7cd518",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = entities[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d86ecbfe-0501-4fd9-b2c8-f0a65627e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for populations\n",
    "population_templates = (\n",
    "    'The study focused on {population}.',\n",
    "    'Results were most significant among {population}.',\n",
    "    'The impact on {population} was noteworthy.',\n",
    "    'Interventions were targeted towards {population}.',\n",
    "    'Data was collected from various {population}.',\n",
    "    'The {population} showed a remarkable response.',\n",
    "    'Surveys were conducted across different {population}.',\n",
    "    'The {population} was observed for changes.',\n",
    "    'A significant change was recorded in the {population}.',\n",
    "    'The research aimed to benefit the {population}.'\n",
    ")\n",
    "\n",
    "# Define custom population entity\n",
    "populations = [entity['text'] for entity in entities if entity['type']=='population']\n",
    "\n",
    "# Use the editor to create examples\n",
    "population_test_cases = editor.template(\n",
    "    population_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    population=populations\n",
    ")\n",
    "    \n",
    "def found_population(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'population' is the only entity type present in the prediction\n",
    "    expected_population = meta['population']\n",
    "    return all(label == 'O' or label.endswith('population') for label in pred)\n",
    "\n",
    "found_population_expect_fn = Expect.single(found_population)\n",
    "\n",
    "# A simple MFT test\n",
    "found_population_test = MFT(\n",
    "    **population_test_cases,\n",
    "    name='Test for correct population recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label populations.',\n",
    "    expect=found_population_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a2bd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for interventions\n",
    "intervention_templates = (\n",
    "    \"The {intervention} was implemented to address the issue.\",\n",
    "    \"Researchers studied the effects of the {intervention}.\",\n",
    "    \"The {intervention} had a significant impact on the community.\",\n",
    "    \"Funding was provided for the {intervention}.\",\n",
    "    \"The success of the {intervention} was evident in the results.\",\n",
    "    \"Participants were selected for the {intervention} group.\",\n",
    "    \"The {intervention} was a key part of the strategy.\",\n",
    "    \"The {intervention} targeted specific outcomes.\",\n",
    "    \"Outcomes were measured after the {intervention} took place.\",\n",
    "    \"The {intervention} was designed to improve overall outcomes.\"\n",
    ")\n",
    "\n",
    "# Define custom intervention entity\n",
    "interventions = [entity['text'] for entity in entities if entity['type']=='intervention']\n",
    "\n",
    "# Use the editor to create examples\n",
    "intervention_test_cases = editor.template(\n",
    "    intervention_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    intervention=interventions\n",
    ")\n",
    "\n",
    "def found_intervention(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'intervention' is the only entity type present in the prediction\n",
    "    expected_intervention = meta['intervention']\n",
    "    return all(label == 'O' or label.endswith('intervention') for label in pred)\n",
    "\n",
    "found_intervention_expect_fn = Expect.single(found_intervention)    \n",
    "\n",
    "# A simple MFT test\n",
    "found_intervention_test = MFT(\n",
    "    **intervention_test_cases,\n",
    "    name='Test for correct intervention recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label interventions.',\n",
    "    expect=found_intervention_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92242b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for outcomes\n",
    "outcome_templates = (\n",
    "    \"The outcome of the study was {outcome}.\",\n",
    "    \"It was observed that the primary outcome was {outcome}.\",\n",
    "    \"The expected outcome was {outcome}, which was surprising.\",\n",
    "    \"As a result, the outcome was {outcome}.\",\n",
    "    \"The final outcome, {outcome}, was recorded after the experiment.\",\n",
    "    \"The result of the intervention was {outcome}.\",\n",
    "    \"The project led to {outcome}.\",\n",
    "    \"The consequences were observed as {outcome}.\",\n",
    "    \"The end effect was {outcome}.\",\n",
    "    \"The study concluded with {outcome}.\"\n",
    ")\n",
    "\n",
    "# Define custom outcome entity\n",
    "outcomes = [entity['text'] for entity in entities if entity['type']=='outcome']\n",
    "\n",
    "# Use the editor to create examples\n",
    "outcome_test_cases = editor.template(\n",
    "    outcome_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    outcome=outcomes\n",
    ")\n",
    "\n",
    "def found_outcome(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'outcome' is the only entity type present in the prediction\n",
    "    expected_outcome = meta['outcome']\n",
    "    return all(label == 'O' or label.endswith('outcome') for label in pred)\n",
    "\n",
    "found_outcome_expect_fn = Expect.single(found_outcome)    \n",
    "\n",
    "# A simple MFT test\n",
    "found_outcome_test = MFT(\n",
    "    **outcome_test_cases,\n",
    "    name='Test for correct outcome recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label outcomes.',\n",
    "    expect=found_outcome_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86f67a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for effect_sizes\n",
    "effect_size_templates = (\n",
    "    \"The observed change was {effect_size}.\",\n",
    "    \"A {effect_size} increase was noted in the study.\",\n",
    "    \"The results showed a {effect_size} decrease.\",\n",
    "    \"There was a {effect_size} improvement over the baseline.\",\n",
    "    \"The effect was quantified as {effect_size}.\",\n",
    "    \"The magnitude of impact measured {effect_size}.\",\n",
    "    \"The statistical significance reached {effect_size}.\",\n",
    "    \"A {effect_size} reduction in errors was achieved.\",\n",
    "    \"The intervention led to a {effect_size} enhancement.\",\n",
    "    \"The data indicated a {effect_size} growth rate.\"\n",
    ")\n",
    "\n",
    "# Define custom effect_size entity\n",
    "effect_sizes = [entity['text'] for entity in entities if entity['type']=='effect_size']\n",
    "\n",
    "# Use the editor to create examples\n",
    "effect_size_test_cases = editor.template(\n",
    "    effect_size_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    effect_size=effect_sizes\n",
    ")\n",
    "\n",
    "def found_effect_size(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'effect_size' is the only entity type present in the prediction\n",
    "    expected_effect_size = meta['effect_size']\n",
    "    return all(label == 'O' or label.endswith('effect_size') for label in pred)\n",
    "\n",
    "found_effect_size_expect_fn = Expect.single(found_effect_size)    \n",
    "\n",
    "# A simple MFT test\n",
    "found_effect_size_test = MFT(\n",
    "    **effect_size_test_cases,\n",
    "    name='Test for correct effect-size recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label effect-size.',\n",
    "    expect=found_effect_size_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3c4a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for coreferences\n",
    "coreference_templates = (\n",
    "    \"This refers to the {coreference}.\",\n",
    "    \"Such instances of {coreference} were noted.\",\n",
    "    \"As mentioned earlier, the {coreference} plays a crucial role.\",\n",
    "    \"This is similar to the {coreference} discussed before.\",\n",
    "    \"The case of {coreference} is particularly interesting.\",\n",
    "    \"In light of the {coreference}, further analysis is required.\",\n",
    "    \"This aligns with the {coreference} we observed.\",\n",
    "    \"The {coreference} under discussion was pivotal.\",\n",
    "    \"Reflecting on the {coreference}, it becomes clear.\",\n",
    "    \"Given the {coreference}, the results are unsurprising.\"\n",
    ")\n",
    "\n",
    "# Define custom coreference entity\n",
    "coreferences = [entity['text'] for entity in entities if entity['type']=='coreference']\n",
    "\n",
    "# Use the editor to create examples\n",
    "coreference_test_cases = editor.template(\n",
    "    coreference_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    coreference=coreferences\n",
    ")\n",
    "\n",
    "def found_coreference(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'coreference' is the only entity type present in the prediction\n",
    "    expected_coreference = meta['coreference']\n",
    "    return all(label == 'O' or label.endswith('coreference') for label in pred)\n",
    "\n",
    "found_coreference_expect_fn = Expect.single(found_coreference)    \n",
    "\n",
    "# A simple MFT test\n",
    "found_coreference_test = MFT(\n",
    "    **coreference_test_cases,\n",
    "    name='Test for correct coreference recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label coreference.',\n",
    "    expect=found_coreference_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc7a0c01-db20-488d-81c5-245df3e92451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define an INV test that adds typos to the sentence\n",
    "# Inv = INV(\n",
    "#     name='Test for robustness to typos',\n",
    "#     capability='Robustness',\n",
    "#     description='The model should be robust to typos in the input.',\n",
    "#     data=Perturb.perturb(['The government implemented a new intervention to boost economic growth.'], Perturb.add_typos).data,\n",
    "#     expect=expect_fn\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "464ee698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This paper is a report of a study examining the effects of a supportive counselling programme on the academic performance of Iranian nursing students experiencing academic failure .', 'This paper is a report of a study examining the effects of a supportive counselling programme on the academic performance of Iranian nursing students experiencign academic failure .'], ['However , there was no significant impact of NERICA adoption on human health .', 'However , there was no significant impact of NERICA adoption on human healt h.'], ['Taking effective preventive measures is particularly important for control of HFMD infection .', 'Taking effective preventive measures is particularly impotrant for control of HFMD infection .'], ['The primary outcome was school climate measured with the Beyond Blue School Climate Questionnaire ( BBSCQ ) .', 'The primary outcome wsa school climate measured with the Beyond Blue School Climate Questionnaire ( BBSCQ ) .'], ['Data come from a random sample of 300 trained and 300 non-trained farmers producing either bitter gourd ( Momordica charantia L .', 'Data come from a random sample of 300 trained and 300 non-trained farmers producing either bitter gourd ( Momordica charanti aL .'], ['However , our findings are consistent with other blinded studies of similar interventions and raise additional questions about the actual health impact of household water treatment under these conditions .', 'However , our findings are consistent with other blinded studies of similar intervention sand raise additional questions about the actual health impact of household water treatment under these conditions .'], ['Results indicate that the program strongly increased land security and access to government entitlements , moderately increased asset ownership and homestead satisfaction , and had a weak positive effect on food security .', 'Results indicate that the program strongly incresaed land security and access to government entitlements , moderately increased asset ownership and homestead satisfaction , and had a weak positive effect on food security .'], ['There were two deaths in the intervention and one in the control arm .', 'There were two deaths in the intervention and one in the cnotrol arm .'], ['In 1994 , Ethiopia introduced mother tongue instruction in primary schooling for the largest ethnic group in the country .', 'In 1994 , Ethiopia introduced mother tongeu instruction in primary schooling for the largest ethnic group in the country .'], [\"[ Results indicate that farmers ' participation in bore pool sharing collectives is positively associated with their crop incomes .\", \"[ Results indiacte that farmers ' participation in bore pool sharing collectives is positively associated with their crop incomes .\"]]\n"
     ]
    }
   ],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "import random\n",
    "\n",
    "\n",
    "# Create a test suite\n",
    "suite = TestSuite()\n",
    "sentences = test_df.sentences.tolist()\n",
    "# Define a simple example input\n",
    "examples = random.sample(sentences, k=10)\n",
    "\n",
    "# Define a perturbation function that changes the case of the input text\n",
    "def change_case(texts):\n",
    "    return [texts.swapcase()]\n",
    "\n",
    "t = Perturb.perturb(examples, Perturb.add_typos)\n",
    "print(t.data)\n",
    "# Create an invariance test\n",
    "test = INV(**t, name='Change case', capability='Robustness',\n",
    "          description='Changing the case of the input text should not change the predictions.')\n",
    "\n",
    "# Add the test to the suite\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a9a4370-6932-4568-b084-33f5af6dc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a DIR test that negates the sentence\n",
    "# Dir = DIR(\n",
    "#     name='Test for sensitivity to negations',\n",
    "#     capability='Negation',\n",
    "#     description='The model should change predictions when negations are added.',\n",
    "#     data=[('The government implemented a new intervention to boost economic growth.', 'The government did not implement a new intervention to boost economic growth.', {'entities': ['B-intervention', 'I-intervention', 'O', 'O', 'O', 'O', 'B-outcome'], 'negated_entities': ['O']*7} )],\n",
    "#     expect=expect_fn\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2390849-083e-43e2-88c5-13f5fa40a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "\n",
    "suite = TestSuite()\n",
    "suite.add(found_population_test)\n",
    "suite.add(found_intervention_test)\n",
    "suite.add(found_outcome_test)\n",
    "suite.add(found_effect_size_test)\n",
    "suite.add(found_coreference_test)\n",
    "# suite.add(Inv)\n",
    "# suite.add(Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d9f6318e-92b0-4d47-8006-9ef58aeb8666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model_name\n",
    "lr = learning_rates[0]\n",
    "\n",
    "# Load state_dict of the model\n",
    "model.load_state_dict(torch.load(f'econmodel_lr-7e-05_20240429-114015.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18293093-1672-4764-9d2d-2b13eeeb17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts):\n",
    "    # Extract just the sentences from the input tuples\n",
    "    sentences = [text[0] for text in texts]\n",
    "    \n",
    "    # Convert texts to input IDs and attention masks using the tokenizer\n",
    "    input_ids, attention_mask = tokenize_and_format(sentences, tokenizer, max_length)\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    # Use the model to get the logits\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Decode the outputs using the CRF layer\n",
    "    decoded_labels = outputs['decoded']\n",
    "    \n",
    "    # Convert label indices to label names\n",
    "    pred_labels = [[reverse_label_dict[label] for label in sentence_labels] for sentence_labels in decoded_labels]\n",
    "    print(pred_labels)\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "718cb8f7-20b7-486d-873e-aaabb5f7095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "predict_and_conf = PredictorWrapper.wrap_predict(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "230ad42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Change case\n",
      "Predicting 20 examples\n",
      "[['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O'], ['O', 'O', 'O']]\n",
      "Robustness\n",
      "\n",
      "Change case\n",
      "Test cases:      10\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the test suite\n",
    "results = suite.run(predict_and_conf)\n",
    "\n",
    "# Summarize the results\n",
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "566c16d7-015e-44e6-80f5-e2785dbed488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test for correct population recognition\n",
      "Predicting 6 examples\n",
      "Running Test for correct intervention recognition\n",
      "Predicting 19 examples\n",
      "Running Test for correct outcome recognition\n",
      "Predicting 21 examples\n",
      "Running Test for correct effect-size recognition\n",
      "Predicting 2 examples\n",
      "Running Test for correct coreference recognition\n",
      "Predicting 2 examples\n"
     ]
    }
   ],
   "source": [
    "# Run the test suite\n",
    "suite.run(predict_and_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c377b627",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER\n",
      "\n",
      "Test for correct population recognition\n",
      "Test cases:      6\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test for correct intervention recognition\n",
      "Test cases:      19\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test for correct outcome recognition\n",
      "Test cases:      21\n",
      "Fails (rate):    1 (4.8%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-intervention', 'I-intervention', 'O', 'O', 'O'] ('The outcome of the study was drainage infrastructure.', 'It was observed that the primary outcome was drainage infrastructure.', 'The expected outcome was drainage infrastructure, which was surprising.', 'As a result, the outcome was drainage infrastructure.', 'The final outcome, drainage infrastructure, was recorded after the experiment.', 'The result of the intervention was drainage infrastructure.', 'The project led to drainage infrastructure.', 'The consequences were observed as drainage infrastructure.', 'The end effect was drainage infrastructure.', 'The study concluded with drainage infrastructure.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct effect-size recognition\n",
      "Test cases:      2\n",
      "Fails (rate):    1 (50.0%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'O', 'O', 'O', 'B-intervention', 'O', 'O', 'O', 'O'] ('The observed change was IPIG.', 'A IPIG increase was noted in the study.', 'The results showed a IPIG decrease.', 'There was a IPIG improvement over the baseline.', 'The effect was quantified as IPIG.', 'The magnitude of impact measured IPIG.', 'The statistical significance reached IPIG.', 'A IPIG reduction in errors was achieved.', 'The intervention led to a IPIG enhancement.', 'The data indicated a IPIG growth rate.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct coreference recognition\n",
      "Test cases:      2\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "145560d2-1713-4c5a-86b3-6c6b5ea0d7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220ebef1ab2f4f2185c0a599b3fd36b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Test for correct pop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "12afd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "56aa6932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Despite large schooling and learning gains in ...</td>\n",
       "      <td>[O, O, B-outcome, I-outcome, I-outcome, I-outc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>For children classified with nonsevere pneumon...</td>\n",
       "      <td>[O, B-population, I-population, I-population, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Food security and agricultural-led industriali...</td>\n",
       "      <td>[B-outcome, I-outcome, O, B-outcome, I-outcome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>However , bonus group members are more likely ...</td>\n",
       "      <td>[O, O, B-intervention, O, O, O, O, O, O, B-out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>The intervention consisted of an intensive pro...</td>\n",
       "      <td>[O, B-coreference, O, O, O, O, B-intervention,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>The results suggest that the project has had a...</td>\n",
       "      <td>[O, O, O, O, O, B-coreference, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>The program had similarly large impact and did...</td>\n",
       "      <td>[O, B-coreference, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Our results show a large effect of the legal t...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-intervention, I-int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>There was a significant treatment effect of vi...</td>\n",
       "      <td>[O, O, O, O, B-coreference, B-coreference, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>The investment readiness program resulted in a...</td>\n",
       "      <td>[O, B-intervention, I-intervention, I-interven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentences  \\\n",
       "322   Despite large schooling and learning gains in ...   \n",
       "408   For children classified with nonsevere pneumon...   \n",
       "405   Food security and agricultural-led industriali...   \n",
       "462   However , bonus group members are more likely ...   \n",
       "1137  The intervention consisted of an intensive pro...   \n",
       "1244  The results suggest that the project has had a...   \n",
       "1205  The program had similarly large impact and did...   \n",
       "799   Our results show a large effect of the legal t...   \n",
       "1295  There was a significant treatment effect of vi...   \n",
       "1151  The investment readiness program resulted in a...   \n",
       "\n",
       "                                                 labels  \n",
       "322   [O, O, B-outcome, I-outcome, I-outcome, I-outc...  \n",
       "408   [O, B-population, I-population, I-population, ...  \n",
       "405   [B-outcome, I-outcome, O, B-outcome, I-outcome...  \n",
       "462   [O, O, B-intervention, O, O, O, O, O, O, B-out...  \n",
       "1137  [O, B-coreference, O, O, O, O, B-intervention,...  \n",
       "1244  [O, O, O, O, O, B-coreference, O, O, O, O, O, ...  \n",
       "1205  [O, B-coreference, O, O, O, O, O, O, O, O, O, ...  \n",
       "799   [O, O, O, O, O, O, O, O, B-intervention, I-int...  \n",
       "1295  [O, O, O, O, B-coreference, B-coreference, O, ...  \n",
       "1151  [O, B-intervention, I-intervention, I-interven...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d81d3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sample.sentences.tolist()\n",
    "labels = sample.labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7ccbd3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Despite large schooling and learning gains in many developing countries , children in highly deprived areas are often unlikely to achieve even basic literacy and numeracy .',\n",
       " 'For children classified with nonsevere pneumonia , 68.2% ( 247 / 362 ) in the intervention arm and 13.3% ( 22 / 203 ) in the control arm received early and appropriate treatment ( risk ratio 5.32 , 95% confidence interval 2.19 - 8.94 ) .',\n",
       " 'Food security and agricultural-led industrialisation are pivotal development objectives in Ethiopia .',\n",
       " 'However , bonus group members are more likely to make extralegal payments and to obtain licenses without knowing how to drive .',\n",
       " 'The intervention consisted of an intensive promotion campaign and free distribution of sodium dichloroisocyanurate ( NaDCC ) tablets during bi-monthly households visits .',\n",
       " 'The results suggest that the project has had a large and positive effect on gross and net values of cereal production per hectare , as well as on the share of production sold to pasta makers through cooperatives .',\n",
       " 'The program had similarly large impact and did not depend on the type of skills offered .',\n",
       " 'Our results show a large effect of the legal threshold on the number of parties .',\n",
       " 'There was a significant treatment effect of vitamin A on serum retinol ( p < 0.01 ) , and the suggestion of an additive effect between vitamin A fortification and de-worming .',\n",
       " 'The investment readiness program resulted in a 0.3 standard deviation increase in the investment readiness score , with this increase occurring throughout the distribution .']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b55a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Despite large schooling and learning gains in many developing countries , children in highly deprived areas are often unlikely to achieve even basic literacy and numeracy .', 'Despite large schooling and learning gains in many developing countries , cihldren in highly deprived areas are often unlikely to achieve even basic literacy and numeracy .'], ['For children classified with nonsevere pneumonia , 68.2% ( 247 / 362 ) in the intervention arm and 13.3% ( 22 / 203 ) in the control arm received early and appropriate treatment ( risk ratio 5.32 , 95% confidence interval 2.19 - 8.94 ) .', 'For children classified with nonsevere pneumonia , 68.2% ( 247 / 362 ) in the intervention arm and 13.3% ( 22 / 203 ) int he control arm received early and appropriate treatment ( risk ratio 5.32 , 95% confidence interval 2.19 - 8.94 ) .'], ['Food security and agricultural-led industrialisation are pivotal development objectives in Ethiopia .', 'Food security and agricultural-led industrialsiation are pivotal development objectives in Ethiopia .'], ['However , bonus group members are more likely to make extralegal payments and to obtain licenses without knowing how to drive .', 'However , bonus group members aer more likely to make extralegal payments and to obtain licenses without knowing how to drive .'], ['The intervention consisted of an intensive promotion campaign and free distribution of sodium dichloroisocyanurate ( NaDCC ) tablets during bi-monthly households visits .', 'The intervention consisted of an intensive promotion campaign and free distribuiton of sodium dichloroisocyanurate ( NaDCC ) tablets during bi-monthly households visits .'], ['The results suggest that the project has had a large and positive effect on gross and net values of cereal production per hectare , as well as on the share of production sold to pasta makers through cooperatives .', 'The results suggest that the project has had a large nad positive effect on gross and net values of cereal production per hectare , as well as on the share of production sold to pasta makers through cooperatives .'], ['The program had similarly large impact and did not depend on the type of skills offered .', 'The program had similarly large impact and did not depend on the type of skills offerde .'], ['Our results show a large effect of the legal threshold on the number of parties .', 'Our results show a alrge effect of the legal threshold on the number of parties .'], ['There was a significant treatment effect of vitamin A on serum retinol ( p < 0.01 ) , and the suggestion of an additive effect between vitamin A fortification and de-worming .', 'There was a significant treatment effect of vitamin A on serum retinol ( p < 0.01 ) , and the suggestion of an additive effect between vitamin A fortification adn de-worming .'], ['The investment readiness program resulted in a 0.3 standard deviation increase in the investment readiness score , with this increase occurring throughout the distribution .', 'The investment readiness program resulted in a 0.3 standard deviation increase in the investment readiness score , with this increase occurring throughout the distribuiton .']]\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(sentences, Perturb.add_typos)\n",
    "print(t.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69385022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d36369356684e6aa06b7ada70e96ce0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11461a73263241bd8e2ad35a92e0c2dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "163bff609cfa453abc5879732e2220f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7343c5bf56714623a01c5594bb9a9aa0",
      "placeholder": "​",
      "style": "IPY_MODEL_59cffec0648542bf98578314858763bb",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "1ad64543adeb474ebb9411511dde951a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb0b7eeec1814e6ab5a7e8c0c701105e",
      "max": 608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24a67c04e0824c1baed82a66396223b6",
      "value": 608
     }
    },
    "225124f7f60c49a4bc218b0299701752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24a67c04e0824c1baed82a66396223b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e20ca46d0334a0ab3f2f2dc60a005ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31abb00576474a3b9a11ea0f06d41d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cb3e628e0c64da392f635d25c68be6b",
       "IPY_MODEL_1ad64543adeb474ebb9411511dde951a",
       "IPY_MODEL_f2c1f53924a7409c816b01308ccb9336"
      ],
      "layout": "IPY_MODEL_2e20ca46d0334a0ab3f2f2dc60a005ca"
     }
    },
    "3ad2d7515dee4ca4ac5d8d2f335adb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6eda298aaf44b9b914ef35a6a123531",
      "placeholder": "​",
      "style": "IPY_MODEL_11461a73263241bd8e2ad35a92e0c2dc",
      "value": " 2.46M/2.46M [00:00&lt;00:00, 27.0MB/s]"
     }
    },
    "4a7b1395942142918447f45464dcd3ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56706f8aac024e13846308140c44006d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59721f7c8561408c8fea78b29ad6be3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87aeb22ec9164278b1f1e2b23b959299",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c5108fe496048d39e8a14345c5f5d65",
      "value": 52
     }
    },
    "59cffec0648542bf98578314858763bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c26711cce0d49d6a401b9b5c6823345": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1e82949a1042b1b831bd86137f1375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_163bff609cfa453abc5879732e2220f0",
       "IPY_MODEL_59721f7c8561408c8fea78b29ad6be3d",
       "IPY_MODEL_7f2924ef022647f48f1c7e7be7700402"
      ],
      "layout": "IPY_MODEL_fd07562db6144a71a9910d3e343eceae"
     }
    },
    "5e389d23cc6b4642b289e7d9f933c9cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c5108fe496048d39e8a14345c5f5d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e62eee804a54b298728d6f6a21b9f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7343c5bf56714623a01c5594bb9a9aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f2924ef022647f48f1c7e7be7700402": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d5aed0313247339c19e9c75d548396",
      "placeholder": "​",
      "style": "IPY_MODEL_225124f7f60c49a4bc218b0299701752",
      "value": " 52.0/52.0 [00:00&lt;00:00, 3.40kB/s]"
     }
    },
    "87aeb22ec9164278b1f1e2b23b959299": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a972e443ff9481d896cac5bca478664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcea801bb91048a68bd1dfbefd8b0b93",
      "max": 2464616,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2ea734058bf4fc9a00cef248b73b9ab",
      "value": 2464616
     }
    },
    "8cb3e628e0c64da392f635d25c68be6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a7b1395942142918447f45464dcd3ce",
      "placeholder": "​",
      "style": "IPY_MODEL_5e389d23cc6b4642b289e7d9f933c9cb",
      "value": "config.json: 100%"
     }
    },
    "95e1a33c031e434bbd30fb0315ea8e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2c593b085534f8d8b148ab14be27b58",
       "IPY_MODEL_8a972e443ff9481d896cac5bca478664",
       "IPY_MODEL_3ad2d7515dee4ca4ac5d8d2f335adb33"
      ],
      "layout": "IPY_MODEL_0d36369356684e6aa06b7ada70e96ce0"
     }
    },
    "a4d5aed0313247339c19e9c75d548396": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb0b7eeec1814e6ab5a7e8c0c701105e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcea801bb91048a68bd1dfbefd8b0b93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e177f9d5aa7f4cd990ed6d81cff20cbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2ea734058bf4fc9a00cef248b73b9ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6eda298aaf44b9b914ef35a6a123531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2c1f53924a7409c816b01308ccb9336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e177f9d5aa7f4cd990ed6d81cff20cbf",
      "placeholder": "​",
      "style": "IPY_MODEL_6e62eee804a54b298728d6f6a21b9f98",
      "value": " 608/608 [00:00&lt;00:00, 39.3kB/s]"
     }
    },
    "f2c593b085534f8d8b148ab14be27b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c26711cce0d49d6a401b9b5c6823345",
      "placeholder": "​",
      "style": "IPY_MODEL_56706f8aac024e13846308140c44006d",
      "value": "spm.model: 100%"
     }
    },
    "fd07562db6144a71a9910d3e343eceae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
