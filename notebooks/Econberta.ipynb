{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e3a19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f2e3a19",
    "outputId": "8f636dfd-7040-479f-8ded-692a99f51824",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers torch transformers[torch] tokenizers huggingface_hub pytorch-crf checklist\n",
    "!pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4734ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "2e4734ec",
    "outputId": "7ce0f168-9f2b-459d-c287-3f661cddb410",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0bc84b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "9a0bc84b",
    "outputId": "feb3c753-6d26-4c70-c52b-7f2d70048f9d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: NVIDIA A100-SXM4-80GB MIG 2g.20gb, n_gpu: 1\n"
     ]
    }
   ],
   "source": [
    "device_name = torch.cuda.get_device_name()\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de59fcff",
   "metadata": {
    "id": "de59fcff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Ensure reproducibility\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf047882",
   "metadata": {},
   "source": [
    "### Set the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "XghB1AiHR2Aj",
   "metadata": {
    "id": "XghB1AiHR2Aj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the hyperparameters according to Table 8\n",
    "dropout = 0.2\n",
    "learning_rates = [5e-5, 6e-5, 7e-5]  # Perform hyperparameter search\n",
    "batch_size = 12\n",
    "gradient_accumulation_steps = 4\n",
    "weight_decay = 0\n",
    "max_epochs = 10\n",
    "lr_decay = \"slanted_triangular\"\n",
    "fraction_of_steps = 0.06\n",
    "adam_epsilon = 1e-8\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4d0ea2",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aGpCRa-oQq0K",
   "metadata": {
    "id": "aGpCRa-oQq0K",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_conll(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    current_sentence = []\n",
    "    current_labels = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                columns = line.split()\n",
    "                word, label = columns[0], columns[-1]\n",
    "                current_sentence.append(word)\n",
    "                current_labels.append(label)\n",
    "                \n",
    "                # Check if the current word is a sentence boundary\n",
    "                if word == '.' and label == 'O':\n",
    "                    sentences.append(' '.join(current_sentence))\n",
    "                    labels.append(current_labels)\n",
    "                    current_sentence = []\n",
    "                    current_labels = []\n",
    "\n",
    "    # Create a DataFrame from the accumulated sentences and labels\n",
    "    df = pd.DataFrame({\n",
    "        'sentences': sentences,\n",
    "        'labels': labels\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "BmsqGYy2TcHS",
   "metadata": {
    "id": "BmsqGYy2TcHS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "max_length=128\n",
    "\n",
    "def tokenize_and_format(sentences, tokenizer, max_length=max_length):\n",
    "    \"\"\"\n",
    "    Tokenizes sentences and returns formatted input IDs and attention masks.\n",
    "    \n",
    "    Parameters:\n",
    "    sentences: List of sentence strings to be tokenized.\n",
    "    tokenizer: Tokenizer instance used for tokenizing the sentences.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # Encode each sentence\n",
    "    for sentence in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=max_length,  # Adjust based on your model's maximum input length\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Store the input ID and the attention mask of this sentence\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert lists of tensors to single tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f177246f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# Define an enum for model names\n",
    "class ModelName(Enum):\n",
    "    BERT = 'google-bert/bert-base-uncased'\n",
    "    BERT_multilingual = 'google-bert/bert-base-multilingual-uncased'\n",
    "    ROBERTA = 'FacebookAI/roberta-base'\n",
    "    XLM_ROBERTA = 'FacebookAI/xlm-roberta-base'\n",
    "    MDEBERTA = 'microsoft/mdeberta-v3-base'\n",
    "    ECONBERTA_FC = 'worldbank/econberta'\n",
    "    ECONBERTA_FS = 'worldbank/econberta-fs'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99909061",
   "metadata": {},
   "source": [
    "### Select model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pjdFP9RFXkCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjdFP9RFXkCq",
    "outputId": "51858648-a4d7-47c0-b5ac-43272e38a953",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apathak2/.local/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = ModelName.ECONBERTA_FC.value\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wXPExdKtEXHh",
   "metadata": {
    "id": "wXPExdKtEXHh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'O': 0,\n",
    "    'B-intervention': 1,\n",
    "    'I-intervention': 2,\n",
    "    'B-outcome': 3,\n",
    "    'I-outcome': 4,\n",
    "    'B-population': 5,\n",
    "    'I-population': 6,\n",
    "    'B-effect_size': 7,\n",
    "    'I-effect_size': 8,\n",
    "    'B-coreference': 9,\n",
    "    'I-coreference': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa54038d-da7f-4fd3-9ad6-029a7c560f87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reverse_label_dict = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "A49f-HWiNCCm",
   "metadata": {
    "id": "A49f-HWiNCCm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_dataset(df, tokenizer, label_dict, max_length=max_length):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame to return a dataset suitable for training/testing an NER model.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame containing 'Tokens' and 'Labels' columns.\n",
    "    tokenizer: Tokenizer to use for encoding the sentences.\n",
    "    label_dict: Dictionary mapping label names to indices.\n",
    "    max_length: Maximum length of the tokenized input.\n",
    "    \"\"\"\n",
    "    sentences = df.sentences.values\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    input_ids, attention_masks = tokenize_and_format(sentences, tokenizer, max_length)\n",
    "\n",
    "    # Prepare labels\n",
    "    label_list = []\n",
    "    for labels in df.labels.values:\n",
    "        # Initialize a list to hold the encoded labels for each sentence\n",
    "        encoded_labels = [label_dict[label] for label in labels]\n",
    "        \n",
    "        # Truncate or pad the labels to match the max_length\n",
    "        encoded_labels = encoded_labels[:max_length]  # Truncate if needed\n",
    "        encoded_labels += [label_dict['O']] * (max_length - len(encoded_labels))  # Pad with 'O' if needed\n",
    "        \n",
    "        label_list.append(encoded_labels)\n",
    "\n",
    "    # Convert label_list to a tensor\n",
    "    labels = torch.tensor(label_list, dtype=torch.long)\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = [(input_ids[i], attention_masks[i], labels[i]) for i in range(len(df))]\n",
    "\n",
    "    return dataset, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Y73hwpVwOvCi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y73hwpVwOvCi",
    "outputId": "3042abbf-6575-47cd-e570-a94f3f930ea7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "train_df = read_conll('../data/econ_ie/train.conll')\n",
    "val_df = read_conll('../data/econ_ie/dev.conll')\n",
    "test_df = read_conll('../data/econ_ie/test.conll')\n",
    "\n",
    "train_set, train_sentences = get_dataset(train_df, tokenizer, label_dict)\n",
    "val_set, val_sentences = get_dataset(val_df, tokenizer, label_dict)\n",
    "test_set, test_sentences = get_dataset(test_df, tokenizer, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e4a2e9-180d-464c-8dcf-b868546574b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    1,   287,   376,  1263,  1770,   268, 11254,   264,  5685, 17736,\n",
       "           267,  4770,  3791,   263,  3922,   323,     2,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 1, 0, 0, 3, 4, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7129234f-176a-482a-9b8e-06b3a8997056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_entities(labels, tokens):\n",
    "    \"\"\"\n",
    "    Extract entities from token-label pairs.\n",
    "    \n",
    "    Args:\n",
    "    labels (list of int): List of label indices corresponding to each token.\n",
    "    tokens (list of str): List of tokens corresponding to each label index.\n",
    "    \n",
    "    Returns:\n",
    "    list of tuples: Each tuple represents an entity with (entity_type, start_index, end_index, entity_text).\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "        if label.startswith(\"B-\"):\n",
    "            if current_entity:\n",
    "                entities.append(current_entity)\n",
    "            entity_type = label.split(\"-\")[1]\n",
    "            current_entity = (entity_type, i, i, token)\n",
    "        elif label.startswith(\"I-\") and current_entity and label.split(\"-\")[1] == current_entity[0]:\n",
    "            current_entity = (current_entity[0], current_entity[1], i, current_entity[3] + \" \" + token)\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = None\n",
    "\n",
    "    if current_entity:\n",
    "        entities.append(current_entity)\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a900c6ef-2a3d-4e2d-8663-2f2228506f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_entity_level_metrics(true_entities, pred_entities):\n",
    "    metrics = {\"EM\": 0, \"EB\": 0, \"PM\": 0, \"PB\": 0, \"ML\": 0, \"FA\": 0}\n",
    "    true_matched = set()\n",
    "    pred_matched = set()\n",
    "\n",
    "    # Check for exact and partial matches\n",
    "    for i, true_entity in enumerate(true_entities):\n",
    "        for j, pred_entity in enumerate(pred_entities):\n",
    "            if j in pred_matched:\n",
    "                continue\n",
    "            if true_entity == pred_entity:\n",
    "                metrics[\"EM\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "            elif true_entity[0] == pred_entity[0] and is_overlapping((true_entity[1], true_entity[2]), (pred_entity[1], pred_entity[2])):\n",
    "                if true_entity[1] == pred_entity[1] and true_entity[2] == pred_entity[2]:\n",
    "                    metrics[\"EB\"] += 1\n",
    "                else:\n",
    "                    metrics[\"PM\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "            elif is_overlapping((true_entity[1], true_entity[2]), (pred_entity[1], pred_entity[2])):\n",
    "                metrics[\"PB\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "\n",
    "    # Check for missed labels (entities in true but not in pred)\n",
    "    for i, true_entity in enumerate(true_entities):\n",
    "        if i not in true_matched:\n",
    "            metrics[\"ML\"] += 1\n",
    "\n",
    "    # Check for false alarms (entities in pred but not in true)\n",
    "    for j, pred_entity in enumerate(pred_entities):\n",
    "        if j not in pred_matched:\n",
    "            metrics[\"FA\"] += 1\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421e8df6-4a33-4b28-8316-d5f5674575ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def is_overlapping(span1, span2):\n",
    "    \"\"\"\n",
    "    Check if two spans overlap.\n",
    "    Args:\n",
    "    span1, span2 (tuple): (start_index, end_index) of the span.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if spans overlap, False otherwise.\n",
    "    \"\"\"\n",
    "    assert len(span1) == 2 and len(span2) == 2, \"Each span must be a tuple of two elements (start_index, end_index)\"\n",
    "    start1, end1 = span1\n",
    "    start2, end2 = span2\n",
    "    return max(start1, start2) <= min(end1, end2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "882fb716-ce62-4e55-be8f-a7c6d6b9bbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-intervention': 1, 'I-intervention': 2, 'B-outcome': 3, 'I-outcome': 4, 'B-population': 5, 'I-population': 6, 'B-effect_size': 7, 'I-effect_size': 8, 'B-coreference': 9, 'I-coreference': 10}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90a7c0d6-e0d3-465f-8792-8cb1bb5b0981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def analyze_generalization(model, data, tokenizer, train_words):\n",
    "    grouped_entities = defaultdict(lambda: ([], []))  # {group_name: (true_entities, pred_entities)}        \n",
    "    groups=[]\n",
    "    mtrcs=[]\n",
    "\n",
    "    for i, (input_ids, attention_mask, label_tensor) in enumerate(data):\n",
    "        input_ids = input_ids.unsqueeze(0).to(device)\n",
    "        attention_mask = attention_mask.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Call model without labels to get the decoded labels\n",
    "        with torch.no_grad():\n",
    "            decoded_labels = model(input_ids, attention_mask=attention_mask)[\"decoded\"][0]\n",
    "            # No need to use argmax since CRF.decode returns the most likely tag sequence\n",
    "        \n",
    "        # Convert the decoded labels to label names using label_dict\n",
    "        pred_labels = [reverse_label_dict.get(label) for label in decoded_labels]\n",
    "\n",
    "        # Convert input_ids to tokens\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist(), skip_special_tokens=True)\n",
    "\n",
    "        # Assuming true_labels are provided in a similar structure\n",
    "        true_labels = [reverse_label_dict.get(l.item()) for l in label_tensor]\n",
    "        \n",
    "        # Preprocess entities for true and predicted labels\n",
    "        true_entities = preprocess_entities(true_labels, tokens)\n",
    "        pred_entities = preprocess_entities(pred_labels, tokens)\n",
    "        \n",
    "        for true_entity, pred_entity in zip(true_entities, pred_entities):\n",
    "            length = true_entity[2] - true_entity[1]\n",
    "\n",
    "            seen = any(word in train_words for word in true_entity[3].split())  # Check if any word in entity text was seen in training\n",
    "\n",
    "            group_name = f\"Length {length} - {'Seen' if seen else 'Unseen'}\"\n",
    "            grouped_entities[group_name][0].append(true_entity)\n",
    "            grouped_entities[group_name][1].append(pred_entity)\n",
    "    \n",
    "    for group_name, group_data in grouped_entities.items():\n",
    "        group_true_entities, group_pred_entities = group_data\n",
    "        metrics = compute_entity_level_metrics(group_true_entities, group_pred_entities)\n",
    "        print(f\"Group: {group_name}, Metrics: {metrics}\")\n",
    "        groups.append(group_name)\n",
    "        mtrcs.append(metrics)\n",
    "        \n",
    "    return groups, mtrcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b081af",
   "metadata": {},
   "source": [
    "## Eval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Fsd5u-jsp_N5",
   "metadata": {
    "id": "Fsd5u-jsp_N5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_validation_performance(val_set, model, device, label_dict, batch_size):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_loss = 0\n",
    "    all_pred_labels = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    num_batches = int(len(val_set) / batch_size) + (1 if len(val_set) % batch_size != 0 else 0)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        end_index = min(batch_size * (i + 1), len(val_set))\n",
    "        batch = val_set[i * batch_size:end_index]\n",
    "\n",
    "        if len(batch) == 0:\n",
    "            continue\n",
    "\n",
    "        input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "        input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "        label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = input_id_tensors.to(device)\n",
    "        b_input_mask = input_mask_tensors.to(device)\n",
    "        b_labels = label_tensors.to(device)\n",
    "        b_labels = b_labels.long()\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            logits = outputs[\"logits\"]\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Get the predicted labels\n",
    "            pred_labels = np.argmax(logits, axis=2).flatten()\n",
    "            true_labels = label_ids.flatten()\n",
    "\n",
    "            # Convert labels to their original names\n",
    "            pred_labels = [reverse_label_dict.get(label) for label in pred_labels]\n",
    "            true_labels = [reverse_label_dict.get(label) for label in true_labels]\n",
    "\n",
    "            # Filter out special tokens ('O' label is used for non-entity and special tokens)\n",
    "            filtered_pred_labels = [pred for pred, true in zip(pred_labels, true_labels) if true != 'O']\n",
    "            filtered_true_labels = [true for true in true_labels if true != 'O']\n",
    "            \n",
    "            # After filtering out special tokens\n",
    "            if not filtered_pred_labels or not filtered_true_labels:\n",
    "                print(\"Warning: No non-'O' labels found in this batch.\")\n",
    "            else:\n",
    "                all_pred_labels.extend(filtered_pred_labels)\n",
    "                all_true_labels.extend(filtered_true_labels)\n",
    "            \n",
    "    # After processing all batches, check if we have any labels to report on\n",
    "    if not all_true_labels or not all_pred_labels:\n",
    "        print(\"Error: No non-'O' labels found in the entire validation set.\")\n",
    "        default_labels = [list(label_dict.values())[0]]  # Use the first label as a placeholder\n",
    "        report = classification_report(default_labels, default_labels, digits=4, zero_division=0)\n",
    "    else:\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        report = classification_report(all_true_labels, all_pred_labels, digits=4, zero_division=0)\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c2c3d",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab0efc37-4ac5-41ee-81f5-66a99e012c08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "from transformers import AutoModel\n",
    "\n",
    "class CRFTagger(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        # Mask should be of type 'bool' in newer PyTorch versions\n",
    "        mask = attention_mask.type(torch.bool) if hasattr(torch, 'bool') else attention_mask.byte()\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = -self.crf(logits, labels, mask=mask, reduction='mean')\n",
    "            return {'loss': loss, 'logits': logits, 'decoded': self.crf.decode(logits, mask=mask)}\n",
    "        else:\n",
    "            decoded_labels = self.crf.decode(logits, mask=mask)\n",
    "            return {'decoded': decoded_labels, 'logits': logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eCm6d0FKqFSW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "eCm6d0FKqFSW",
    "outputId": "7a07ee72-afe7-453a-ba34-ef75a74a4b8c",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRFTagger(\n",
       "  (bert): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  (crf): CRF(num_tags=11)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = CRFTagger(model_name, len(label_dict))\n",
    "model.dropout = torch.nn.Dropout(dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc3f5649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_model_name(full_string):\n",
    "    # Split the string by the '/' character\n",
    "    parts = full_string.split('/')\n",
    "    if len(parts) == 2:\n",
    "        return parts[1]  # The second part is the model name\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model_name format. Actual: {full_string}, Expected: 'org_name/model_name'.\")  # Invalid format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ac358",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a6c0c-b1e6-4ff9-ab65-686e985a6460",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "import time\n",
    "\n",
    "# Calculate the total number of training steps\n",
    "total_steps = (len(train_set) // (batch_size * gradient_accumulation_steps)) * max_epochs\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Current learning rate: {lr}\")\n",
    "\n",
    "    # Create the optimizer with the specified hyperparameters\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, eps=adam_epsilon, betas=(adam_beta1, adam_beta2), weight_decay=weight_decay, no_deprecation_warning=True)\n",
    "\n",
    "    # Create the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * fraction_of_steps), num_training_steps=total_steps)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch_i in range(max_epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, max_epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        num_batches = int(len(train_set) / batch_size) + (1 if len(train_set) % batch_size != 0 else 0)\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            end_index = min(batch_size * (i + 1), len(train_set))\n",
    "            batch = train_set[i * batch_size:end_index]\n",
    "\n",
    "            if len(batch) == 0:\n",
    "                continue\n",
    "\n",
    "            input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "            input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "            label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "            b_input_ids = input_id_tensors.to(device)\n",
    "            b_input_mask = input_mask_tensors.to(device)\n",
    "            b_labels = label_tensors.long().to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Accumulate gradients\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimizer step after accumulating gradients for gradient_accumulation_steps\n",
    "            if (i + 1) % gradient_accumulation_steps == 0 or i == num_batches - 1:  # Ensure step is taken on the last batch\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "        print(f\"Total loss: {total_train_loss}\")\n",
    "        report = get_validation_performance(val_set, model, device, label_dict, batch_size)\n",
    "        print(report)\n",
    "        analyze_generalization(model, val_set, tokenizer, train_sentences)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Training complete at learning rate: {lr}!\")\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_name = extract_model_name(model_name)\n",
    "    print(f\"{model_name} model with lr {lr} saved at: {timestamp}\")\n",
    "    torch.save(model.state_dict(), f'../models/{model_name}_{lr}_{timestamp}.pth')\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bf1f7",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "003be45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "econberta\n",
      "7e-05\n"
     ]
    }
   ],
   "source": [
    "# Load variables for evaluation\n",
    "model_name = extract_model_name(model_name)\n",
    "print(model_name)\n",
    "lr = learning_rates[2]  # [5e-5, 6e-5, 7e-5]\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a97d7bc8-61b0-4cda-bd70-309d7b57b5af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load state_dict of the model\n",
    "model.load_state_dict(torch.load(f'../models/{model_name}_{lr}_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e7b47ed-5523-4097-b121-ed3156040f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8875    0.5018    0.6411       550\n",
      " B-effect_size     0.6686    0.3594    0.4675       320\n",
      "B-intervention     0.7324    0.5805    0.6477      1330\n",
      "     B-outcome     0.6894    0.5774    0.6284      1718\n",
      "  B-population     0.7564    0.6130    0.6772      1018\n",
      " I-coreference     0.0000    0.0000    0.0000        22\n",
      " I-effect_size     0.8259    0.4232    0.5597       482\n",
      "I-intervention     0.8688    0.6241    0.7264      2663\n",
      "     I-outcome     0.8853    0.5966    0.7128      3235\n",
      "  I-population     0.8762    0.5998    0.7121      1227\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.5819     12565\n",
      "     macro avg     0.6537    0.4433    0.5248     12565\n",
      "  weighted avg     0.8182    0.5819    0.6778     12565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_validation_performance(test_set, model, device, label_dict, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "182b32c6-b772-4fbf-ab3d-26186ae685db",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Length 3 - Unseen, Metrics: {'EM': 8, 'EB': 6, 'PM': 100, 'PB': 175, 'ML': 13, 'FA': 13}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 13, 'EB': 2, 'PM': 57, 'PB': 103, 'ML': 8, 'FA': 8}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 128, 'EB': 266, 'PM': 107, 'PB': 1076, 'ML': 80, 'FA': 80}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 41, 'EB': 20, 'PM': 148, 'PB': 286, 'ML': 22, 'FA': 22}\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 89, 'EB': 53, 'PM': 288, 'PB': 638, 'ML': 41, 'FA': 41}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 10, 'EB': 1, 'PM': 44, 'PB': 73, 'ML': 10, 'FA': 10}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 20, 'PB': 27, 'ML': 3, 'FA': 3}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 4, 'PB': 9, 'ML': 2, 'FA': 2}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 3, 'ML': 2, 'FA': 2}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 32, 'PB': 62, 'ML': 6, 'FA': 6}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 3, 'EB': 0, 'PM': 23, 'PB': 16, 'ML': 4, 'FA': 4}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 2, 'EB': 0, 'PM': 8, 'PB': 9, 'ML': 3, 'FA': 3}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 17 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 18 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 21 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 32 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 19 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 0, 'ML': 1, 'FA': 1}\n"
     ]
    }
   ],
   "source": [
    "lengths, metrics = analyze_generalization(model, test_set, tokenizer, train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd7a45",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be7fa71a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHwCAYAAACPE1g3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1TUlEQVR4nO3de9yUdZ3/8ddHxGA9r5AViJBpZaJkqB10ozOSomUqhCXl5q99aFpmJR3MDrtZ7ZrbVuu6qZgZpKalqZlbkZ3UPKB4yERDQc0DlkqCCX1+f1zXTcNwH+aCmXtm4PV8PObBXIe5rs/MPdz3e77zua4rMhNJkiRJjdmk3QVIkiRJ3cQALUmSJFVggJYkSZIqMEBLkiRJFRigJUmSpAoM0JIkSVIFBmhJDYuIGRHx4zbs9zURcXdELIuIgwdhf8si4oX9LL89IiY1eZ+LIuKNzdym2iMiZkfE5ys+5lcR8fIB1jkjIj61ftU1X0RsHxF3RsRz2l2LNFgM0FKblcFpeRnaHi7/+G7RAXWNjYiMiE175mXm+Zn55jaU81nga5m5RWZ+v35h3WvYc/taIxuOiHkR8c+188r93FsuXysMZebLMnPeOj+bFouIj0fEH8rXYUlEfLfdNQ2GiJgZEb/stn1GxIHAU5l5czl9SkQ8W/d+/mhmvj8zP7eO++j3A1pEbBYRF5XrZf0HxD5qeiFAZj4M/Aw4el1qk7qRAVrqDAdm5hbAnsBE4JP1K9QG2VYbzH01aEfg9gHWObAMvj23YwejsE4TEUcC7wLeWL6nJgI/aW9VGsD7gfPq5n237v38pf420KT/s78EjgD+2Mfy+prurVl2PvD/mlCD1BUM0FIHycwHgCuB3QDKkaBjIuJu4O5y3vsiYmFEPB4Rl0bEC3oeX65/XETcGxGPRcSXI2KTctkmEfHJiLgvIh6JiG9FxNblsp7R5qMi4n7gp8A15Wb/XI42vap+tC0iXh0Rv42IJ8p/X12zbF5EfK78avqpiPhxRIzo67n39bwi4h7ghcBlZR2VvibuqTki/j0i/lSOzO5fLvtXYD/ga7Wj1uVr8aKIOBqYAXy0XH5ZuXz1aF75up4UEfdExNKIuCAi/rFcNiwivl3O/3P5Gm3fT7l7RcQdZZ3nRMSwcju3laOUPc9paPnz7e0r/72AqzLzHoDM/GNmnlnz2K0j4qyIeCgiHoiIz0fEkHLZkPJ1eqx8Dx0TNd9C1I9ilqOS366ZfmVE/Lp8rrfUjmIO9H6IiH1rHrs4ImaW859T1nR/FN/QnBERw/t5DXsVES+JiKvL99ddEXFYzbLZEfH1iLi8rO26iNipZvmby8c8ERHfiIifR8Q/R8RLgTOAV5Xvjz/X7HLbvrZXV9dmwOuBnzfwHFZ/GxIRk6L4duFjEfFH4JyIGBERPyxfw8cj4hfl+/M8YAx//z/00fptZ+ZfM/P0zPwlsKqR17TOdcALI2LHdXis1HUM0FIHiYgdgCnAzTWzDwb2AXaNiNcDXwAOA54P3AfMrdvM2yhGHfcEDgLeW86fWd5eRxFItwDq2xxeC7wUeAvwT+W8bcrRpt/U1fqPwOXAV4HtgNOAyyNiu5rV3gm8B3gusBlwYh/Pu8/nlZk7Affz9xHmZ3rbxgD2Ae4CRgBfAs6KiMjMTwC/AI7tbdS6DJ7nA18qlx9Yv2HgAxQ/o9cCLwD+BHy9XHYksDWwA8Vr9H5geT91zqB47XcCduHv30R8i2JksMcU4KGer/zrXAu8OyI+EhETe8JxjdnASuBFwMuBNwM9LSzvAw4o508E3tFPrWuIiFEU74fPA/9I8bP+XkSMrFmt1/dDGbquBP4LGAlMAOaXjzmV4rWYUNY8Cji50brK7W8OXA18p9z3NOAbEbFrzWrTgM8A2wILgX8tHzsCuAiYRfEzvAt4NUBm3knxM/1N+f7YZqDt9WJn4G+ZuaTKcyo9j+K13pGifeLDwBKK13B74ONFmfku1vw/1O9odj8OLIP57RHxL7ULMnMlxfPcYx23LXUVA7TUGb5fjl79kmIk6t9qln0hMx/PzOUUAevszLypDJKzKEa/xtas/8Vy/fuB04Hp5fwZwGmZeW9mLisfOy3W/Or3lMz8S7mvgbwVuDszz8vMlZk5B/gdUBsyz8nM35fbu4AiBPWmkec1kO+XI289t/fVLLsvM/83M1cB51KE9P5Ggqt4P/CJzFxS1n4K8I7ydX2WInS9KDNXZeaNmflkP9v6WmYuzszHKQJXz8/u28CUiNiqnH4Xa3/lD0Bmfpsi1L+F4r30SER8DIqDvSjC9wfLn/MjwFcowh4UH2BOr6nhCxVehyOAKzLzisz8W2ZeDdxQ7q9HX++HdwL/l5lzMvPZzFyamfMjIiiC4YfK9/RTFP83plHNAcCizDynfK/eDHwPOLRmnUsy8/oyCJ5fU9sU4PbMvLhc9lX6bnGo1df26m0DPNXL/MPq3s8v6GWdvwGfzsxnytf0WYr39o7l6/iLzMwGam3EBRQfrkdSfNA6OSKm163zVPl8pA1ep/U5ShurgzPz//pYtrjm/guAm3omMnNZRCylGJVb1Mv695WP6XnsfXXLNmXNIFn72IHUb69nm6NqpmuDxtMUo959bWug5zWQ/l7D1XVk5tNFLuuzlqp2BC6JiL/VzFtF8bqeRzH6PDcitqEIwp/IzGf72FavP7vMfDAifgUcEhGXAPsDx/dVUGaeD5wfEUMpRsfPj4j5FKPjQ4GHytcAioGUnv2+oJcaGrUjcGjUtJqU+/pZzXRf74cdgHt62eZI4B+AG2vqDaB+VL2R2vapa7HYlDU/hPRV2xqvSWZmRDQyWtzoe/9PwJa9zL8gM2u/daDmNejxaGauqJn+MsUHuB+X656Zmac2UOuAMvOOmslfR8R/UnxDMadm/pbAn5uxP6nTOQItdb7aEaQHKcIAsPqr6e2AB2rW2aHm/pjyMWs9tly2Eni4j30NNHJVv72ebT7Qy7oDaeR5tcpAz3Og5YuB/TNzm5rbsMx8oBwF/Exm7krxtf8BwLv72VZfPzsoRs6PoBg1/U3ZL99/4cX+LwRupeirXww8A4yoqXWrzHxZ+ZCHeqmh1l8oAm2P59XcXwycV/c6bN5ggFtM0bZS7zGKlpeX1Wxz6ywOjqxiMfDzutq2yMx/GfCRxWsyumeiHBUfXbN8fUd4F5abHTXgmmtbY9+Z+VRmfjgzXwhMBU6IiDc0qc7e9v33TzXFNy4vAm5p8n6kjmSAlrrLHOA9ETEhioPp/g24LjMX1azzkYjYtuynPh74bs1jPxQR46I4Td6/URxVv7KPfT1K8RVxX+dDvgLYJSLeGRGbRsThwK7AD1v0vFrlYfp+jo0sPwP4156DpyJiZEQcVN5/XUSML/uQn6T4iv1vfW+KYyJidNlf/gn+/rMD+D5FX/vxFD3RvYrioMm3RsSW5QFk+wMvo3g9HwJ+DPxHRGxVLt8pIl5bPvwC4Liyhm2Bk+o2P5+i7WdoRNT3SH+bokf2LVEcjDisPNBtNAM7H3hjRBxWvpe2i4gJmfk34H+Br0TEc8vnNyoi3tLPtqLc9+obxXtyl4h4V1n70IjYK4qDAAdyOTA+Ig4uQ+IxrPnB4WFgdBQHA1aWmX8F/o+ih369RMQBURz8GsATFN+E9LzfBnof9xywOayc3Kx8/aJcdlD5eyUiYm/gOOAHNQ/fm6JNpsq3FlLXMkBLXaRsUfgURf/mQxSjdvX9oD8AbqQIO5cDZ5Xzz6b4yvoa4A/ACope2b729TRFH+6vyh7MV9YtX0oxovphYCnwUeCAzHysRc9rID1nGOi5XdLg4/6Tomf5TxHx1V6Wn0VxAOefI+L7fTz+UoqvzZ+iOIhvn3LZ8ygOQHsSuJOiJ7nX3uXSdygC7r0ULQ2rzz9d9rh+DxgHXNzPNp6kOHjsfoqv078E/EsWZ1eAYgR8M+AOivaBiyj6ZqEIq1dRjCLe1Mt+PkXxs/kTxQFy36mpbzHFQasfp/jwtRj4CA38nSn79adQvJcep3jv9hyM9jGKUdprI+JJirD54n4292qKUev625sp3lMPUrRXfBEY8Iwu5fv5UIrXcSnFh8QbKEbyoThjze3AHyOi8nu/9D8Ufe3ra2eK12cZ8BvgG5nZ00LzBeCT5fu414N5KQ6QXE7ROnVVeb/nm6FpFD+Hpyg+wH0xM8+teewMig+T0kYhmnd8gaR2i4gEds7Mhe2uRc0XEScDu9T3xrZwf2MpPmwN7eebio1KFKeFXALMqAmnzdjuryjOBtPbmVU6WvntwM+Bl9f1ZEsbLA8ilKQuULZ1HEVzRipVQdkych3FiOxHKHp/r23mPjLzNc3c3mAqz+bSSDuMtMGwhUOSOlwUp+RbDFyZmdcMtL6a7lUULTWPUZym8eBs7FSPkjZQtnBIkiRJFTgCLUmSJFVggJYkSZIq6LqDCEeMGJFjx45tdxmSJEnawN14442PZebI+vldF6DHjh3LDTfc0O4yJEmStIGLiF4vDmQLhyRJklSBAVqSJEmqwAAtSZIkVdB1PdCSJEnqDM8++yxLlixhxYruvor7sGHDGD16NEOHDm1ofQO0JEmS1smSJUvYcsstGTt2LBHR7nLWSWaydOlSlixZwrhx4xp6jC0ckiRJWicrVqxgu+2269rwDBARbLfddpVG0Q3QkiRJWmfdHJ57VH0OBmhJkiR1rSFDhjBhwoTVt1NPPRWASZMmMWbMGDJz9boHH3wwW2yxxXrv0x5oSZIkNcXYky5v6vYWnfrWAdcZPnw48+fP73XZNttsw69+9Sv23Xdf/vznP/PQQw81pS5HoCVJkrRBmjZtGnPnzgXg4osv5u1vf3tTtmuAliRJUtdavnz5Gi0c3/3ud1cve8Mb3sA111zDqlWrmDt3LocffnhT9mkLhyRJkrpWfy0cQ4YMYd9992Xu3LksX76csWPHNmWfjkBLkiRpgzVt2jSOO+44DjvssKZt0wAtSZKkDdZ+++3HrFmzmD59etO2aQuHJEmSulZPD3SPyZMnrz6VHRTneD7xxBObuk8DtCRJkpqikdPONduqVat6nT9v3rxe5y9btmy992kLhyRJklSBAVqSJEmqwAAtSZIkVWAPtCRJquSyyy5rdwkceOCB/S63xsYMVKN65wi0JEmSVIEBWpIkSarAAC1JkqSuNWTIECZMmLD61nMO6EmTJvHiF7+YCRMm8NKXvpQzzzyzafu0B1qSJEnNccrWTd7eEwOuMnz4cObPn9/rsvPPP5+JEyfy+OOPs9NOOzFz5kw222yz9S7LEWhJkiRt0JYtW8bmm2/OkCFDmrI9R6AlSZLUteov5T1r1iwOP/xwAGbMmMFznvMc7r77bk4//XQDtCRJktRIC8ejjz7Kq1/9aiZPnsyOO+643vu0hUOSJEkbtJEjR7Lnnnty3XXXNWV7BmhJkiRt0J5++mluvvlmdtppp6ZszxYOSZIkda36HujJkyevPpXdjBkzGD58OM888wwzZ87kFa94RVP2aYCWJElSczRw2rlmW7VqVa/z582b17J9tqyFIyLOjohHIuK2PpbPiIhbI2JBRPw6IvZoVS2SJElSs7SyB3o2MLmf5X8AXpuZ44HPAc27PIwkSZLUIi1r4cjMayJibD/Lf10zeS0wulW1SJIkSc3SKWfhOAq4st1FSJIkSQNp+0GEEfE6igC9bz/rHA0cDTBmzJhBqkySJElaW1tHoCNid+CbwEGZubSv9TLzzMycmJkTR44cOXgFSpIkSXXaFqAjYgxwMfCuzPx9u+qQJElS9xoyZAgTJkxgt91249BDD+Xpp58GICI44ogjVq+3cuVKRo4cyQEHHLDe+2xZC0dEzAEmASMiYgnwaWAoQGaeAZwMbAd8IyIAVmbmxFbVI0mSpNYaf+74pm5vwZELBlxn+PDhzJ8/HygunHLGGWdwwgknsPnmm3PbbbexfPlyhg8fztVXX82oUaOaUlfLRqAzc3pmPj8zh2bm6Mw8KzPPKMMzmfnPmbltZk4ob4ZnSZIkrbP99tuPhQsXrp6eMmUKl19+OQBz5sxh+vTpTdlPp5yFQ5IkSVpnK1eu5Morr2T8+L+Pgk+bNo25c+eyYsUKbr31VvbZZ5+m7KvtZ+GQJEmS1tXy5cuZMGECUIxAH3XUUauX7b777ixatIg5c+YwZcqUpu3TAC1JkqSuVdsD3ZupU6dy4oknMm/ePJYu7fOkb5UYoCVJkrTBeu9738s222zD+PHjmTdvXlO2aQ+0JEmSNlijR4/muOOOa+o2HYGWJElSUzRy2rlmW7ZsWcPzJ02axKRJk9Z7n45AS5IkSRUYoCVJkqQKDNCSJElSBQZoSZIkqQIDtCRJklSBAVqSJEmqwAAtSZKkrjVkyBAmTJjAbrvtxqGHHsrTTz+9xvw99tiDPffck1//+tdN26fngZYkSVJT3PmSlzZ1ey/93Z0DrlN7Ke8ZM2ZwxhlncMIJJ6wx/6qrrmLWrFn8/Oc/b0pdjkBLkiRpg7DffvuxcOHCteY/+eSTbLvttk3bjyPQkiRJ6norV67kyiuvZPLkyQAsX76cCRMmsGLFCh566CF++tOfNm1fBmhJ0kbjsssua3cJHHjgge0uQdqg9ARlKEagjzrqKGDN1o7f/OY3vPvd7+a2224jItZ7nwZoSZI6iCFfqqY2KPflVa96FY899hiPPvooz33uc9d7n/ZAS5IkaYP2u9/9jlWrVrHddts1ZXuOQEuSJGmDU9vakZmce+65DBkypCnbNkBLkiSpKRo57VyzLVu2rNf5q1atatk+beGQJEmSKjBAS5IkSRUYoCVJkqQKDNCSJElSBQZoSZIkqQIDtCRJklSBAVqSJEldKyI44ogjVk+vXLmSkSNHcsABBwAwe/Zsjj322Kbu0/NAS5IkqSm+/v6fNnV7x5zx+gHX2XzzzbnttttYvnw5w4cP5+qrr2bUqFFNraOeI9CSJEnqalOmTOHyyy8HYM6cOUyfPr2l+zNAS5IkqatNmzaNuXPnsmLFCm699Vb22Weflu7PAC1JkqSutvvuu7No0SLmzJnDlClTWr4/e6AlSZLU9aZOncqJJ57IvHnzWLp0aUv3ZYCWJDXFZZdd1u4SOPDAA9tdgqQ2ee9738s222zD+PHjmTdvXkv3ZQuHJEmSut7o0aM57rjjel02e/ZsRo8evfq2ZMmS9dqXI9CSJElqikZOO9dsy5YtW2vepEmTmDRpEgAzZ85k5syZTd2nI9CSJElSBY5AS2oZe2IlSRsiR6AlSZKkCgzQkiRJUgUGaEmSJKkCA7QkSZJUgQcRStqodcuBju2u04MxJXWqIUOGMH78+NXT3//+9xk7diynn346J510Eg8//DBbb711U/dpgJYkSVJTNPvDfiMf3ocPH878+fPXmj9nzhz22msvLr74Yt7znvc0tS5bOCRJkrRBueeee1i2bBmf//znmTNnTtO37wh0Be3+ChX8GlWSJKnW8uXLmTBhAgDjxo3jkksuYe7cuUybNo399tuPu+66i4cffpjtt9++afs0QEuSJKlr9dbCMWfOHC655BI22WQTDjnkEC688EKOPfbYpu3TAK1B1w0j+dbYGL8RkSR1mgULFnD33Xfzpje9CYC//vWvjBs3rqkB2h5oSZIkbTDmzJnDKaecwqJFi1i0aBEPPvggDz74IPfdd1/T9uEI9AbGUUlJkrQxmzt3LldcccUa8972trcxd+5cPvaxjzVlHwZoSZIkNUU7BtGWLVu2xvS999671jqnnXZaU/dpC4ckSZJUgQFakiRJqsAALUmSJFVggJYkSdI6y8x2l7Deqj4HA7QkSZLWybBhw1i6dGlXh+jMZOnSpQwbNqzhx3gWDkmSJK2T0aNHs2TJEh599NF2l7Jehg0bxujRoxte3wAtSZKkdTJ06FDGjRvX7jIGXctaOCLi7Ih4JCJu62N5RMRXI2JhRNwaEXu2qhZJkiSpWVrZAz0bmNzP8v2Bncvb0cB/t7AWSZIkqSlaFqAz8xrg8X5WOQj4VhauBbaJiOe3qh5JkiSpGdrZAz0KWFwzvaSc91D9ihFxNMUoNWPGjBmU4npz/+Wbt23fqw1whUxrbJA1Noc1NkcDV75te53dUCNsED9va2yQNTbHADWOP3f84NTRjwVHLmh3CWvpitPYZeaZmTkxMyeOHDmy3eVIkiRpI9bOAP0AsEPN9OhyniRJktSx2hmgLwXeXZ6N45XAE5m5VvuGJEmS1Ela1gMdEXOAScCIiFgCfBoYCpCZZwBXAFOAhcDTwHtaVYskSZLULC0L0Jk5fYDlCRzTqv1LkiRJrdAVBxFKkiRJncIALUmSJFVggJYkSZIqMEBLkiRJFRigJUmSpAoM0JIkSVIFBmhJkiSpgpadB1rt8fp5nXBq7TvbXYAkSVLLOAItSZIkVeAItAZdN4ySW2Oj/LZBkrTxMUBXYGCRJEmSLRySJElSBQZoSZIkqQIDtCRJklSBPdCSNmrdcmxD++v0+AtJ6uEItCRJklSBAVqSJEmqwAAtSZIkVWAPtKSWaX/fLti7K0lqNkegJUmSpAoM0JIkSVIFBmhJkiSpAgO0JEmSVIEHEUqSmsKDRiVtLByBliRJkiowQEuSJEkVGKAlSZKkCgzQkiRJUgUGaEmSJKkCA7QkSZJUgQFakiRJqsAALUmSJFVggJYkSZIqMEBLkiRJFRigJUmSpAoM0JIkSVIFBmhJkiSpAgO0JEmSVIEBWpIkSapg03YXIEmS/u71845pdwnAne0uQOpoBmhJ0kbDcCqpGWzhkCRJkiowQEuSJEkVGKAlSZKkCgzQkiRJUgUGaEmSJKkCA7QkSZJUgQFakiRJqsAALUmSJFVggJYkSZIqMEBLkiRJFRigJUmSpAoM0JIkSVIFBmhJkiSpAgO0JEmSVIEBWpIkSarAAC1JkiRVUClAR8QmEbFVhfUnR8RdEbEwIk7qZfmYiPhZRNwcEbdGxJQq9UiSJEmDbcAAHRHfiYitImJz4Dbgjoj4SAOPGwJ8Hdgf2BWYHhG71q32SeCCzHw5MA34RtUnIEmSJA2mRkagd83MJ4GDgSuBccC7Gnjc3sDCzLw3M/8KzAUOqlsngZ4R7a2BBxspWpIkSWqXRgL00IgYShGgL83MZymC70BGAYtrppeU82qdAhwREUuAK4APNLBdSZIkqW0aCdD/AywCNgeuiYgdgSebtP/pwOzMHA1MAc6LiLVqioijI+KGiLjh0UcfbdKuJUmSpOoGDNCZ+dXMHJWZU7JwH/C6Brb9ALBDzfTocl6to4ALyv38BhgGjOilhjMzc2JmThw5cmQDu5YkSZJao5GDCLePiLMi4spyelfgyAa2/Vtg54gYFxGbURwkeGndOvcDbyi3+1KKAO0QsyRJkjpWIy0cs4GrgBeU078HPjjQgzJzJXBs+dg7Kc62cXtEfDYipparfRh4X0TcAswBZmZmI/3VkiRJUlts2sA6IzLzgoiYBUUwjohVjWw8M6+gODiwdt7JNffvAF5ToV5JkiSprRoZgf5LRGxHeeaNiHgl8ERLq5IkSZI6VCMj0CdQ9C7vFBG/AkYC72hpVZIkSVKHGjBAZ+ZNEfFa4MVAAHeV54KWJEmSNjp9BuiIeH1m/jQi3l63aJeIIDMvbnFtkiRJUsfpbwT6tcBPgQN7WZaAAVqSJEkbnT4DdGZ+urz72cz8Q+2yiBjX0qokSZKkDtXIWTi+18u8i5pdiCRJktQN+uuBfgnwMmDruj7orSiuGChJkiRtdPrrgX4xcACwDWv2QT8FvK+FNUmSJEkdq78e6B8AP4iIV2XmbwaxJkmSJKlj9dfC8dHM/BLwzoiYXr88M49raWWSJElSB+qvhePO8t8bBqMQSZLUHV4/75h2l8DfY0rvznjV8YNUR9+OYUG/y7uhRvWuvxaOy8q7T2fmhbXLIuLQllYlSZIkdahGTmM3q8F5kiRJ0gavvx7o/YEpwKiI+GrNoq2Ala0uTJIkSepE/fVAP0jR/zwVuLFm/lPAh1pZlCRJktSp+uuBvgW4JSK+k5nPDmJNkiRJUsfqbwS6x94RcQqwY7l+AJmZL2xlYZIkSVInaiRAn0XRsnEjsKq15UiSJEmdrZEA/URmXtnySiRJkqQu0EiA/llEfBm4GHimZ2Zm3tSyqiRJkqQO1UiA3qf8d2LNvARe3/xyJEmSpM42YIDOzNcNRiGSJElSN+jzSoQRcXrN/ePrls1uXUmSJElS5+rvUt7/VHP/yLplu7egFkmSJKnj9Rego4/7kiRJ0karvx7oTSJiW4qQ3XO/J0gPaXllkiRJUgfqL0BvTXHxlJ7QXHvaumxZRZIkSVIH6zNAZ+bYQaxDkiRJ6gr99UBLkiRJqmOAliRJkiro7zzQ4wazEEmSJKkb9DcCfRFARPxkkGqRJEmSOt5Ap7H7OLBLRJxQvzAzT2tdWZIkSVJn6m8EehqwiiJkb9nLTZIkSdro9Hcau7uAL0bErZl55SDWJEmSJHWsRs7C8euIOC0ibihv/xERW7e8MkmSJKkDNRKgzwaeAg4rb08C57SyKEmSJKlT9XcQYY+dMvOQmunPRMT8FtUjSZIkdbRGRqCXR8S+PRMR8RpgeetKkiRJkjpXIyPQ7we+VdP3/CfgyNaVJEmSJHWuAQN0Zt4C7BERW5XTT7a8KkmSJKlDNTICDRicJUmSJGisB1qSJElSyQAtSZIkVdBQC0dEvBoYW7t+Zn6rRTVJkiRJHWvAAB0R5wE7AfOBVeXsBAzQkiRJ2ug0MgI9Edg1M7PVxUiSJEmdrpEe6NuA57W6EEmSJKkbNDICPQK4IyKuB57pmZmZU1tWlSRJktShGgnQp7S6CEmSJKlbNHIlwp9HxPbAXuWs6zPzkdaWJUmSJHWmAXugI+Iw4HrgUOAw4LqIeEerC5MkSZI6USMtHJ8A9uoZdY6IkcD/ARe1sjBJkiSpEzVyFo5N6lo2ljb4OEmSJGmD08gI9I8i4ipgTjl9OHBF60qSJEmSOlcjBxF+JCIOAV5TzjozMy9pbVmSJElSZ2pkBJrM/B7wvaobj4jJwH8CQ4BvZuapvaxzGMWp8hK4JTPfWXU/kiRJ0mDpM0BHxC8zc9+IeIoi3K5eBGRmbtXfhiNiCPB14E3AEuC3EXFpZt5Rs87OwCzgNZn5p4h47no8F0mSJKnl+gzQmblv+e+W67jtvYGFmXkvQETMBQ4C7qhZ533A1zPzT+W+PL+0JEmSOloj54E+r5F5vRgFLK6ZXlLOq7ULsEtE/Coiri1bPiRJkqSO1UgP9MtqJyJiU+AVTdz/zsAkYDRwTUSMz8w/1+3zaOBogDFjxjRp15IkSVJ1fY5AR8Sssv9594h4srw9BTwM/KCBbT8A7FAzPbqcV2sJcGlmPpuZfwB+TxGo15CZZ2bmxMycOHLkyAZ2LUmSJLVGnwE6M78AbA18KzO3Km9bZuZ2mTmrgW3/Ftg5IsZFxGbANODSunW+TzH6TESMoGjpuLf605AkSZIGR7890Jn5N2CvddlwZq4EjgWuAu4ELsjM2yPisxExtVztKmBpRNwB/Az4SGYuXZf9SZIkSYOhkR7omyJir8z8bdWNZ+YV1F21MDNPrrmfwAnlTZIkSep4jQTofYAZEXEf8Bf+fh7o3VtamSRJktSBGgnQb2l5FZIkSVKXGPA80Jl5H7ANcGB526acJ0mSJG10GrmQyvHA+cBzy9u3I+IDrS5MkiRJ6kSNtHAcBeyTmX8BiIgvAr8B/quVhUmSJEmdaMARaIqDBlfVTK8q50mSJEkbnUZGoM8BrouISyiC80HAWS2tSpIkSepQAwbozDwtIuYB+wIJvCczb251YZKk7nLYrEbGZFprQbsLkLRRaKSFo0fU/StJkiRtdBo5C8fJwLnAtsAI4JyI+GSrC5MkSZI6USPft80A9sjMFQARcSowH/h8C+uSJEmSOlIjLRwPAsNqpp8DPNCaciRJkqTO1sgI9BPA7RFxNcVBhG8Cro+IrwJk5nEtrE+SJEnqKI0E6EvKW495rSlFkiRJ6nyNnMbu3IjYDNilnHVXZj7b2rIkSZKkzjRggI6ISRRn4VhEcQq7HSLiyMy8pqWVSZIkSR2okRaO/wDenJl3AUTELsAc4BWtLEySJEnqRI2chWNoT3gGyMzfA0NbV5IkSZLUuRoZgb4xIr4JfLucngHc0LqSJEmSpM7VSIB+P3AM0HO6ul8A32hZRZIkSVIH6zdAR8QQ4JbMfAlw2uCUJEmSJHWufnugM3MVcFdEjBmkeiRJkqSO1kgLx7YUVyK8HvhLz8zMnNqyqiRJkqQO1UiA/lTLq5AkSZK6RJ8BOiKGURxA+CJgAXBWZq4crMIkSZKkTtRfD/S5wESK8Lw/xQVVJEmSpI1afy0cu2bmeICIOAu4fnBKkiRJkjpXfyPQz/bcsXVDkiRJKvQ3Ar1HRDxZ3g9geDkdQGbmVi2vTpIkSeowfQbozBwymIVIkiRJ3aDfC6lIkiRJWpMBWpIkSarAAC1JkiRVYICWJEmSKjBAS5IkSRUYoCVJkqQKDNCSJElSBQZoSZIkqQIDtCRJklSBAVqSJEmqwAAtSZIkVWCAliRJkiowQEuSJEkVbNruAiRJGiyHzWr/n70F7S5A0npzBFqSJEmqwAAtSZIkVWCAliRJkiowQEuSJEkVGKAlSZKkCgzQkiRJUgUGaEmSJKkCA7QkSZJUgQFakiRJqsAALUmSJFVggJYkSZIqMEBLkiRJFRigJUmSpAoM0JIkSVIFLQ3QETE5Iu6KiIURcVI/6x0SERkRE1tZjyRJkrS+WhagI2II8HVgf2BXYHpE7NrLelsCxwPXtaoWSZIkqVk2beG29wYWZua9ABExFzgIuKNuvc8BXwQ+0sJa1EEOm9XKt11jFrS7AEmS1LVamWRGAYtrppcA+9SuEBF7Ajtk5uUR0WeAjoijgaMBxowZ04JSJamztfuDpx86Jenv2vYbOSI2AU4DZg60bmaeCZwJMHHixGxtZZKapd2hDwx+kqTma+VftweAHWqmR5fzemwJ7AbMiwiA5wGXRsTUzLyhhXVJGwTDqSRJ7dHKs3D8Ftg5IsZFxGbANODSnoWZ+URmjsjMsZk5FrgWMDxLkiSpo7VsCCszV0bEscBVwBDg7My8PSI+C9yQmZf2vwWtC0clJUmSWqulaSszrwCuqJt3ch/rTmplLZIkSVIzeCVCSZIkqQIDtCRJklRB+xtmpQ5kL7kkSepL+1OCJEnqKg4yaGNnC4ckSZJUgQFakiRJqsAALUmSJFVggJYkSZIqMEBLkiRJFRigJUmSpAoM0JIkSVIFBmhJkiSpAgO0JEmSVIEBWpIkSarAAC1JkiRVYICWJEmSKjBAS5IkSRUYoCVJkqQKDNCSJElSBQZoSZIkqQIDtCRJklTBpu0uQJLa6bBZ7f81uKDdBUiSKnEEWpIkSarAAC1JkiRVYICWJEmSKjBAS5IkSRUYoCVJkqQK2n/4eRfxaH1JkiQ5Ai1JkiRVYICWJEmSKjBAS5IkSRUYoCVJkqQKDNCSJElSBQZoSZIkqQIDtCRJklSBAVqSJEmqwAAtSZIkVWCAliRJkipo/7WpJUnSaofNav+f5gXtLkDqcI5AS5IkSRUYoCVJkqQKDNCSJElSBQZoSZIkqQIDtCRJklSBAVqSJEmqwAAtSZIkVWCAliRJkiowQEuSJEkVtP9yR11kwR/ub3cJkiRJajNHoCVJkqQKDNCSJElSBQZoSZIkqQIDtCRJklSBAVqSJEmqwAAtSZIkVWCAliRJkiowQEuSJEkVtDRAR8TkiLgrIhZGxEm9LD8hIu6IiFsj4icRsWMr65EkSZLWV8sCdEQMAb4O7A/sCkyPiF3rVrsZmJiZuwMXAV9qVT2SJElSM7RyBHpvYGFm3puZfwXmAgfVrpCZP8vMp8vJa4HRLaxHkiRJWm+tDNCjgMU100vKeX05CriyhfVIkiRJ623TdhcAEBFHABOB1/ax/GjgaIAxY8YMYmWSJEnSmlo5Av0AsEPN9Ohy3hoi4o3AJ4CpmflMbxvKzDMzc2JmThw5cmRLipUkSZIa0coA/Vtg54gYFxGbAdOAS2tXiIiXA/9DEZ4faWEtkiRJUlO0LEBn5krgWOAq4E7ggsy8PSI+GxFTy9W+DGwBXBgR8yPi0j42J0mSJHWElvZAZ+YVwBV1806uuf/GVu5fkiRJajavRChJkiRVYICWJEmSKjBAS5IkSRUYoCVJkqQKDNCSJElSBQZoSZIkqQIDtCRJklSBAVqSJEmqwAAtSZIkVWCAliRJkiowQEuSJEkVGKAlSZKkCgzQkiRJUgUGaEmSJKkCA7QkSZJUgQFakiRJqsAALUmSJFVggJYkSZIq2LTdBai5Fvzh/naXIEmStEFzBFqSJEmqwAAtSZIkVWCAliRJkiqwB1qDzj5tSZLUzRyBliRJkiowQEuSJEkVGKAlSZKkCgzQkiRJUgUGaEmSJKkCA7QkSZJUgQFakiRJqsAALUmSJFXghVQkSRuNp+48td0lSNoAOAItSZIkVWCAliRJkiqwhWMDM3bFd9pdAovaXcBGYsEf7m93CQPqhholSarKAF2B4bQ5fB0lSVI3s4VDkiRJqsARaKlLdcNIfjfUKElSVY5AS5IkSRU4Ai1JagrPsSxpY+EItCRJklSBAVqSJEmqwAAtSZIkVWCAliRJkiowQEuSJEkVeBYOqRdeglqSJPXFEWhJkiSpAgO0JEmSVIEBWpIkSarAAC1JkiRVYICWJEmSKjBAS5IkSRV4GjupF2NXfKfdJbCo3QVIkqReOQItSZIkVWCAliRJkiowQEuSJEkVGKAlSZKkCloaoCNickTcFRELI+KkXpY/JyK+Wy6/LiLGtrIeSZIkaX21LEBHxBDg68D+wK7A9IjYtW61o4A/ZeaLgK8AX2xVPZIkSVIztHIEem9gYWbem5l/BeYCB9WtcxBwbnn/IuANEREtrEmSJElaL60M0KOAxTXTS8p5va6TmSuBJ4DtWliTJEmStF4iM1uz4Yh3AJMz85/L6XcB+2TmsTXr3Faus6Scvqdc57G6bR0NHF1Ovhi4qyVFt94I4LEB12ova2yObqgRuqNOa2wOa2wOa2yebqjTGpujG2rsy46ZObJ+ZiuvRPgAsEPN9OhyXm/rLImITYGtgaX1G8rMM4EzW1TnoImIGzJzYrvr6I81Nkc31AjdUac1Noc1Noc1Nk831GmNzdENNVbVyhaO3wI7R8S4iNgMmAZcWrfOpcCR5f13AD/NVg2JS5IkSU3QshHozFwZEccCVwFDgLMz8/aI+CxwQ2ZeCpwFnBcRC4HHKUK2JEmS1LFa2cJBZl4BXFE37+Sa+yuAQ1tZQ4fphjYUa2yObqgRuqNOa2wOa2wOa2yebqjTGpujG2qspGUHEUqSJEkbIi/lLUmSJFVggB4kA13WvN0i4uyIeKQ8tWBHiogdIuJnEXFHRNweEce3u6Z6ETEsIq6PiFvKGj/T7pr6EhFDIuLmiPhhu2vpTUQsiogFETE/Im5odz29iYhtIuKiiPhdRNwZEa9qd031IuLF5WvYc3syIj7Y7rrqRcSHyv8zt0XEnIgY1u6a6kXE8WV9t3fKa9jb7+6I+MeIuDoi7i7/3bYDazy0fB3/FhFtPztDHzV+ufy/fWtEXBIR27SxxJ6aeqvzc2WN8yPixxHxgk6rsWbZhyMiI2JEO2prJgP0IGjwsubtNhuY3O4iBrAS+HBm7gq8EjimA1/HZ4DXZ+YewARgckS8sr0l9el44M52FzGA12XmhA4+/dF/Aj/KzJcAe9CBr2dm3lW+hhOAVwBPA5e0t6o1RcQo4DhgYmbuRnHgeUcdVB4RuwHvo7jK7h7AARHxovZWBfT+u/sk4CeZuTPwk3K6nWazdo23AW8Hrhn0ano3m7VrvBrYLTN3B34PzBrsonoxm7Xr/HJm7l7+H/8hcHL9gwbZbHrJExGxA/Bm4P7BLqgVDNCDo5HLmrdVZl5DcSaUjpWZD2XmTeX9pyjCSv3VLdsqC8vKyaHlreMONIiI0cBbgW+2u5ZuFRFbA/9EcTYhMvOvmfnnthY1sDcA92Tmfe0upBebAsPLawL8A/Bgm+up91Lgusx8urxy7s8pAmBb9fG7+yDg3PL+ucDBg1lTvd5qzMw7M7NjLorWR40/Ln/WANdSXM+irfqo88mayc1p89+cfvLEV4CP0oF/E9eFAXpwNHJZc1UQEWOBlwPXtbmUtZStEfOBR4CrM7PjagROp/hF9rc219GfBH4cETeWVyPtNOOAR4FzylaYb0bE5u0uagDTgDntLqJeZj4A/DvFyNRDwBOZ+eP2VrWW24D9ImK7iPgHYAprXiysk2yfmQ+V9/8IbN/OYjYQ7wWubHcRfYmIf42IxcAM2j8CvZaIOAh4IDNvaXctzWKAVteJiC2A7wEfrPvk3REyc1X5VdpoYO/yq9+OEREHAI9k5o3trmUA+2bmnhStT8dExD+1u6A6mwJ7Av+dmS8H/kL7vyrvU3lBq6nAhe2upV7Zo3sQxYeSFwCbR8QR7a1qTZl5J/BF4MfAj4D5wKp21tSI8uJkG8SIX7tExCcoWgjPb3ctfcnMT2TmDhQ1HtvuemqVHzg/TgcG+/VhgB4cjVzWXA2IiKEU4fn8zLy43fX0p/w6/2d0Xm/5a4CpEbGIop3o9RHx7faWtLZyVJLMfISiZ3fv9la0liXAkppvGC6iCNSdan/gpsx8uN2F9OKNwB8y89HMfBa4GHh1m2taS2aelZmvyMx/Av5E0RfbiR6OiOcDlP8+0uZ6ulZEzAQOAGZ0yZWSzwcOaXcRdXai+HB8S/l3ZzRwU0Q8r61VrScD9OBo5LLmGkBEBEW/6Z2ZeVq76+lNRIzsOVI7IoYDbwJ+19ai6mTmrMwcnZljKd6LP83Mjhrti4jNI2LLnvsUB5501BliMvOPwOKIeHE56w3AHW0saSDT6cD2jdL9wCsj4h/K/+dvoAMPyIyI55b/jqHof/5Oeyvq06XAkeX9I4EftLGWrhURkyla3aZm5tPtrqcvEbFzzeRBdN7fnAWZ+dzMHFv+3VkC7Fn+Du1aLb0SoQp9Xda8zWWtISLmAJOAERGxBPh0Zp7V3qrW8hrgXcCCsscY4OPlFS87xfOBc8szr2wCXJCZHXmauA63PXBJkaXYFPhOZv6ovSX16gPA+eUH43uB97S5nl6VH0LeBPy/dtfSm8y8LiIuAm6i+Kr8ZjrzymXfi4jtgGeBYzrhoNHefncDpwIXRMRRwH3AYe2rsM8aHwf+CxgJXB4R8zPzLR1W4yzgOcDV5e+iazPz/e2qEfqsc0r5Qf5vFD/vjquxA/PEevNKhJIkSVIFtnBIkiRJFRigJUmSpAoM0JIkSVIFBmhJkiSpAgO0JEmSVIEBWpIGQUSsioj5Nbd+r1oYEZMi4tU10++PiHeX92dGxAsq7n9eRExct+ob2v7BEbHrYO1PktrJ80BL0uBYXl7ivVGTgGXArwEy84yaZTMpLizzYJNqa4aDgR/S2ReTkaSmcARaktooIhZFxGci4qaIWBARL4mIsRQXQ/hQOVq9X0ScEhEnRsQ7gIkUF3CZHxFvjYjv12zvTRFxSYP73jwizo6I6yPi5og4qJw/MyIujogfRcTdEfGlmsccFRG/Lx/zvxHxtXKkfCrw5bKmncrVDy3X+31E7NeUF0ySOoABWpIGx/C6Fo7Da5Y9lpl7Av8NnJiZi4AzgK9k5oTM/EXPipl5EXADMKMc0b4CeElEjCxXeQ9wdoM1fYLiUu57A6+jCMCbl8smAIcD44HDI2KHsm3kU8ArKa4M+pKypl9TXD76I2W995Tb2LTc9gcprpgmSRsEWzgkaXD018JxcfnvjcDbq2w0MzMizgOOiIhzgFcB727w4W8GpkbEieX0MGBMef8nmfkEQETcAewIjAB+npmPl/MvBHbpZ/u1z2tsgzVJUsczQEtS+z1T/ruKdfu9fA5wGbACuDAzVzb4uAAOycy71pgZsU9NTetT1/o+L0nqSLZwSFJnegrYspFlmfkgxQGFn6QI0426CvhARARARLx8gPV/C7w2IraNiE2BQxqsV5I2KAZoSRoc9T3Qpw6w/mXA23oOIqxbNhs4o1w2vJx3PrA4M+/sZ5uXR8SS8nYh8DlgKHBrRNxeTvcpMx8A/g24HvgVsAh4olw8F/hIeTDiTr1vQZI2DJGZ7a5BkrSeIuJrwM2ZeVaL97NFZi4rR6AvAc7OzIbO+iFJGwoDtCR1uYi4EfgL8KbMfGag9ddzX/8OvJHigMMfA8enf0gkbWQM0JIkSVIF9kBLkiRJFRigJUmSpAoM0JIkSVIFBmhJkiSpAgO0JEmSVIEBWpIkSarg/wN+cyGgqSZy5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract sequence lengths and sort data by sequence length\n",
    "sequence_lengths = [int(s.split()[1]) for s in lengths]\n",
    "sorted_indices = sorted(range(len(sequence_lengths)), key=lambda x: sequence_lengths[x])\n",
    "sequence_lengths = [sequence_lengths[i] for i in sorted_indices]\n",
    "\n",
    "# Calculate proportions for each metric, excluding 'False Alarm'\n",
    "metrics_keys = ['EM', 'EB', 'PM', 'PB', 'ML']  # Exclude 'FA' from this list\n",
    "proportions = {key: [] for key in metrics_keys}\n",
    "false_alarms = []\n",
    "\n",
    "# Calculate the total counts for each sequence length, excluding 'False Alarm'\n",
    "totals_per_length = [sum(metrics[i][key] for key in metrics_keys) for i in sorted_indices]\n",
    "\n",
    "# Calculate the proportions for each metric relative to the total counts per sequence length\n",
    "for i, total in enumerate(totals_per_length):\n",
    "    for key in metrics_keys:\n",
    "        proportions[key].append(metrics[sorted_indices[i]][key] / total if total > 0 else 0)\n",
    "    # Calculate the 'False Alarm' proportion relative to the total counts per sequence length\n",
    "    false_alarms.append(metrics[sorted_indices[i]]['FA'] / total if total > 0 else 0)\n",
    "\n",
    "# Plot each metric using stacked bar graphs for the first 15 sequence lengths\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  # Adjust the figure size as needed\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "indices = range(len(sequence_lengths[:15]))\n",
    "\n",
    "# Initialize the bottom for the stack\n",
    "bottom = [0] * 15\n",
    "\n",
    "# Plot the metrics, excluding 'False Alarm'\n",
    "for key in metrics_keys:\n",
    "    ax.bar(indices, proportions[key][:15], bottom=bottom, label=key)\n",
    "    # Update the bottom position for the next metric\n",
    "    bottom = [bottom[i] + proportions[key][i] for i in range(15)]\n",
    "\n",
    "# Now plot 'False Alarm' above the stacked bars\n",
    "ax.bar(indices, false_alarms[:15], bottom=bottom, label='FA', color='k', alpha=0.3)  # 'k' is for black\n",
    "\n",
    "# Labeling\n",
    "ax.set_xlabel('Entity Length')\n",
    "ax.set_ylabel('Proportion of Entities')\n",
    "ax.set_title('Proportion of Entities by Sequence Length (First 15)')\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels(sequence_lengths[:15])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9e1eb",
   "metadata": {},
   "source": [
    "## Robustness Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1504dcdf-ce60-4cd2-968f-80aac642aede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/apathak2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "407ec42d-2a8e-4032-9258-e2882fa3d315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 23:35:32.254731: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/sw/other/apps/cudnn/cudnn-linux-x86_64-8.9.7.29_cuda12-archive/lib:/opt/sw/other/apps/cuda/12.3.1/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/openmpi-4.1.2-4a/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/tcl-8.6.11-d4/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/sqlite-3.37.1-6s/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/zlib-1.2.11-2y/lib:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib64:/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-9.3.0/gcc-10.3.0-ya/lib\n",
      "2024-05-03 23:35:32.254772: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d284ea11-3d4b-471c-96c1-3f56e06611b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_entities(df):\n",
    "    # Assuming df has columns 'sentences' and 'labels'\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['sentences']\n",
    "        labels = row['labels']\n",
    "        words = sentence.split()\n",
    "\n",
    "        for i, (word, label) in enumerate(zip(words, labels)):\n",
    "            if label.startswith('B-'):\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                current_entity = {'type': label[2:], 'start_idx': i, 'end_idx': i, 'text': word}\n",
    "            elif label.startswith('I-') and current_entity and label[2:] == current_entity['type']:\n",
    "                current_entity['end_idx'] = i\n",
    "                current_entity['text'] += ' ' + word\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "\n",
    "        if current_entity:\n",
    "            entities.append(current_entity)\n",
    "            current_entity = None\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b4058c6-47a1-4a37-8e76-d0e256960791",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15872\n"
     ]
    }
   ],
   "source": [
    "entities = extract_entities(train_df)\n",
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca57929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = entities[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1977e257",
   "metadata": {},
   "source": [
    "### MFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d86ecbfe-0501-4fd9-b2c8-f0a65627e3eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define templates with placeholders for entities\n",
    "population_templates_mft = (\n",
    "    'The study focused on {population}.',\n",
    "    'Results were most significant among {population}.',\n",
    "    'The impact on {population} was noteworthy.',\n",
    "    'Interventions were targeted towards {population}.',\n",
    "    'Data was collected from various {population}.',\n",
    "    'The {population} showed a remarkable response.',\n",
    "    'Surveys were conducted across different {population}.',\n",
    "    'The {population} was observed for changes.',\n",
    "    'A significant change was recorded in the {population}.',\n",
    "    'The research aimed to benefit the {population}.'\n",
    ")\n",
    "\n",
    "intervention_templates_mft = (\n",
    "    \"The {intervention} was implemented to address the issue.\",\n",
    "    \"Researchers studied the effects of the {intervention}.\",\n",
    "    \"The {intervention} had a significant impact on the community.\",\n",
    "    \"Funding was provided for the {intervention}.\",\n",
    "    \"The success of the {intervention} was evident in the results.\",\n",
    "    \"Participants were selected for the {intervention} group.\",\n",
    "    \"The {intervention} was a key part of the strategy.\",\n",
    "    \"The {intervention} targeted specific outcomes.\",\n",
    "    \"Outcomes were measured after the {intervention} took place.\",\n",
    "    \"The {intervention} was designed to improve overall outcomes.\"\n",
    ")\n",
    "\n",
    "outcome_templates_mft = (\n",
    "    \"The outcome of the study was {outcome}.\",\n",
    "    \"It was observed that the primary outcome was {outcome}.\",\n",
    "    \"The expected outcome was {outcome}, which was surprising.\",\n",
    "    \"As a result, the outcome was {outcome}.\",\n",
    "    \"The final outcome, {outcome}, was recorded after the experiment.\",\n",
    "    \"The result of the intervention was {outcome}.\",\n",
    "    \"The project led to {outcome}.\",\n",
    "    \"The consequences were observed as {outcome}.\",\n",
    "    \"The end effect was {outcome}.\",\n",
    "    \"The study concluded with {outcome}.\"\n",
    ")\n",
    "\n",
    "effect_size_templates_mft = (\n",
    "    \"The observed change was {effect_size}.\",\n",
    "    \"A {effect_size} increase was noted in the study.\",\n",
    "    \"The results showed a {effect_size} decrease.\",\n",
    "    \"There was a {effect_size} improvement over the baseline.\",\n",
    "    \"The effect was quantified as {effect_size}.\",\n",
    "    \"The magnitude of impact measured {effect_size}.\",\n",
    "    \"The statistical significance reached {effect_size}.\",\n",
    "    \"A {effect_size} reduction in errors was achieved.\",\n",
    "    \"The intervention led to a {effect_size} enhancement.\",\n",
    "    \"The data indicated a {effect_size} growth rate.\"\n",
    ")\n",
    "\n",
    "coreference_templates_mft = (\n",
    "    \"This refers to the {coreference}.\",\n",
    "    \"Such instances of {coreference} were noted.\",\n",
    "    \"As mentioned earlier, the {coreference} plays a crucial role.\",\n",
    "    \"This is similar to the {coreference} discussed before.\",\n",
    "    \"The case of {coreference} is particularly interesting.\",\n",
    "    \"In light of the {coreference}, further analysis is required.\",\n",
    "    \"This aligns with the {coreference} we observed.\",\n",
    "    \"The {coreference} under discussion was pivotal.\",\n",
    "    \"Reflecting on the {coreference}, it becomes clear.\",\n",
    "    \"Given the {coreference}, the results are unsurprising.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1e97c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom entities\n",
    "populations = [entity['text'] for entity in entities if entity['type']=='population']\n",
    "interventions = [entity['text'] for entity in entities if entity['type']=='intervention']\n",
    "outcomes = [entity['text'] for entity in entities if entity['type']=='outcome']\n",
    "effect_sizes = [entity['text'] for entity in entities if entity['type']=='effect_size']\n",
    "coreferences = [entity['text'] for entity in entities if entity['type']=='coreference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f41ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the editor to create examples\n",
    "population_test_cases = editor.template(\n",
    "    population_templates_mft, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    population=populations\n",
    ")\n",
    "\n",
    "intervention_test_cases = editor.template(\n",
    "    intervention_templates_mft, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    intervention=interventions\n",
    ")\n",
    "\n",
    "outcome_test_cases = editor.template(\n",
    "    outcome_templates_mft, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    outcome=outcomes\n",
    ")\n",
    "\n",
    "effect_size_test_cases = editor.template(\n",
    "    effect_size_templates_mft, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    effect_size=effect_sizes\n",
    ")\n",
    "\n",
    "coreference_test_cases = editor.template(\n",
    "    coreference_templates_mft, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    coreference=coreferences\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5de4235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_population(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'population' is the only entity type present in the prediction\n",
    "    return all(label == 'O' or label.endswith('population') for label in pred)\n",
    "\n",
    "def found_intervention(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'intervention' is the only entity type present in the prediction\n",
    "    return all(label == 'O' or label.endswith('intervention') for label in pred)\n",
    "\n",
    "def found_outcome(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'outcome' is the only entity type present in the prediction\n",
    "    return all(label == 'O' or label.endswith('outcome') for label in pred)\n",
    "\n",
    "def found_effect_size(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'effect_size' is the only entity type present in the prediction\n",
    "    return all(label == 'O' or label.endswith('effect_size') for label in pred)\n",
    "\n",
    "def found_coreference(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'coreference' is the only entity type present in the prediction\n",
    "    return all(label == 'O' or label.endswith('coreference') for label in pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a3a41c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_population_expect_fn = Expect.single(found_population)\n",
    "found_intervention_expect_fn = Expect.single(found_intervention)\n",
    "found_outcome_expect_fn = Expect.single(found_outcome)\n",
    "found_effect_size_expect_fn = Expect.single(found_effect_size)  \n",
    "found_coreference_expect_fn = Expect.single(found_coreference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a2bd8cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some simple MFT tests\n",
    "found_population_test = MFT(\n",
    "    **population_test_cases,\n",
    "    name='Test for correct population recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label populations.',\n",
    "    expect=found_population_expect_fn\n",
    ")\n",
    "\n",
    "found_intervention_test = MFT(\n",
    "    **intervention_test_cases,\n",
    "    name='Test for correct intervention recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label interventions.',\n",
    "    expect=found_intervention_expect_fn\n",
    ")\n",
    "\n",
    "found_outcome_test = MFT(\n",
    "    **outcome_test_cases,\n",
    "    name='Test for correct outcome recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label outcomes.',\n",
    "    expect=found_outcome_expect_fn\n",
    ")\n",
    "\n",
    "found_effect_size_test = MFT(\n",
    "    **effect_size_test_cases,\n",
    "    name='Test for correct effect-size recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label effect-size.',\n",
    "    expect=found_effect_size_expect_fn\n",
    ")\n",
    "\n",
    "found_coreference_test = MFT(\n",
    "    **coreference_test_cases,\n",
    "    name='Test for correct coreference recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label coreference.',\n",
    "    expect=found_coreference_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "18293093-1672-4764-9d2d-2b13eeeb17c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "def predict_mft(texts):\n",
    "    # Extract just the sentences from the input tuples\n",
    "    sentences = [text for text in texts]\n",
    "    \n",
    "    # Convert texts to input IDs and attention masks using the tokenizer\n",
    "    input_ids, attention_mask = tokenize_and_format(sentences, tokenizer, max_length)\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    # Use the model to get the logits\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Decode the outputs using the CRF layer\n",
    "    decoded_labels = outputs['decoded']\n",
    "    \n",
    "    # Convert label indices to label names\n",
    "    pred_labels = [[reverse_label_dict[label] for label in sentence_labels] for sentence_labels in decoded_labels]\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "718cb8f7-20b7-486d-873e-aaabb5f7095b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "predict_and_conf_mft = PredictorWrapper.wrap_predict(predict_mft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b2390849-083e-43e2-88c5-13f5fa40a7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "mft_suite = TestSuite()\n",
    "mft_suite.add(found_population_test)\n",
    "mft_suite.add(found_intervention_test)\n",
    "mft_suite.add(found_outcome_test)\n",
    "mft_suite.add(found_effect_size_test)\n",
    "mft_suite.add(found_coreference_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc85840",
   "metadata": {},
   "source": [
    "### DIR Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f9f5f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_predictions(orig_pred, pred, orig_conf, conf, label=None, meta=None):\n",
    "    # Check if the predicted labels remain consistent despite changes in the entity\n",
    "    return orig_pred==pred\n",
    "\n",
    "compare_expect_fn = Expect.pairwise(compare_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b9026280",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_templates = [\n",
    "    '{intervention} was shown to lead to {outcome}.',\n",
    "    'In a study with {population}, the {effect_size} of {intervention} on {outcome} was significant.',\n",
    "    'The effect of {intervention} on {outcome} was mediated by {coreference}.',\n",
    "    '{population} benefited from {intervention}, which resulted in {outcome}.',\n",
    "    'Despite {coreference}, {intervention} had no significant {effect_size} on {outcome} among {population}.'\n",
    "]\n",
    "\n",
    "# Define templates with placeholders for numeric entities\n",
    "numeric_templates = [\n",
    "    \"The company reported a revenue of ${revenue} million last quarter.\",\n",
    "    \"A total of {employees} employees work at the company.\",\n",
    "    \"The company's stock rose by {percentage}% after the announcement.\"\n",
    "]\n",
    "\n",
    "# Define templates with placeholders for named entities\n",
    "punctuation_templates = [\n",
    "    \"The company {company} announced a new product.\",\n",
    "    \"The company {company} announced a new product; it expects high sales.\",\n",
    "    \"Did the company {company} announce a new product today?\",\n",
    "    \"The company {company}—known for its innovative solutions—announced a new product.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "43db8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_cases = editor.template(\n",
    "    all_templates, \n",
    "    remove_duplicates=True,\n",
    "    population=populations,\n",
    "    intervention=interventions,\n",
    "    outcome=outcomes,\n",
    "    effect_size=effect_sizes,\n",
    "    coreference=coreferences,\n",
    "    nsamples=500\n",
    ")\n",
    "\n",
    "# Use the editor to create examples with original numeric entities\n",
    "numeric_test_cases = editor.template(\n",
    "    numeric_templates,\n",
    "    remove_duplicates=True,\n",
    "    revenue=[\"100\", \"200\", \"300\"],\n",
    "    employees=[\"1000\", \"2000\", \"3000\"],\n",
    "    percentage=[\"5\", \"10\", \"15\"]\n",
    ")\n",
    "\n",
    "# Use the editor to create examples with original entities\n",
    "punctuation_test_cases = editor.template(\n",
    "    punctuation_templates,\n",
    "    remove_duplicates=True,\n",
    "    company=[\"Apple Inc.\", \"Google LLC\", \"Amazon.com Inc.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9c7034ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply numeric replacements\n",
    "def apply_numeric_replacement(texts):\n",
    "    # Initialize a list to store the results\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        # Iterate over each text in the input list\n",
    "        replacements = [\n",
    "            text.replace('million', 'billion'),\n",
    "            text.replace('employees', 'workers'),\n",
    "            text.replace('%', ' percent')\n",
    "        ]\n",
    "        # Append the modified texts to the results list\n",
    "        results.extend(replacements)\n",
    "    return results\n",
    "\n",
    "# Define a function to apply punctuation variations\n",
    "def apply_punctuation_variation(texts):\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        # Replace commas with semicolons, add question marks, etc.\n",
    "        variations = [\n",
    "            text.replace(',', ';'),\n",
    "            text.replace('.', '?'),\n",
    "            text.replace('—', '-')\n",
    "        ]\n",
    "        # Append the modified texts to the results list\n",
    "        results.extend(variations)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8b76fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply perturbations to the data\n",
    "perturbed_test_cases = Perturb.perturb(all_test_cases.data, Perturb.add_typos)\n",
    "# Apply numeric replacements\n",
    "perturbed_numeric_cases = Perturb.perturb(numeric_test_cases.data, perturb_fn=apply_numeric_replacement, keep_original=True)\n",
    "# Apply punctuation variations\n",
    "perturbed_punctuation_cases = Perturb.perturb(punctuation_test_cases.data, apply_punctuation_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "761ce4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DIR test to check the robustness of the model against typos\n",
    "typo_robustness_test = DIR(\n",
    "    perturbed_test_cases.data,\n",
    "    name='Test for robustness against typos in data',\n",
    "    capability='NER',\n",
    "    description='The model should maintain consistent predictions before and after adding typos.',\n",
    "    expect=compare_expect_fn\n",
    ")\n",
    "\n",
    "# Create the DIR test\n",
    "numeric_test = DIR(\n",
    "    **perturbed_numeric_cases,\n",
    "    name='Numeric Replacement Test',\n",
    "    capability='NER',\n",
    "    description='The model should maintain consistent predictions before and after numeric replacements.',\n",
    "    expect=compare_expect_fn\n",
    ")\n",
    "\n",
    "# Create the DIR test\n",
    "punctuation_test = DIR(\n",
    "    **perturbed_punctuation_cases,\n",
    "    name='Punctuation Variation Test',\n",
    "    capability='NER',\n",
    "    description='The model should maintain consistent predictions before and after punctuation variations.',\n",
    "    expect=compare_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0a6ae32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mft_suite.add(typo_robustness_test)\n",
    "# mft_suite.add(numeric_test)\n",
    "# mft_suite.add(punctuation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "491c8a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test for correct population recognition\n",
      "Predicting 187 examples\n",
      "Running Test for correct intervention recognition\n",
      "Predicting 250 examples\n",
      "Running Test for correct outcome recognition\n",
      "Predicting 357 examples\n",
      "Running Test for correct effect-size recognition\n",
      "Predicting 94 examples\n",
      "Running Test for correct coreference recognition\n",
      "Predicting 112 examples\n",
      "NER\n",
      "\n",
      "Test for correct population recognition\n",
      "Test cases:      187\n",
      "Fails (rate):    187 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "['B-coreference', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] Interventions were targeted towards Veracruz.\n",
      "\n",
      "----\n",
      "['B-coreference', 'O', 'O', 'O', 'B-population', 'O', 'O', 'O'] Interventions were targeted towards children.\n",
      "\n",
      "----\n",
      "['B-coreference', 'O', 'O', 'O', 'B-population', 'O', 'O', 'O'] Interventions were targeted towards women.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct intervention recognition\n",
      "Test cases:      250\n",
      "Fails (rate):    5 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'O', 'B-intervention', 'O', 'O', 'B-outcome', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] The This stove can improve health was implemented to address the issue.\n",
      "\n",
      "----\n",
      "['O', 'B-outcome', 'I-outcome', 'I-outcome', 'I-intervention', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] The Adoption of improved maize was implemented to address the issue.\n",
      "\n",
      "----\n",
      "['O', 'B-coreference', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] The vision was implemented to address the issue.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct outcome recognition\n",
      "Test cases:      357\n",
      "Fails (rate):    23 (6.4%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'O', 'O', 'O', 'B-outcome', 'I-outcome', 'I-intervention', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] The expected outcome was use of device, which was surprising.\n",
      "\n",
      "----\n",
      "['O', 'O', 'O', 'O', 'B-outcome', 'I-outcome', 'B-population', 'I-outcome', 'I-outcome', 'I-outcome', 'I-outcome', 'I-outcome', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] The expected outcome was risk of women experiencing physical and sexual abuse, which was surprising.\n",
      "\n",
      "----\n",
      "['O', 'O', 'O', 'O', 'B-intervention', 'I-outcome', 'I-outcome', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] The expected outcome was boiled their water, which was surprising.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct effect-size recognition\n",
      "Test cases:      94\n",
      "Fails (rate):    4 (4.3%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'B-outcome', 'I-outcome', 'I-outcome', 'I-effect_size', 'I-effect_size', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] A adjusted risk ratio = 0.45 increase was noted in the study.\n",
      "\n",
      "----\n",
      "['O', 'B-outcome', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] A IPIG increase was noted in the study.\n",
      "\n",
      "----\n",
      "['O', 'B-outcome', 'O', 'B-effect_size', 'I-effect_size', 'I-effect_size', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] A risk difference 21 percentage points increase was noted in the study.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct coreference recognition\n",
      "Test cases:      112\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mft_suite.run(predict_and_conf_mft)\n",
    "mft_suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b128c842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b1647d0e3047e0aca9bed569d79862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Test for correct pop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apathak2/.local/lib/python3.9/site-packages/checklist/abstract_test.py:501: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  conf = e[2][e[1]]\n"
     ]
    }
   ],
   "source": [
    "mft_suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97485a",
   "metadata": {},
   "source": [
    "### INV Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf3996cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "def predict_inv(texts):\n",
    "    sentences = [text for text in texts]\n",
    "    \n",
    "    # Convert texts to input IDs and attention masks using the tokenizer\n",
    "    input_ids, attention_mask = tokenize_and_format(sentences, tokenizer, max_length)\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    # Use the model to get the logits\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Decode the outputs using the CRF layer\n",
    "    decoded_labels = outputs['decoded']\n",
    "    \n",
    "    # Convert label indices to label names\n",
    "    pred_labels = [[reverse_label_dict[label] for label in sentence_labels] for sentence_labels in decoded_labels]\n",
    "    return pred_labels\n",
    "\n",
    "predict_and_conf_inv = PredictorWrapper.wrap_predict(predict_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5302ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(sentences: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Method that takes a list of sentences and returns their to lower cased form.\n",
    "    \"\"\"\n",
    "    lowered_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split(' ')\n",
    "        lowered_words = []\n",
    "        for word in words:\n",
    "            lowered_words.append(word.lower())\n",
    "        lowered_sentences.append(' '.join(lowered_words))\n",
    "    return ''.join(lowered_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42cdc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for entities\n",
    "population_templates_inv = (\n",
    "    'Interventions were targeted towards {population}.'\n",
    ")\n",
    "\n",
    "intervention_templates_inv = (\n",
    "    \"The {intervention} was implemented to address the issue.\"\n",
    ")\n",
    "\n",
    "outcome_templates_inv = (\n",
    "    \"The expected outcome was {outcome}, which was surprising.\"\n",
    ")\n",
    "\n",
    "effect_size_templates_inv = (\n",
    "    \"A {effect_size} increase was noted in the study.\"\n",
    ")\n",
    "\n",
    "coreference_templates_inv = (\n",
    "    \"Given the {coreference}, the results are unsurprising.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d670bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the editor to create examples\n",
    "intervention_test_cases = editor.template(\n",
    "    intervention_templates_inv, \n",
    "    remove_duplicates=True,\n",
    "    intervention=interventions\n",
    ")\n",
    "\n",
    "population_test_cases = editor.template(\n",
    "    population_templates_inv, \n",
    "    remove_duplicates=True,\n",
    "    population=populations\n",
    ")\n",
    "\n",
    "outcome_test_cases = editor.template(\n",
    "    outcome_templates_inv, \n",
    "    remove_duplicates=True,\n",
    "    outcome=outcomes\n",
    ")\n",
    "\n",
    "effect_size_test_cases = editor.template(\n",
    "    effect_size_templates_inv, \n",
    "    remove_duplicates=True,\n",
    "    effect_size=effect_sizes\n",
    ")\n",
    "\n",
    "coreference_test_cases = editor.template(\n",
    "    coreference_templates_inv, \n",
    "    remove_duplicates=True,\n",
    "    coreference=coreferences\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f27ac8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowered_intervention_test_cases = Perturb.perturb(intervention_test_cases.data, perturb_fn=lower_case, keep_original=True)\n",
    "lowered_population_test_cases = Perturb.perturb(population_test_cases.data, perturb_fn=lower_case, keep_original=True)\n",
    "lowered_outcome_test_cases = Perturb.perturb(outcome_test_cases.data, perturb_fn=lower_case, keep_original=True)\n",
    "lowered_effect_size_test_cases = Perturb.perturb(effect_size_test_cases.data, perturb_fn=lower_case, keep_original=True)\n",
    "lowered_coreference_test_cases = Perturb.perturb(coreference_test_cases.data, perturb_fn=lower_case, keep_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc14600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An INV test to check if the model's predictions are invariant to changes in the entity\n",
    "population_invariance_test = INV(\n",
    "    **lowered_population_test_cases,\n",
    "    name='Test for population invariance',\n",
    "    capability='NER',\n",
    "    description='The model predictions should remain consistent despite changes in the population entity.',\n",
    "    expect=compare_expect_fn\n",
    ")\n",
    "\n",
    "intervention_invariance_test = INV(\n",
    "    **lowered_intervention_test_cases,\n",
    "    name='Test for intervention invariance',\n",
    "    capability='NER',\n",
    "    description='The model predictions should remain consistent despite changes in the intervention entity.',\n",
    "    expect=compare_expect_fn\n",
    ")\n",
    "\n",
    "outcome_invariance_test = INV(\n",
    "    **lowered_outcome_test_cases,\n",
    "    name='Test for outcome invariance',\n",
    "    capability='NER',\n",
    "    description='The model predictions should remain consistent despite changes in the outcome entity.',\n",
    "    expect=compare_expect_fn\n",
    ")\n",
    "\n",
    "effect_size_invariance_test = INV(\n",
    "    **lowered_effect_size_test_cases,\n",
    "    name='Test for effect_size invariance',\n",
    "    capability='NER',\n",
    "    description='The model predictions should remain consistent despite changes in the effect_size entity.',\n",
    "    expect=compare_expect_fn\n",
    ")\n",
    "\n",
    "coreference_invariance_test = INV(\n",
    "    **lowered_coreference_test_cases,\n",
    "    name='Test for coreference invariance',\n",
    "    capability='NER',\n",
    "    description='The model predictions should remain consistent despite changes in the coreference entity.',\n",
    "    expect=compare_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62947d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20d1c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_suite.add(intervention_invariance_test)\n",
    "inv_suite.add(population_invariance_test)\n",
    "inv_suite.add(outcome_invariance_test)\n",
    "inv_suite.add(effect_size_invariance_test)\n",
    "inv_suite.add(coreference_invariance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a792dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test for intervention invariance\n",
      "Predicting 500 examples\n",
      "Running Test for population invariance\n",
      "Predicting 374 examples\n",
      "Running Test for outcome invariance\n",
      "Predicting 714 examples\n",
      "Running Test for effect_size invariance\n",
      "Predicting 188 examples\n",
      "Running Test for coreference invariance\n",
      "Predicting 224 examples\n",
      "NER\n",
      "\n",
      "Test for intervention invariance\n",
      "Test cases:      250\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test for population invariance\n",
      "Test cases:      187\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test for outcome invariance\n",
      "Test cases:      357\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test for effect_size invariance\n",
      "Test cases:      94\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Test for coreference invariance\n",
      "Test cases:      112\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inv_suite.run(predict_and_conf_inv)\n",
    "inv_suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b7a0184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6513165414ae46dab1184d3059971735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Test for interventio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inv_suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e310d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d36369356684e6aa06b7ada70e96ce0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11461a73263241bd8e2ad35a92e0c2dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "163bff609cfa453abc5879732e2220f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7343c5bf56714623a01c5594bb9a9aa0",
      "placeholder": "​",
      "style": "IPY_MODEL_59cffec0648542bf98578314858763bb",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "1ad64543adeb474ebb9411511dde951a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb0b7eeec1814e6ab5a7e8c0c701105e",
      "max": 608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24a67c04e0824c1baed82a66396223b6",
      "value": 608
     }
    },
    "225124f7f60c49a4bc218b0299701752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24a67c04e0824c1baed82a66396223b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e20ca46d0334a0ab3f2f2dc60a005ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31abb00576474a3b9a11ea0f06d41d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cb3e628e0c64da392f635d25c68be6b",
       "IPY_MODEL_1ad64543adeb474ebb9411511dde951a",
       "IPY_MODEL_f2c1f53924a7409c816b01308ccb9336"
      ],
      "layout": "IPY_MODEL_2e20ca46d0334a0ab3f2f2dc60a005ca"
     }
    },
    "3ad2d7515dee4ca4ac5d8d2f335adb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6eda298aaf44b9b914ef35a6a123531",
      "placeholder": "​",
      "style": "IPY_MODEL_11461a73263241bd8e2ad35a92e0c2dc",
      "value": " 2.46M/2.46M [00:00&lt;00:00, 27.0MB/s]"
     }
    },
    "4a7b1395942142918447f45464dcd3ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56706f8aac024e13846308140c44006d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59721f7c8561408c8fea78b29ad6be3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87aeb22ec9164278b1f1e2b23b959299",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c5108fe496048d39e8a14345c5f5d65",
      "value": 52
     }
    },
    "59cffec0648542bf98578314858763bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c26711cce0d49d6a401b9b5c6823345": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1e82949a1042b1b831bd86137f1375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_163bff609cfa453abc5879732e2220f0",
       "IPY_MODEL_59721f7c8561408c8fea78b29ad6be3d",
       "IPY_MODEL_7f2924ef022647f48f1c7e7be7700402"
      ],
      "layout": "IPY_MODEL_fd07562db6144a71a9910d3e343eceae"
     }
    },
    "5e389d23cc6b4642b289e7d9f933c9cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c5108fe496048d39e8a14345c5f5d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e62eee804a54b298728d6f6a21b9f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7343c5bf56714623a01c5594bb9a9aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f2924ef022647f48f1c7e7be7700402": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d5aed0313247339c19e9c75d548396",
      "placeholder": "​",
      "style": "IPY_MODEL_225124f7f60c49a4bc218b0299701752",
      "value": " 52.0/52.0 [00:00&lt;00:00, 3.40kB/s]"
     }
    },
    "87aeb22ec9164278b1f1e2b23b959299": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a972e443ff9481d896cac5bca478664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcea801bb91048a68bd1dfbefd8b0b93",
      "max": 2464616,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2ea734058bf4fc9a00cef248b73b9ab",
      "value": 2464616
     }
    },
    "8cb3e628e0c64da392f635d25c68be6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a7b1395942142918447f45464dcd3ce",
      "placeholder": "​",
      "style": "IPY_MODEL_5e389d23cc6b4642b289e7d9f933c9cb",
      "value": "config.json: 100%"
     }
    },
    "95e1a33c031e434bbd30fb0315ea8e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2c593b085534f8d8b148ab14be27b58",
       "IPY_MODEL_8a972e443ff9481d896cac5bca478664",
       "IPY_MODEL_3ad2d7515dee4ca4ac5d8d2f335adb33"
      ],
      "layout": "IPY_MODEL_0d36369356684e6aa06b7ada70e96ce0"
     }
    },
    "a4d5aed0313247339c19e9c75d548396": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb0b7eeec1814e6ab5a7e8c0c701105e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcea801bb91048a68bd1dfbefd8b0b93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e177f9d5aa7f4cd990ed6d81cff20cbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2ea734058bf4fc9a00cef248b73b9ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6eda298aaf44b9b914ef35a6a123531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2c1f53924a7409c816b01308ccb9336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e177f9d5aa7f4cd990ed6d81cff20cbf",
      "placeholder": "​",
      "style": "IPY_MODEL_6e62eee804a54b298728d6f6a21b9f98",
      "value": " 608/608 [00:00&lt;00:00, 39.3kB/s]"
     }
    },
    "f2c593b085534f8d8b148ab14be27b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c26711cce0d49d6a401b9b5c6823345",
      "placeholder": "​",
      "style": "IPY_MODEL_56706f8aac024e13846308140c44006d",
      "value": "spm.model: 100%"
     }
    },
    "fd07562db6144a71a9910d3e343eceae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
