{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f2e3a19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f2e3a19",
    "outputId": "8f636dfd-7040-479f-8ded-692a99f51824",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/apathak2/.local/lib/python3.9/site-packages (4.39.3)\n",
      "Requirement already satisfied: torch in /home/apathak2/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: tokenizers in /home/apathak2/.local/lib/python3.9/site-packages (0.15.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/apathak2/.local/lib/python3.9/site-packages (0.22.2)\n",
      "Requirement already satisfied: pytorch-crf in /home/apathak2/.local/lib/python3.9/site-packages (0.7.2)\n",
      "Requirement already satisfied: filelock in /home/apathak2/.local/lib/python3.9/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in /home/apathak2/.local/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from torch) (2.8.5)\n",
      "Requirement already satisfied: jinja2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: fsspec in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/apathak2/.local/lib/python3.9/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/apathak2/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers[torch]) (0.29.2)\n",
      "Requirement already satisfied: psutil in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/apathak2/.local/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/apathak2/.local/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: protobuf==3.20.3 in /home/apathak2/.local/lib/python3.9/site-packages (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers torch transformers[torch] tokenizers huggingface_hub pytorch-crf\n",
    "!pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e4734ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "2e4734ec",
    "outputId": "7ce0f168-9f2b-459d-c287-3f661cddb410"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a0bc84b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "9a0bc84b",
    "outputId": "feb3c753-6d26-4c70-c52b-7f2d70048f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: NVIDIA A100-SXM4-80GB MIG 3g.40gb, n_gpu: 1\n"
     ]
    }
   ],
   "source": [
    "device_name = torch.cuda.get_device_name()\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de59fcff",
   "metadata": {
    "id": "de59fcff"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aGpCRa-oQq0K",
   "metadata": {
    "id": "aGpCRa-oQq0K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_conll(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    current_sentence = []\n",
    "    current_labels = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                columns = line.split()\n",
    "                word, label = columns[0], columns[-1]\n",
    "                current_sentence.append(word)\n",
    "                current_labels.append(label)\n",
    "                \n",
    "                # Check if the current word is a sentence boundary\n",
    "                if word == '.' and label == 'O':\n",
    "                    sentences.append(' '.join(current_sentence))\n",
    "                    labels.append(current_labels)\n",
    "                    current_sentence = []\n",
    "                    current_labels = []\n",
    "\n",
    "    # Create a DataFrame from the accumulated sentences and labels\n",
    "    df = pd.DataFrame({\n",
    "        'sentences': sentences,\n",
    "        'labels': labels\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "BmsqGYy2TcHS",
   "metadata": {
    "id": "BmsqGYy2TcHS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "max_length=128\n",
    "\n",
    "def tokenize_and_format(sentences, tokenizer, max_length=max_length):\n",
    "    \"\"\"\n",
    "    Tokenizes sentences and returns formatted input IDs and attention masks.\n",
    "    \n",
    "    Parameters:\n",
    "    sentences: List of sentence strings to be tokenized.\n",
    "    tokenizer: Tokenizer instance used for tokenizing the sentences.\n",
    "    \"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # Encode each sentence\n",
    "    for sentence in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=max_length,  # Adjust based on your model's maximum input length\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Store the input ID and the attention mask of this sentence\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert lists of tensors to single tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pjdFP9RFXkCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjdFP9RFXkCq",
    "outputId": "51858648-a4d7-47c0-b5ac-43272e38a953"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "wXPExdKtEXHh",
   "metadata": {
    "id": "wXPExdKtEXHh"
   },
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'O': 0,\n",
    "    'B-intervention': 1,\n",
    "    'I-intervention': 2,\n",
    "    'B-outcome': 3,\n",
    "    'I-outcome': 4,\n",
    "    'B-population': 5,\n",
    "    'I-population': 6,\n",
    "    'B-effect_size': 7,\n",
    "    'I-effect_size': 8,\n",
    "    'B-coreference': 9,\n",
    "    'I-coreference': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa54038d-da7f-4fd3-9ad6-029a7c560f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_label_dict = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "A49f-HWiNCCm",
   "metadata": {
    "id": "A49f-HWiNCCm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_dataset(df, tokenizer, label_dict, max_length=max_length):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame to return a dataset suitable for training/testing an NER model.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame containing 'Tokens' and 'Labels' columns.\n",
    "    tokenizer: Tokenizer to use for encoding the sentences.\n",
    "    label_dict: Dictionary mapping label names to indices.\n",
    "    max_length: Maximum length of the tokenized input.\n",
    "    \"\"\"\n",
    "    sentences = df.sentences.values\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    input_ids, attention_masks = tokenize_and_format(sentences, tokenizer, max_length)\n",
    "\n",
    "    # Prepare labels\n",
    "    label_list = []\n",
    "    for labels in df.labels.values:\n",
    "        # Initialize a list to hold the encoded labels for each sentence\n",
    "        encoded_labels = [label_dict[label] for label in labels]\n",
    "        \n",
    "        # Truncate or pad the labels to match the max_length\n",
    "        encoded_labels = encoded_labels[:max_length]  # Truncate if needed\n",
    "        encoded_labels += [label_dict['O']] * (max_length - len(encoded_labels))  # Pad with 'O' if needed\n",
    "        \n",
    "        label_list.append(encoded_labels)\n",
    "\n",
    "    # Convert label_list to a tensor\n",
    "    labels = torch.tensor(label_list, dtype=torch.long)\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = [(input_ids[i], attention_masks[i], labels[i]) for i in range(len(df))]\n",
    "\n",
    "    return dataset, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "Y73hwpVwOvCi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y73hwpVwOvCi",
    "outputId": "3042abbf-6575-47cd-e570-a94f3f930ea7"
   },
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "train_df = read_conll('data/econ_ie/train.conll')\n",
    "val_df = read_conll('data/econ_ie/dev.conll')\n",
    "test_df = read_conll('data/econ_ie/test.conll')\n",
    "\n",
    "train_set, train_sentences = get_dataset(train_df, tokenizer, label_dict)\n",
    "val_set, val_sentences = get_dataset(val_df, tokenizer, label_dict)\n",
    "test_set, test_sentences = get_dataset(test_df, tokenizer, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40e4a2e9-180d-464c-8dcf-b868546574b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  1006,  1015,  1007,  3802,  2015, 16605,  2000, 11768, 10210,\n",
       "         13340,  3508,  1999,  4405,  4655,  1998,  6088,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 1, 0, 0, 3, 4, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "XghB1AiHR2Aj",
   "metadata": {
    "id": "XghB1AiHR2Aj"
   },
   "outputs": [],
   "source": [
    "# Set the hyperparameters according to Table 8\n",
    "dropout = 0.2\n",
    "learning_rates = [5e-5, 6e-5, 7e-5]  # Perform hyperparameter search\n",
    "batch_size = 12\n",
    "gradient_accumulation_steps = 4\n",
    "weight_decay = 0\n",
    "max_epochs = 10\n",
    "lr_decay = \"slanted_triangular\"\n",
    "fraction_of_steps = 0.06\n",
    "adam_epsilon = 1e-8\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7129234f-176a-482a-9b8e-06b3a8997056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entities(labels, tokens):\n",
    "    \"\"\"\n",
    "    Extract entities from token-label pairs.\n",
    "    \n",
    "    Args:\n",
    "    labels (list of int): List of label indices corresponding to each token.\n",
    "    tokens (list of str): List of tokens corresponding to each label index.\n",
    "    \n",
    "    Returns:\n",
    "    list of tuples: Each tuple represents an entity with (entity_type, start_index, end_index, entity_text).\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    for i, (token, label) in enumerate(zip(tokens, labels)):\n",
    "        if label.startswith(\"B-\"):\n",
    "            if current_entity:\n",
    "                entities.append(current_entity)\n",
    "            entity_type = label.split(\"-\")[1]\n",
    "            current_entity = (entity_type, i, i, token)\n",
    "        elif label.startswith(\"I-\") and current_entity and label.split(\"-\")[1] == current_entity[0]:\n",
    "            current_entity = (current_entity[0], current_entity[1], i, current_entity[3] + \" \" + token)\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = None\n",
    "\n",
    "    if current_entity:\n",
    "        entities.append(current_entity)\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a900c6ef-2a3d-4e2d-8663-2f2228506f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entity_level_metrics(true_entities, pred_entities):\n",
    "    metrics = {\"EM\": 0, \"EB\": 0, \"PM\": 0, \"PB\": 0, \"ML\": 0, \"FA\": 0}\n",
    "    true_matched = set()\n",
    "    pred_matched = set()\n",
    "\n",
    "    # Check for exact and partial matches\n",
    "    for i, true_entity in enumerate(true_entities):\n",
    "        for j, pred_entity in enumerate(pred_entities):\n",
    "            if j in pred_matched:\n",
    "                continue\n",
    "            if true_entity == pred_entity:\n",
    "                metrics[\"EM\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "            elif true_entity[0] == pred_entity[0] and is_overlapping((true_entity[1], true_entity[2]), (pred_entity[1], pred_entity[2])):\n",
    "                if true_entity[1] == pred_entity[1] and true_entity[2] == pred_entity[2]:\n",
    "                    metrics[\"EB\"] += 1\n",
    "                else:\n",
    "                    metrics[\"PM\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "            elif is_overlapping((true_entity[1], true_entity[2]), (pred_entity[1], pred_entity[2])):\n",
    "                metrics[\"PB\"] += 1\n",
    "                true_matched.add(i)\n",
    "                pred_matched.add(j)\n",
    "                break\n",
    "\n",
    "    # Check for missed labels (entities in true but not in pred)\n",
    "    for i, true_entity in enumerate(true_entities):\n",
    "        if i not in true_matched:\n",
    "            metrics[\"ML\"] += 1\n",
    "\n",
    "    # Check for false alarms (entities in pred but not in true)\n",
    "    for j, pred_entity in enumerate(pred_entities):\n",
    "        if j not in pred_matched:\n",
    "            metrics[\"FA\"] += 1\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "421e8df6-4a33-4b28-8316-d5f5674575ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(span1, span2):\n",
    "    \"\"\"\n",
    "    Check if two spans overlap.\n",
    "    Args:\n",
    "    span1, span2 (tuple): (start_index, end_index) of the span.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if spans overlap, False otherwise.\n",
    "    \"\"\"\n",
    "    assert len(span1) == 2 and len(span2) == 2, \"Each span must be a tuple of two elements (start_index, end_index)\"\n",
    "    start1, end1 = span1\n",
    "    start2, end2 = span2\n",
    "    return max(start1, start2) <= min(end1, end2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "882fb716-ce62-4e55-be8f-a7c6d6b9bbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-intervention': 1, 'I-intervention': 2, 'B-outcome': 3, 'I-outcome': 4, 'B-population': 5, 'I-population': 6, 'B-effect_size': 7, 'I-effect_size': 8, 'B-coreference': 9, 'I-coreference': 10}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90a7c0d6-e0d3-465f-8792-8cb1bb5b0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def analyze_generalization(model, data, tokenizer, train_words):\n",
    "    grouped_entities = defaultdict(lambda: ([], []))  # {group_name: (true_entities, pred_entities)}        \n",
    "    groups=[]\n",
    "    mtrcs=[]\n",
    "\n",
    "    for i, (input_ids, attention_mask, label_tensor) in enumerate(data):\n",
    "        input_ids = input_ids.unsqueeze(0).to(device)\n",
    "        attention_mask = attention_mask.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Call model without labels to get the decoded labels\n",
    "        with torch.no_grad():\n",
    "            decoded_labels = model(input_ids, attention_mask=attention_mask)[\"decoded\"][0]\n",
    "            # No need to use argmax since CRF.decode returns the most likely tag sequence\n",
    "        \n",
    "        # Convert the decoded labels to label names using label_dict\n",
    "        pred_labels = [reverse_label_dict.get(label) for label in decoded_labels]\n",
    "\n",
    "        # Convert input_ids to tokens\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist(), skip_special_tokens=True)\n",
    "\n",
    "        # Assuming true_labels are provided in a similar structure\n",
    "        true_labels = [reverse_label_dict.get(l.item()) for l in label_tensor]\n",
    "        \n",
    "        # Preprocess entities for true and predicted labels\n",
    "        true_entities = preprocess_entities(true_labels, tokens)\n",
    "        pred_entities = preprocess_entities(pred_labels, tokens)\n",
    "        \n",
    "        for true_entity, pred_entity in zip(true_entities, pred_entities):\n",
    "            length = true_entity[2] - true_entity[1]\n",
    "\n",
    "            seen = any(word in train_words for word in true_entity[3].split())  # Check if any word in entity text was seen in training\n",
    "\n",
    "            group_name = f\"Length {length} - {'Seen' if seen else 'Unseen'}\"\n",
    "            grouped_entities[group_name][0].append(true_entity)\n",
    "            grouped_entities[group_name][1].append(pred_entity)\n",
    "    \n",
    "    for group_name, group_data in grouped_entities.items():\n",
    "        group_true_entities, group_pred_entities = group_data\n",
    "        metrics = compute_entity_level_metrics(group_true_entities, group_pred_entities)\n",
    "        print(f\"Group: {group_name}, Metrics: {metrics}\")\n",
    "        groups.append(group_name)\n",
    "        mtrcs.append(metrics)\n",
    "        \n",
    "    return groups, mtrcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "Fsd5u-jsp_N5",
   "metadata": {
    "id": "Fsd5u-jsp_N5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_validation_performance(val_set, model, device, label_dict, batch_size):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_loss = 0\n",
    "    all_pred_labels = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    num_batches = int(len(val_set) / batch_size) + (1 if len(val_set) % batch_size != 0 else 0)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        end_index = min(batch_size * (i + 1), len(val_set))\n",
    "        batch = val_set[i * batch_size:end_index]\n",
    "\n",
    "        if len(batch) == 0:\n",
    "            continue\n",
    "\n",
    "        input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "        input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "        label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = input_id_tensors.to(device)\n",
    "        b_input_mask = input_mask_tensors.to(device)\n",
    "        b_labels = label_tensors.to(device)\n",
    "        b_labels = b_labels.long()\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            logits = outputs[\"logits\"]\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Get the predicted labels\n",
    "            pred_labels = np.argmax(logits, axis=2).flatten()\n",
    "            true_labels = label_ids.flatten()\n",
    "\n",
    "            # Convert labels to their original names\n",
    "            pred_labels = [reverse_label_dict.get(label) for label in pred_labels]\n",
    "            true_labels = [reverse_label_dict.get(label) for label in true_labels]\n",
    "\n",
    "            # Filter out special tokens ('O' label is used for non-entity and special tokens)\n",
    "            filtered_pred_labels = [pred for pred, true in zip(pred_labels, true_labels) if true != 'O']\n",
    "            filtered_true_labels = [true for true in true_labels if true != 'O']\n",
    "            \n",
    "            # After filtering out special tokens\n",
    "            if not filtered_pred_labels or not filtered_true_labels:\n",
    "                print(\"Warning: No non-'O' labels found in this batch.\")\n",
    "            else:\n",
    "                all_pred_labels.extend(filtered_pred_labels)\n",
    "                all_true_labels.extend(filtered_true_labels)\n",
    "            \n",
    "    # After processing all batches, check if we have any labels to report on\n",
    "    if not all_true_labels or not all_pred_labels:\n",
    "        print(\"Error: No non-'O' labels found in the entire validation set.\")\n",
    "        default_labels = [list(label_dict.values())[0]]  # Use the first label as a placeholder\n",
    "        report = classification_report(default_labels, default_labels, digits=4, zero_division=0)\n",
    "    else:\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        report = classification_report(all_true_labels, all_pred_labels, digits=4, zero_division=0)\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab0efc37-4ac5-41ee-81f5-66a99e012c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcrf import CRF\n",
    "from transformers import AutoModel\n",
    "\n",
    "class CRFTagger(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        # Mask should be of type 'bool' in newer PyTorch versions\n",
    "        mask = attention_mask.type(torch.bool) if hasattr(torch, 'bool') else attention_mask.byte()\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = -self.crf(logits, labels, mask=mask, reduction='mean')\n",
    "            return {'loss': loss, 'logits': logits, 'decoded': self.crf.decode(logits, mask=mask)}\n",
    "        else:\n",
    "            decoded_labels = self.crf.decode(logits, mask=mask)\n",
    "            return {'decoded': decoded_labels, 'logits': logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eCm6d0FKqFSW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "eCm6d0FKqFSW",
    "outputId": "7a07ee72-afe7-453a-ba34-ef75a74a4b8c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRFTagger(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       "  (crf): CRF(num_tags=11)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = CRFTagger(model_name, len(label_dict))\n",
    "model.dropout = torch.nn.Dropout(dropout)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f41a6c0c-b1e6-4ff9-ab65-686e985a6460",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate: 5e-05\n",
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "Total loss: 16016.201522827148\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.0000    0.0000    0.0000       255\n",
      " B-effect_size     0.0000    0.0000    0.0000       142\n",
      "B-intervention     0.0000    0.0000    0.0000       704\n",
      "     B-outcome     0.3333    0.0010    0.0019      1035\n",
      "  B-population     0.0000    0.0000    0.0000       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.0000    0.0000    0.0000       247\n",
      "I-intervention     0.7718    0.1163    0.2021      1600\n",
      "     I-outcome     0.4481    0.1790    0.2558      1760\n",
      "  I-population     0.0000    0.0000    0.0000       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.0721      6966\n",
      "     macro avg     0.1412    0.0269    0.0418      6966\n",
      "  weighted avg     0.3400    0.0721    0.1113      6966\n",
      "\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "Total loss: 10688.420168876648\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.6429    0.0353    0.0669       255\n",
      " B-effect_size     0.0000    0.0000    0.0000       142\n",
      "B-intervention     0.7600    0.2429    0.3681       704\n",
      "     B-outcome     0.5882    0.1643    0.2568      1035\n",
      "  B-population     0.7034    0.1706    0.2746       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.0000    0.0000    0.0000       247\n",
      "I-intervention     0.8173    0.3131    0.4528      1600\n",
      "     I-outcome     0.6613    0.4449    0.5319      1760\n",
      "  I-population     0.8018    0.2816    0.4168       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.2742      6966\n",
      "     macro avg     0.4523    0.1502    0.2153      6966\n",
      "  weighted avg     0.6741    0.2742    0.3767      6966\n",
      "\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "Total loss: 9465.897883415222\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.7313    0.1922    0.3043       255\n",
      " B-effect_size     0.0000    0.0000    0.0000       142\n",
      "B-intervention     0.6820    0.3168    0.4326       704\n",
      "     B-outcome     0.6587    0.1604    0.2580      1035\n",
      "  B-population     0.7186    0.2007    0.3137       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.7083    0.0688    0.1255       247\n",
      "I-intervention     0.7168    0.5125    0.5977      1600\n",
      "     I-outcome     0.7157    0.4119    0.5229      1760\n",
      "  I-population     0.8808    0.2152    0.3459       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.3234      6966\n",
      "     macro avg     0.5284    0.1889    0.2637      6966\n",
      "  weighted avg     0.7040    0.3234    0.4246      6966\n",
      "\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "Total loss: 8969.054332733154\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8519    0.3608    0.5069       255\n",
      " B-effect_size     0.0000    0.0000    0.0000       142\n",
      "B-intervention     0.6239    0.3935    0.4826       704\n",
      "     B-outcome     0.6482    0.2493    0.3601      1035\n",
      "  B-population     0.6840    0.3294    0.4447       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.6053    0.0931    0.1614       247\n",
      "I-intervention     0.6558    0.6813    0.6683      1600\n",
      "     I-outcome     0.7187    0.4790    0.5748      1760\n",
      "  I-population     0.7968    0.3997    0.5323       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.4345      6966\n",
      "     macro avg     0.5077    0.2715    0.3392      6966\n",
      "  weighted avg     0.6736    0.4345    0.5107      6966\n",
      "\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "Total loss: 8679.154804229736\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.7829    0.3961    0.5260       255\n",
      " B-effect_size     0.5714    0.0282    0.0537       142\n",
      "B-intervention     0.6232    0.4276    0.5072       704\n",
      "     B-outcome     0.6155    0.2986    0.4021      1035\n",
      "  B-population     0.6759    0.2860    0.4019       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.5944    0.3441    0.4359       247\n",
      "I-intervention     0.7854    0.4781    0.5944      1600\n",
      "     I-outcome     0.7550    0.4290    0.5471      1760\n",
      "  I-population     0.8127    0.3511    0.4904       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.3887      6966\n",
      "     macro avg     0.5651    0.2762    0.3599      6966\n",
      "  weighted avg     0.7171    0.3887    0.4996      6966\n",
      "\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "Total loss: 8592.419111251831\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8268    0.4118    0.5497       255\n",
      " B-effect_size     0.5000    0.0634    0.1125       142\n",
      "B-intervention     0.7019    0.4148    0.5214       704\n",
      "     B-outcome     0.6430    0.2802    0.3903      1035\n",
      "  B-population     0.7101    0.2826    0.4043       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.6364    0.2267    0.3343       247\n",
      "I-intervention     0.7634    0.5425    0.6343      1600\n",
      "     I-outcome     0.7377    0.4619    0.5681      1760\n",
      "  I-population     0.8015    0.3398    0.4773       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.4037      6966\n",
      "     macro avg     0.5746    0.2749    0.3629      6966\n",
      "  weighted avg     0.7233    0.4037    0.5112      6966\n",
      "\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "Total loss: 8661.606723308563\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8140    0.2745    0.4106       255\n",
      " B-effect_size     0.4737    0.0634    0.1118       142\n",
      "B-intervention     0.6263    0.4190    0.5021       704\n",
      "     B-outcome     0.5569    0.3121    0.4000      1035\n",
      "  B-population     0.6754    0.3027    0.4180       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.6806    0.1984    0.3072       247\n",
      "I-intervention     0.7987    0.4688    0.5908      1600\n",
      "     I-outcome     0.7854    0.3597    0.4934      1760\n",
      "  I-population     0.7663    0.3608    0.4906       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.3636      6966\n",
      "     macro avg     0.5616    0.2508    0.3386      6966\n",
      "  weighted avg     0.7175    0.3636    0.4781      6966\n",
      "\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "Total loss: 8730.544265270233\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.7823    0.3804    0.5119       255\n",
      " B-effect_size     0.4154    0.1901    0.2609       142\n",
      "B-intervention     0.6154    0.4432    0.5153       704\n",
      "     B-outcome     0.5683    0.3459    0.4300      1035\n",
      "  B-population     0.6090    0.3829    0.4702       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.6780    0.1619    0.2614       247\n",
      "I-intervention     0.8083    0.4375    0.5677      1600\n",
      "     I-outcome     0.7862    0.3426    0.4772      1760\n",
      "  I-population     0.7249    0.4434    0.5502       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.3790      6966\n",
      "     macro avg     0.5443    0.2844    0.3677      6966\n",
      "  weighted avg     0.7086    0.3790    0.4894      6966\n",
      "\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "Total loss: 8852.731281757355\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8148    0.3451    0.4848       255\n",
      " B-effect_size     0.4615    0.0845    0.1429       142\n",
      "B-intervention     0.6432    0.4403    0.5228       704\n",
      "     B-outcome     0.6272    0.3169    0.4211      1035\n",
      "  B-population     0.6469    0.3645    0.4663       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.7273    0.0972    0.1714       247\n",
      "I-intervention     0.7948    0.4600    0.5827      1600\n",
      "     I-outcome     0.7811    0.3955    0.5251      1760\n",
      "  I-population     0.7252    0.4142    0.5273       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.3830      6966\n",
      "     macro avg     0.5656    0.2653    0.3495      6966\n",
      "  weighted avg     0.7230    0.3830    0.4955      6966\n",
      "\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "Total loss: 8702.423847913742\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8482    0.3725    0.5177       255\n",
      " B-effect_size     0.6364    0.0986    0.1707       142\n",
      "B-intervention     0.6652    0.4403    0.5299       704\n",
      "     B-outcome     0.6313    0.3391    0.4412      1035\n",
      "  B-population     0.6732    0.3445    0.4558       598\n",
      " I-coreference     0.0000    0.0000    0.0000         7\n",
      " I-effect_size     0.7059    0.1943    0.3048       247\n",
      "I-intervention     0.7703    0.5050    0.6100      1600\n",
      "     I-outcome     0.7484    0.4528    0.5642      1760\n",
      "  I-population     0.7362    0.4110    0.5275       618\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.4139      6966\n",
      "     macro avg     0.5832    0.2871    0.3747      6966\n",
      "  weighted avg     0.7192    0.4139    0.5210      6966\n",
      "\n",
      "\n",
      "Training complete at learning rate: 5e-05!\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "import time\n",
    "\n",
    "# Calculate the total number of training steps\n",
    "total_steps = (len(train_set) // (batch_size * gradient_accumulation_steps)) * max_epochs\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Current learning rate: {lr}\")\n",
    "\n",
    "    # Create the optimizer with the specified hyperparameters\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, eps=adam_epsilon, betas=(adam_beta1, adam_beta2), weight_decay=weight_decay, no_deprecation_warning=True)\n",
    "\n",
    "    # Create the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * fraction_of_steps), num_training_steps=total_steps)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch_i in range(max_epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, max_epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        num_batches = int(len(train_set) / batch_size) + (1 if len(train_set) % batch_size != 0 else 0)\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            end_index = min(batch_size * (i + 1), len(train_set))\n",
    "            batch = train_set[i * batch_size:end_index]\n",
    "\n",
    "            if len(batch) == 0:\n",
    "                continue\n",
    "\n",
    "            input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "            input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "            label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "            b_input_ids = input_id_tensors.to(device)\n",
    "            b_input_mask = input_mask_tensors.to(device)\n",
    "            b_labels = label_tensors.long().to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Accumulate gradients\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimizer step after accumulating gradients for gradient_accumulation_steps\n",
    "            if (i + 1) % gradient_accumulation_steps == 0 or i == num_batches - 1:  # Ensure step is taken on the last batch\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "        print(f\"Total loss: {total_train_loss}\")\n",
    "        report = get_validation_performance(val_set, model, device, label_dict, batch_size)\n",
    "        print(report)\n",
    "        analyze_generalization(model, val_set, tokenizer, train_sentences)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Training complete at learning rate: {lr}!\")\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    print(f\"mDeBERTa Model saved at: {timestamp}\")\n",
    "    torch.save(model.state_dict(), f'mdebertamodel_lr-{lr}_{timestamp}.pth')\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a97d7bc8-61b0-4cda-bd70-309d7b57b5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load state_dict of the model\n",
    "model.load_state_dict(torch.load(f'models/BERT_model_lr-7e-05_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e7b47ed-5523-4097-b121-ed3156040f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      " B-coreference     0.8250    0.3000    0.4400       550\n",
      " B-effect_size     0.4949    0.1531    0.2339       320\n",
      "B-intervention     0.6344    0.3797    0.4751      1330\n",
      "     B-outcome     0.5298    0.3161    0.3959      1718\n",
      "  B-population     0.5601    0.3802    0.4529      1018\n",
      " I-coreference     0.0000    0.0000    0.0000        22\n",
      " I-effect_size     0.6333    0.1971    0.3006       482\n",
      "I-intervention     0.7436    0.5054    0.6018      2663\n",
      "     I-outcome     0.7502    0.3675    0.4934      3235\n",
      "  I-population     0.8009    0.4132    0.5452      1227\n",
      "             O     0.0000    0.0000    0.0000         0\n",
      "\n",
      "      accuracy                         0.3809     12565\n",
      "     macro avg     0.5429    0.2738    0.3581     12565\n",
      "  weighted avg     0.6869    0.3809    0.4857     12565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_validation_performance(test_set, model, device, label_dict, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "182b32c6-b772-4fbf-ab3d-26186ae685db",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Length 3 - Unseen, Metrics: {'EM': 1, 'EB': 4, 'PM': 100, 'PB': 171, 'ML': 12, 'FA': 12}\n",
      "Group: Length 4 - Unseen, Metrics: {'EM': 7, 'EB': 0, 'PM': 58, 'PB': 95, 'ML': 10, 'FA': 10}\n",
      "Group: Length 0 - Unseen, Metrics: {'EM': 107, 'EB': 253, 'PM': 82, 'PB': 1059, 'ML': 72, 'FA': 72}\n",
      "Group: Length 2 - Unseen, Metrics: {'EM': 8, 'EB': 11, 'PM': 138, 'PB': 287, 'ML': 25, 'FA': 25}\n",
      "Group: Length 1 - Unseen, Metrics: {'EM': 41, 'EB': 40, 'PM': 323, 'PB': 609, 'ML': 33, 'FA': 33}\n",
      "Group: Length 5 - Unseen, Metrics: {'EM': 3, 'EB': 2, 'PM': 55, 'PB': 60, 'ML': 6, 'FA': 6}\n",
      "Group: Length 9 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 8, 'PB': 10, 'ML': 6, 'FA': 6}\n",
      "Group: Length 7 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 19, 'PB': 24, 'ML': 3, 'FA': 3}\n",
      "Group: Length 10 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 6, 'PB': 6, 'ML': 3, 'FA': 3}\n",
      "Group: Length 8 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 22, 'PB': 20, 'ML': 5, 'FA': 5}\n",
      "Group: Length 11 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 2, 'ML': 3, 'FA': 3}\n",
      "Group: Length 6 - Unseen, Metrics: {'EM': 1, 'EB': 0, 'PM': 31, 'PB': 60, 'ML': 7, 'FA': 7}\n",
      "Group: Length 12 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 1, 'FA': 1}\n",
      "Group: Length 13 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 1, 'ML': 1, 'FA': 1}\n",
      "Group: Length 16 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 1, 'ML': 1, 'FA': 1}\n",
      "Group: Length 17 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 1, 'ML': 0, 'FA': 0}\n",
      "Group: Length 18 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 32 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 14 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 0, 'ML': 0, 'FA': 0}\n",
      "Group: Length 19 - Unseen, Metrics: {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}\n"
     ]
    }
   ],
   "source": [
    "bert_lengths, bert_metrics = analyze_generalization(model, test_set, tokenizer, train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64d9d97a-92c2-4962-8977-92147cd93d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Length 3 - Unseen',\n",
       " 'Length 4 - Unseen',\n",
       " 'Length 0 - Unseen',\n",
       " 'Length 2 - Unseen',\n",
       " 'Length 1 - Unseen',\n",
       " 'Length 5 - Unseen',\n",
       " 'Length 9 - Unseen',\n",
       " 'Length 7 - Unseen',\n",
       " 'Length 10 - Unseen',\n",
       " 'Length 8 - Unseen',\n",
       " 'Length 11 - Unseen',\n",
       " 'Length 6 - Unseen',\n",
       " 'Length 12 - Unseen',\n",
       " 'Length 13 - Unseen',\n",
       " 'Length 16 - Unseen',\n",
       " 'Length 17 - Unseen',\n",
       " 'Length 18 - Unseen',\n",
       " 'Length 32 - Unseen',\n",
       " 'Length 14 - Unseen',\n",
       " 'Length 19 - Unseen']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a977c78a-c648-4607-b827-d0a01d303d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'EM': 1, 'EB': 4, 'PM': 100, 'PB': 171, 'ML': 12, 'FA': 12},\n",
       " {'EM': 7, 'EB': 0, 'PM': 58, 'PB': 95, 'ML': 10, 'FA': 10},\n",
       " {'EM': 107, 'EB': 253, 'PM': 82, 'PB': 1059, 'ML': 72, 'FA': 72},\n",
       " {'EM': 8, 'EB': 11, 'PM': 138, 'PB': 287, 'ML': 25, 'FA': 25},\n",
       " {'EM': 41, 'EB': 40, 'PM': 323, 'PB': 609, 'ML': 33, 'FA': 33},\n",
       " {'EM': 3, 'EB': 2, 'PM': 55, 'PB': 60, 'ML': 6, 'FA': 6},\n",
       " {'EM': 1, 'EB': 0, 'PM': 8, 'PB': 10, 'ML': 6, 'FA': 6},\n",
       " {'EM': 1, 'EB': 0, 'PM': 19, 'PB': 24, 'ML': 3, 'FA': 3},\n",
       " {'EM': 0, 'EB': 0, 'PM': 6, 'PB': 6, 'ML': 3, 'FA': 3},\n",
       " {'EM': 1, 'EB': 0, 'PM': 22, 'PB': 20, 'ML': 5, 'FA': 5},\n",
       " {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 2, 'ML': 3, 'FA': 3},\n",
       " {'EM': 1, 'EB': 0, 'PM': 31, 'PB': 60, 'ML': 7, 'FA': 7},\n",
       " {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 1, 'FA': 1},\n",
       " {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 1, 'ML': 1, 'FA': 1},\n",
       " {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 1, 'ML': 1, 'FA': 1},\n",
       " {'EM': 0, 'EB': 0, 'PM': 0, 'PB': 1, 'ML': 0, 'FA': 0},\n",
       " {'EM': 0, 'EB': 0, 'PM': 3, 'PB': 0, 'ML': 0, 'FA': 0},\n",
       " {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0},\n",
       " {'EM': 0, 'EB': 0, 'PM': 2, 'PB': 0, 'ML': 0, 'FA': 0},\n",
       " {'EM': 0, 'EB': 0, 'PM': 1, 'PB': 0, 'ML': 0, 'FA': 0}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f50e605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be7fa71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract sequence lengths and sort data by sequence length\n",
    "sequence_lengths = [int(s.split()[1]) for s in bert_lengths]\n",
    "sorted_indices = sorted(range(len(sequence_lengths)), key=lambda x: sequence_lengths[x])\n",
    "sequence_lengths = [sequence_lengths[i] for i in sorted_indices]\n",
    "\n",
    "# Calculate proportions for each metric\n",
    "metrics_keys = ['EM', 'EB', 'PM', 'PB', 'ML', 'FA']  # Add other metric keys if needed\n",
    "proportions = {key: [] for key in metrics_keys}\n",
    "\n",
    "for key in metrics_keys:\n",
    "    metric_values = [bert_metrics[i][key] for i in sorted_indices]\n",
    "    metric_total = sum(metric_values)\n",
    "    proportions[key] = [value / metric_total for value in metric_values]\n",
    "\n",
    "# Plot each metric using stacked bar graphs for the first 15 sequence lengths\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  # Adjust the figure size as needed\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "indices = range(len(sequence_lengths[:15]))\n",
    "\n",
    "# Initialize the bottom for the stack\n",
    "bottom = [0] * 15\n",
    "\n",
    "for key in metrics_keys:\n",
    "    ax.bar(indices, proportions[key][:15], bottom=bottom, label=key)\n",
    "    # Update the bottom position for the next metric\n",
    "    bottom = [bottom[i] + proportions[key][i] for i in range(15)]\n",
    "\n",
    "# Labeling\n",
    "ax.set_xlabel('Entity Length')\n",
    "ax.set_ylabel('Proportion of Entities')\n",
    "ax.set_title('Proportion of Entities by Sequence Length (First 15)')\n",
    "ax.set_xticks(indices)\n",
    "ax.set_xticklabels(sequence_lengths[:15])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f5649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177246f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcff725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ff82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005449a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb60fd7-9d27-4fbc-bcd8-03135bf9aa3c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting checklist\n",
      "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from checklist) (1.22.3)\n",
      "Requirement already satisfied: spacy>=2.2 in /home/apathak2/.local/lib/python3.9/site-packages (from checklist) (3.3.3)\n",
      "Collecting munch>=2.5 (from checklist)\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: dill>=0.3.1 in /home/apathak2/.local/lib/python3.9/site-packages (from checklist) (0.3.6)\n",
      "Requirement already satisfied: jupyter>=1.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from checklist) (1.0.0)\n",
      "Requirement already satisfied: ipywidgets>=7.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from checklist) (7.7.0)\n",
      "Requirement already satisfied: transformers>=2.8 in /home/apathak2/.local/lib/python3.9/site-packages (from checklist) (4.39.3)\n",
      "Collecting patternfork-nosql (from checklist)\n",
      "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting iso-639 (from checklist)\n",
      "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (6.9.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/apathak2/.local/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (5.14.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (5.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (3.6.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (8.1.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipywidgets>=7.5->checklist) (1.1.0)\n",
      "Requirement already satisfied: notebook in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter>=1.0->checklist) (6.4.10)\n",
      "Requirement already satisfied: qtconsole in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter>=1.0->checklist) (5.2.2)\n",
      "Requirement already satisfied: jupyter-console in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter>=1.0->checklist) (6.4.3)\n",
      "Requirement already satisfied: nbconvert in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter>=1.0->checklist) (6.4.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (8.0.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (0.7.11)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (2.0.10)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (0.4.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (61.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from spacy>=2.2->checklist) (21.3)\n",
      "Collecting typing-extensions<4.6.0,>=3.7.4.1 (from spacy>=2.2->checklist)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/apathak2/.local/lib/python3.9/site-packages (from spacy>=2.2->checklist) (3.3.0)\n",
      "Requirement already satisfied: filelock in /home/apathak2/.local/lib/python3.9/site-packages (from transformers>=2.8->checklist) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers>=2.8->checklist) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers>=2.8->checklist) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from transformers>=2.8->checklist) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers>=2.8->checklist) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/apathak2/.local/lib/python3.9/site-packages (from transformers>=2.8->checklist) (0.4.2)\n",
      "Collecting future (from patternfork-nosql->checklist)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting backports.csv (from patternfork-nosql->checklist)\n",
      "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from patternfork-nosql->checklist) (4.10.0)\n",
      "Requirement already satisfied: lxml in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from patternfork-nosql->checklist) (5.1.0)\n",
      "Collecting feedparser (from patternfork-nosql->checklist)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pdfminer.six (from patternfork-nosql->checklist)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: scipy in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from patternfork-nosql->checklist) (1.9.1)\n",
      "Requirement already satisfied: nltk in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from patternfork-nosql->checklist) (3.6.7)\n",
      "Collecting python-docx (from patternfork-nosql->checklist)\n",
      "  Downloading python_docx-1.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting cherrypy (from patternfork-nosql->checklist)\n",
      "  Downloading CherryPy-18.9.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/apathak2/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=2.8->checklist) (2024.3.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (1.6.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (7.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (0.1.3)\n",
      "Requirement already satisfied: psutil in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (5.9.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (1.5.4)\n",
      "Requirement already satisfied: backcall in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (3.0.28)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.8.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist) (4.9.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from packaging>=20.0->spacy>=2.2->checklist) (3.0.7)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /home/apathak2/.local/lib/python3.9/site-packages (from pathy>=0.3.5->spacy>=2.2->checklist) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/apathak2/.local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2021.10.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy>=2.2->checklist) (8.0.4)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (22.3.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (0.13.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from notebook->jupyter>=1.0->checklist) (0.13.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.4)\n",
      "Requirement already satisfied: bleach in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nbconvert->jupyter>=1.0->checklist) (0.5.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jinja2->spacy>=2.2->checklist) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from beautifulsoup4->patternfork-nosql->checklist) (2.3.1)\n",
      "Collecting cheroot>=8.2.1 (from cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading cheroot-10.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting portend>=2.1.1 (from cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading portend-3.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: more-itertools in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from cherrypy->patternfork-nosql->checklist) (8.12.0)\n",
      "Collecting zc.lockfile (from cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting jaraco.collections (from cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading jaraco.collections-5.0.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting sgmllib3k (from feedparser->patternfork-nosql->checklist)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from nltk->patternfork-nosql->checklist) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from pdfminer.six->patternfork-nosql->checklist) (36.0.2)\n",
      "Requirement already satisfied: qtpy in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from qtconsole->jupyter>=1.0->checklist) (2.0.1)\n",
      "Collecting jaraco.functools (from cheroot>=8.2.1->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading jaraco.functools-4.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (1.15.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist) (0.18.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (2.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.0)\n",
      "Collecting tempora>=1.8 (from portend>=2.1.1->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading tempora-5.5.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: wcwidth in /home/apathak2/.local/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.13)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from argon2-cffi->notebook->jupyter>=1.0->checklist) (21.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from bleach->nbconvert->jupyter>=1.0->checklist) (0.5.1)\n",
      "Collecting jaraco.text (from jaraco.collections->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading jaraco.text-3.12.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: executing in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5->checklist) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (2.21)\n",
      "Requirement already satisfied: pytz in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (2019.3)\n",
      "Collecting jaraco.context>=4.1 (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading jaraco.context-5.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting autocommand (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading autocommand-2.2.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting inflect (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading inflect-7.2.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting backports.tarfile (from jaraco.context>=4.1->jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading backports.tarfile-1.1.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting typeguard>=4.0.1 (from inflect->jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading typeguard-4.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /home/apathak2/.local/lib/python3.9/site-packages (from typeguard>=4.0.1->inflect->jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (4.13.0)\n",
      "INFO: pip is looking at multiple versions of typeguard to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading typeguard-4.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading typeguard-4.1.5-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading typeguard-4.1.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading typeguard-4.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading typeguard-4.1.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading typeguard-4.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading typeguard-4.1.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "INFO: pip is still looking at multiple versions of typeguard to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading typeguard-4.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting inflect (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist)\n",
      "  Downloading inflect-7.2.0-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading inflect-7.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is looking at multiple versions of inflect to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading inflect-6.2.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading inflect-6.1.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading inflect-6.1.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading inflect-6.0.5-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading inflect-6.0.4-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading inflect-6.0.3-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading inflect-6.0.2-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is still looking at multiple versions of inflect to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading inflect-6.0.1-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
      "Downloading CherryPy-18.9.0-py3-none-any.whl (348 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m348.8/348.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cheroot-10.0.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portend-3.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading jaraco.collections-5.0.1-py3-none-any.whl (10 kB)\n",
      "Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
      "Downloading tempora-5.5.1-py3-none-any.whl (13 kB)\n",
      "Downloading jaraco.functools-4.0.1-py3-none-any.whl (9.8 kB)\n",
      "Downloading jaraco.text-3.12.0-py3-none-any.whl (11 kB)\n",
      "Downloading jaraco.context-5.3.0-py3-none-any.whl (6.5 kB)\n",
      "Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading inflect-6.0.1-py3-none-any.whl (34 kB)\n",
      "Downloading backports.tarfile-1.1.1-py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: checklist, iso-639, patternfork-nosql, sgmllib3k\n",
      "  Building wheel for checklist (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165635 sha256=525f10c47a59733a6a4a7ddb890568813833675bb8de77d72569c3ff4679e014\n",
      "  Stored in directory: /home/apathak2/.cache/pip/wheels/70/48/f4/983e6cfe66fed9979451c546178d6d6f92ba1d6dc5e6add3e4\n",
      "  Building wheel for iso-639 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=168855 sha256=ddaf6948c1dba661ce10b605a33c3ac83cf65cfd3a087f52780023448035c1b5\n",
      "  Stored in directory: /home/apathak2/.cache/pip/wheels/43/3f/de/07f35ac2a2cd11ff30224e3fc6fbf458d7fc95effb1f673431\n",
      "  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332804 sha256=3011bf1c5e8ac87d472dc07e10c4231dc3ee52ba9841852098876a81401abec4\n",
      "  Stored in directory: /home/apathak2/.cache/pip/wheels/b4/f8/c1/165dbb1ce03c55f2a5c7e075ef9c1c6ff71b3620fb4dbcda38\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=a3e4929dd701bab5089f650b3006c2067f662ab1f861a01eef15fc5c22fc9c0a\n",
      "  Stored in directory: /home/apathak2/.cache/pip/wheels/65/7a/a7/78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
      "Successfully built checklist iso-639 patternfork-nosql sgmllib3k\n",
      "Installing collected packages: sgmllib3k, iso-639, backports.csv, zc.lockfile, typing-extensions, munch, jaraco.functools, future, feedparser, backports.tarfile, autocommand, tempora, python-docx, jaraco.context, cheroot, portend, pdfminer.six, inflect, jaraco.text, jaraco.collections, cherrypy, patternfork-nosql, checklist\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/home/apathak2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script calc-prorate is installed in '/home/apathak2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script cheroot is installed in '/home/apathak2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script cherryd is installed in '/home/apathak2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.2.2 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "label-studio 1.4.1.post1 requires google-api-core==1.31.5, but you have google-api-core 2.18.0 which is incompatible.\n",
      "label-studio 1.4.1.post1 requires google-auth==1.35.0, but you have google-auth 2.29.0 which is incompatible.\n",
      "label-studio 1.4.1.post1 requires google-cloud-core==1.5.0, but you have google-cloud-core 2.4.1 which is incompatible.\n",
      "label-studio 1.4.1.post1 requires google-cloud-storage~=1.29.0, but you have google-cloud-storage 2.16.0 which is incompatible.\n",
      "label-studio 1.4.1.post1 requires google-resumable-media==0.5.1, but you have google-resumable-media 2.7.0 which is incompatible.\n",
      "label-studio 1.4.1.post1 requires googleapis-common-protos==1.52.0, but you have googleapis-common-protos 1.63.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed autocommand-2.2.2 backports.csv-1.0.7 backports.tarfile-1.1.1 checklist-0.0.11 cheroot-10.0.1 cherrypy-18.9.0 feedparser-6.0.11 future-1.0.0 inflect-6.0.1 iso-639-0.4.5 jaraco.collections-5.0.1 jaraco.context-5.3.0 jaraco.functools-4.0.1 jaraco.text-3.12.0 munch-4.0.0 patternfork-nosql-3.6 pdfminer.six-20231228 portend-3.2.0 python-docx-1.1.0 sgmllib3k-1.0.0 tempora-5.5.1 typing-extensions-4.5.0 zc.lockfile-3.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1504dcdf-ce60-4cd2-968f-80aac642aede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/apathak2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "407ec42d-2a8e-4032-9258-e2882fa3d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d284ea11-3d4b-471c-96c1-3f56e06611b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(df):\n",
    "    # Assuming df has columns 'sentences' and 'labels'\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['sentences']\n",
    "        labels = row['labels']\n",
    "        words = sentence.split()\n",
    "\n",
    "        for i, (word, label) in enumerate(zip(words, labels)):\n",
    "            if label.startswith('B-'):\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                current_entity = {'type': label[2:], 'start_idx': i, 'end_idx': i, 'text': word}\n",
    "            elif label.startswith('I-') and current_entity and label[2:] == current_entity['type']:\n",
    "                current_entity['end_idx'] = i\n",
    "                current_entity['text'] += ' ' + word\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "\n",
    "        if current_entity:\n",
    "            entities.append(current_entity)\n",
    "            current_entity = None\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b4058c6-47a1-4a37-8e76-d0e256960791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15872\n"
     ]
    }
   ],
   "source": [
    "entities = extract_entities(train_df)\n",
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d86ecbfe-0501-4fd9-b2c8-f0a65627e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for populations\n",
    "population_templates = (\n",
    "    'The study focused on {population}.',\n",
    "    'Results were most significant among {population}.',\n",
    "    'The impact on {population} was noteworthy.',\n",
    "    'Interventions were targeted towards {population}.',\n",
    "    'Data was collected from various {population}.',\n",
    "    'The {population} showed a remarkable response.',\n",
    "    'Surveys were conducted across different {population}.',\n",
    "    'The {population} was observed for changes.',\n",
    "    'A significant change was recorded in the {population}.',\n",
    "    'The research aimed to benefit the {population}.'\n",
    ")\n",
    "\n",
    "# Define custom population entity\n",
    "populations = [entity['text'] for entity in entities if entity['type']=='population']\n",
    "\n",
    "# Use the editor to create examples\n",
    "population_test_cases = editor.template(\n",
    "    population_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    population=populations\n",
    ")\n",
    "    \n",
    "def found_population(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'population' is the only entity type present in the prediction\n",
    "    expected_population = meta['population']\n",
    "    return all(label == 'O' or label.endswith('population') for label in pred)\n",
    "\n",
    "found_population_expect_fn = Expect.single(found_population)\n",
    "\n",
    "# A simple MFT test\n",
    "found_population_test = MFT(\n",
    "    **population_test_cases,\n",
    "    name='Test for correct population recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label populations.',\n",
    "    expect=found_population_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a2bd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for interventions\n",
    "intervention_templates = (\n",
    "    \"The {intervention} was implemented to address the issue.\",\n",
    "    \"Researchers studied the effects of the {intervention}.\",\n",
    "    \"The {intervention} had a significant impact on the community.\",\n",
    "    \"Funding was provided for the {intervention}.\",\n",
    "    \"The success of the {intervention} was evident in the results.\",\n",
    "    \"Participants were selected for the {intervention} group.\",\n",
    "    \"The {intervention} was a key part of the strategy.\",\n",
    "    \"The {intervention} targeted specific outcomes.\",\n",
    "    \"Outcomes were measured after the {intervention} took place.\",\n",
    "    \"The {intervention} was designed to improve overall outcomes.\"\n",
    ")\n",
    "\n",
    "# Define custom intervention entity\n",
    "interventions = [entity['text'] for entity in entities if entity['type']=='intervention']\n",
    "\n",
    "# Use the editor to create examples\n",
    "intervention_test_cases = editor.template(\n",
    "    intervention_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    intervention=interventions\n",
    ")\n",
    "\n",
    "def found_intervention(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'intervention' is the only entity type present in the prediction\n",
    "    expected_intervention = meta['intervention']\n",
    "    return all(label == 'O' or label.endswith('intervention') for label in pred)\n",
    "\n",
    "found_intervention_expect_fn = Expect.single(found_intervention)    \n",
    "\n",
    "# A simple MFT test\n",
    "found_intervention_test = MFT(\n",
    "    **intervention_test_cases,\n",
    "    name='Test for correct intervention recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label interventions.',\n",
    "    expect=found_intervention_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92242b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for outcomes\n",
    "outcome_templates = (\n",
    "    \"The outcome of the study was {outcome}.\",\n",
    "    \"It was observed that the primary outcome was {outcome}.\",\n",
    "    \"The expected outcome was {outcome}, which was surprising.\",\n",
    "    \"As a result, the outcome was {outcome}.\",\n",
    "    \"The final outcome, {outcome}, was recorded after the experiment.\",\n",
    "    \"The result of the intervention was {outcome}.\",\n",
    "    \"The project led to {outcome}.\",\n",
    "    \"The consequences were observed as {outcome}.\",\n",
    "    \"The end effect was {outcome}.\",\n",
    "    \"The study concluded with {outcome}.\"\n",
    ")\n",
    "\n",
    "# Define custom outcome entity\n",
    "outcomes = [entity['text'] for entity in entities if entity['type']=='outcome']\n",
    "\n",
    "# Use the editor to create examples\n",
    "outcome_test_cases = editor.template(\n",
    "    outcome_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    outcome=outcomes\n",
    ")\n",
    "\n",
    "def found_outcome(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'outcome' is the only entity type present in the prediction\n",
    "    expected_outcome = meta['outcome']\n",
    "    return all(label == 'O' or label.endswith('outcome') for label in pred)\n",
    "\n",
    "found_outcome_expect_fn = Expect.single(found_outcome)    \n",
    "\n",
    "# A simple MFT test\n",
    "found_outcome_test = MFT(\n",
    "    **outcome_test_cases,\n",
    "    name='Test for correct outcome recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label outcomes.',\n",
    "    expect=found_outcome_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "86f67a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for effect_sizes\n",
    "effect_size_templates = (\n",
    "    \"The observed change was {effect_size}.\",\n",
    "    \"A {effect_size} increase was noted in the study.\",\n",
    "    \"The results showed a {effect_size} decrease.\",\n",
    "    \"There was a {effect_size} improvement over the baseline.\",\n",
    "    \"The effect was quantified as {effect_size}.\",\n",
    "    \"The magnitude of impact measured {effect_size}.\",\n",
    "    \"The statistical significance reached {effect_size}.\",\n",
    "    \"A {effect_size} reduction in errors was achieved.\",\n",
    "    \"The intervention led to a {effect_size} enhancement.\",\n",
    "    \"The data indicated a {effect_size} growth rate.\"\n",
    ")\n",
    "\n",
    "# Define custom effect_size entity\n",
    "effect_sizes = [entity['text'] for entity in entities if entity['type']=='effect_size']\n",
    "\n",
    "# Use the editor to create examples\n",
    "effect_size_test_cases = editor.template(\n",
    "    effect_size_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    effect_size=effect_sizes\n",
    ")\n",
    "\n",
    "def found_effect_size(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'effect_size' is the only entity type present in the prediction\n",
    "    expected_effect_size = meta['effect_size']\n",
    "    return all(label == 'O' or label.endswith('effect_size') for label in pred)\n",
    "\n",
    "found_effect_size_expect_fn = Expect.single(found_effect_size)    \n",
    "\n",
    "# A simple MFT test\n",
    "found_effect_size_test = MFT(\n",
    "    **effect_size_test_cases,\n",
    "    name='Test for correct effect-size recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label effect-size.',\n",
    "    expect=found_effect_size_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3c4a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates with placeholders for coreferences\n",
    "coreference_templates = (\n",
    "    \"This refers to the {coreference}.\",\n",
    "    \"Such instances of {coreference} were noted.\",\n",
    "    \"As mentioned earlier, the {coreference} plays a crucial role.\",\n",
    "    \"This is similar to the {coreference} discussed before.\",\n",
    "    \"The case of {coreference} is particularly interesting.\",\n",
    "    \"In light of the {coreference}, further analysis is required.\",\n",
    "    \"This aligns with the {coreference} we observed.\",\n",
    "    \"The {coreference} under discussion was pivotal.\",\n",
    "    \"Reflecting on the {coreference}, it becomes clear.\",\n",
    "    \"Given the {coreference}, the results are unsurprising.\"\n",
    ")\n",
    "\n",
    "# Define custom coreference entity\n",
    "coreferences = [entity['text'] for entity in entities if entity['type']=='coreference']\n",
    "\n",
    "# Use the editor to create examples\n",
    "coreference_test_cases = editor.template(\n",
    "    coreference_templates, \n",
    "    meta=True,\n",
    "    remove_duplicates=True,\n",
    "    coreference=coreferences\n",
    ")\n",
    "\n",
    "def found_coreference(x, pred, conf, label=None, meta=None):\n",
    "    # Check if 'coreference' is the only entity type present in the prediction\n",
    "    expected_coreference = meta['coreference']\n",
    "    return all(label == 'O' or label.endswith('coreference') for label in pred)\n",
    "\n",
    "found_coreference_expect_fn = Expect.single(found_coreference)    \n",
    "\n",
    "# A simple MFT test\n",
    "found_coreference_test = MFT(\n",
    "    **coreference_test_cases,\n",
    "    name='Test for correct coreference recognition',\n",
    "    capability='NER',\n",
    "    description='The model should correctly identify and label coreference.',\n",
    "    expect=found_coreference_expect_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc7a0c01-db20-488d-81c5-245df3e92451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define an INV test that adds typos to the sentence\n",
    "# Inv = INV(\n",
    "#     name='Test for robustness to typos',\n",
    "#     capability='Robustness',\n",
    "#     description='The model should be robust to typos in the input.',\n",
    "#     data=Perturb.perturb(['The government implemented a new intervention to boost economic growth.'], Perturb.add_typos).data,\n",
    "#     expect=expect_fn\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a9a4370-6932-4568-b084-33f5af6dc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a DIR test that negates the sentence\n",
    "# Dir = DIR(\n",
    "#     name='Test for sensitivity to negations',\n",
    "#     capability='Negation',\n",
    "#     description='The model should change predictions when negations are added.',\n",
    "#     data=[('The government implemented a new intervention to boost economic growth.', 'The government did not implement a new intervention to boost economic growth.', {'entities': ['B-intervention', 'I-intervention', 'O', 'O', 'O', 'O', 'B-outcome'], 'negated_entities': ['O']*7} )],\n",
    "#     expect=expect_fn\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2390849-083e-43e2-88c5-13f5fa40a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite\n",
    "\n",
    "suite = TestSuite()\n",
    "suite.add(found_population_test)\n",
    "suite.add(found_intervention_test)\n",
    "suite.add(found_outcome_test)\n",
    "suite.add(found_effect_size_test)\n",
    "suite.add(found_coreference_test)\n",
    "# suite.add(Inv)\n",
    "# suite.add(Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6318e-92b0-4d47-8006-9ef58aeb8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_name\n",
    "lr = learning_rates[0]\n",
    "\n",
    "# Load state_dict of the model\n",
    "model.load_state_dict(torch.load(f'models/EconBERTa_model_lr-7e-05_best.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "18293093-1672-4764-9d2d-2b13eeeb17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(texts):\n",
    "    # Extract just the sentences from the input tuples\n",
    "    sentences = [text[0] for text in texts]\n",
    "    \n",
    "    # Convert texts to input IDs and attention masks using the tokenizer\n",
    "    input_ids, attention_mask = tokenize_and_format(sentences, tokenizer, max_length)\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    # Use the model to get the logits\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Decode the outputs using the CRF layer\n",
    "    decoded_labels = outputs['decoded']\n",
    "    \n",
    "    # Convert label indices to label names\n",
    "    pred_labels = [[reverse_label_dict[label] for label in sentence_labels] for sentence_labels in decoded_labels]\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "718cb8f7-20b7-486d-873e-aaabb5f7095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "predict_and_conf = PredictorWrapper.wrap_predict(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "566c16d7-015e-44e6-80f5-e2785dbed488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test for correct population recognition\n",
      "Predicting 3205 examples\n",
      "Running Test for correct intervention recognition\n",
      "Predicting 4120 examples\n",
      "Running Test for correct outcome recognition\n",
      "Predicting 5870 examples\n",
      "Running Test for correct effect-size recognition\n",
      "Predicting 965 examples\n",
      "Running Test for correct coreference recognition\n",
      "Predicting 1712 examples\n"
     ]
    }
   ],
   "source": [
    "# Run the test suite\n",
    "suite.run(predict_and_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "c377b627",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER\n",
      "\n",
      "Test for correct population recognition\n",
      "Test cases:      3205\n",
      "Fails (rate):    241 (7.5%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'O', 'O', 'O', 'B-intervention', 'I-intervention', 'O', 'O', 'O'] ('The study focused on household contacts.', 'Results were most significant among household contacts.', 'The impact on household contacts was noteworthy.', 'Interventions were targeted towards household contacts.', 'Data was collected from various household contacts.', 'The household contacts showed a remarkable response.', 'Surveys were conducted across different household contacts.', 'The household contacts was observed for changes.', 'A significant change was recorded in the household contacts.', 'The research aimed to benefit the household contacts.')\n",
      "\n",
      "----\n",
      "['O', 'O', 'O', 'O', 'B-population', 'O', 'B-intervention', 'I-intervention', 'I-intervention', 'B-intervention', 'I-intervention', 'I-intervention', 'I-intervention', 'I-intervention', 'I-intervention', 'O', 'O', 'B-intervention', 'I-intervention', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] ('The study focused on schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ).', 'Results were most significant among schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ).', 'The impact on schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ) was noteworthy.', 'Interventions were targeted towards schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ).', 'Data was collected from various schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ).', 'The schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ) showed a remarkable response.', 'Surveys were conducted across different schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ).', 'The schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ) was observed for changes.', 'A significant change was recorded in the schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ).', 'The research aimed to benefit the schools ( government run , on - site sanitation and water , no hygiene interventions in last year , fewer than 450 students ).')\n",
      "\n",
      "----\n",
      "['O', 'O', 'O', 'O', 'B-intervention', 'I-intervention', 'O', 'O', 'O'] ('The study focused on Extension agents.', 'Results were most significant among Extension agents.', 'The impact on Extension agents was noteworthy.', 'Interventions were targeted towards Extension agents.', 'Data was collected from various Extension agents.', 'The Extension agents showed a remarkable response.', 'Surveys were conducted across different Extension agents.', 'The Extension agents was observed for changes.', 'A significant change was recorded in the Extension agents.', 'The research aimed to benefit the Extension agents.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct intervention recognition\n",
      "Test cases:      4120\n",
      "Fails (rate):    293 (7.1%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'B-intervention', 'I-intervention', 'I-intervention', 'B-population', 'I-intervention', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] ('The bringing education to the poor was implemented to address the issue.', 'Researchers studied the effects of the bringing education to the poor.', 'The bringing education to the poor had a significant impact on the community.', 'Funding was provided for the bringing education to the poor.', 'The success of the bringing education to the poor was evident in the results.', 'Participants were selected for the bringing education to the poor group.', 'The bringing education to the poor was a key part of the strategy.', 'The bringing education to the poor targeted specific outcomes.', 'Outcomes were measured after the bringing education to the poor took place.', 'The bringing education to the poor was designed to improve overall outcomes.')\n",
      "\n",
      "----\n",
      "['O', 'B-coreference', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] ('The grants was implemented to address the issue.', 'Researchers studied the effects of the grants.', 'The grants had a significant impact on the community.', 'Funding was provided for the grants.', 'The success of the grants was evident in the results.', 'Participants were selected for the grants group.', 'The grants was a key part of the strategy.', 'The grants targeted specific outcomes.', 'Outcomes were measured after the grants took place.', 'The grants was designed to improve overall outcomes.')\n",
      "\n",
      "----\n",
      "['O', 'B-intervention', 'I-intervention', 'O', 'B-intervention', 'I-population', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] ('The hygiene promotion by government , school , and community leaders was implemented to address the issue.', 'Researchers studied the effects of the hygiene promotion by government , school , and community leaders.', 'The hygiene promotion by government , school , and community leaders had a significant impact on the community.', 'Funding was provided for the hygiene promotion by government , school , and community leaders.', 'The success of the hygiene promotion by government , school , and community leaders was evident in the results.', 'Participants were selected for the hygiene promotion by government , school , and community leaders group.', 'The hygiene promotion by government , school , and community leaders was a key part of the strategy.', 'The hygiene promotion by government , school , and community leaders targeted specific outcomes.', 'Outcomes were measured after the hygiene promotion by government , school , and community leaders took place.', 'The hygiene promotion by government , school , and community leaders was designed to improve overall outcomes.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct outcome recognition\n",
      "Test cases:      5870\n",
      "Fails (rate):    1001 (17.1%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-population', 'I-population', 'O', 'O', 'B-outcome', 'O', 'I-outcome', 'O', 'O', 'O', 'O', 'O', 'O'] ('The outcome of the study was school staff - perpetrated physical violence against students.', 'It was observed that the primary outcome was school staff - perpetrated physical violence against students.', 'The expected outcome was school staff - perpetrated physical violence against students, which was surprising.', 'As a result, the outcome was school staff - perpetrated physical violence against students.', 'The final outcome, school staff - perpetrated physical violence against students, was recorded after the experiment.', 'The result of the intervention was school staff - perpetrated physical violence against students.', 'The project led to school staff - perpetrated physical violence against students.', 'The consequences were observed as school staff - perpetrated physical violence against students.', 'The end effect was school staff - perpetrated physical violence against students.', 'The study concluded with school staff - perpetrated physical violence against students.')\n",
      "\n",
      "----\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-population', 'O', 'O', 'O'] ('The outcome of the study was satisfied with the police.', 'It was observed that the primary outcome was satisfied with the police.', 'The expected outcome was satisfied with the police, which was surprising.', 'As a result, the outcome was satisfied with the police.', 'The final outcome, satisfied with the police, was recorded after the experiment.', 'The result of the intervention was satisfied with the police.', 'The project led to satisfied with the police.', 'The consequences were observed as satisfied with the police.', 'The end effect was satisfied with the police.', 'The study concluded with satisfied with the police.')\n",
      "\n",
      "----\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-intervention', 'O', 'O', 'O', 'O'] ('The outcome of the study was SBP.', 'It was observed that the primary outcome was SBP.', 'The expected outcome was SBP, which was surprising.', 'As a result, the outcome was SBP.', 'The final outcome, SBP, was recorded after the experiment.', 'The result of the intervention was SBP.', 'The project led to SBP.', 'The consequences were observed as SBP.', 'The end effect was SBP.', 'The study concluded with SBP.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct effect-size recognition\n",
      "Test cases:      965\n",
      "Fails (rate):    107 (11.1%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'O', 'B-coreference', 'O', 'B-effect_size', 'I-effect_size', 'O', 'O', 'O'] ('The observed change was 38 %.', 'A 38 % increase was noted in the study.', 'The results showed a 38 % decrease.', 'There was a 38 % improvement over the baseline.', 'The effect was quantified as 38 %.', 'The magnitude of impact measured 38 %.', 'The statistical significance reached 38 %.', 'A 38 % reduction in errors was achieved.', 'The intervention led to a 38 % enhancement.', 'The data indicated a 38 % growth rate.')\n",
      "\n",
      "----\n",
      "['O', 'O', 'B-coreference', 'O', 'B-effect_size', 'I-effect_size', 'O', 'O', 'O'] ('The observed change was 33 %.', 'A 33 % increase was noted in the study.', 'The results showed a 33 % decrease.', 'There was a 33 % improvement over the baseline.', 'The effect was quantified as 33 %.', 'The magnitude of impact measured 33 %.', 'The statistical significance reached 33 %.', 'A 33 % reduction in errors was achieved.', 'The intervention led to a 33 % enhancement.', 'The data indicated a 33 % growth rate.')\n",
      "\n",
      "----\n",
      "['O', 'O', 'B-coreference', 'O', 'B-effect_size', 'O', 'O', 'O', 'O'] ('The observed change was 26 %.', 'A 26 % increase was noted in the study.', 'The results showed a 26 % decrease.', 'There was a 26 % improvement over the baseline.', 'The effect was quantified as 26 %.', 'The magnitude of impact measured 26 %.', 'The statistical significance reached 26 %.', 'A 26 % reduction in errors was achieved.', 'The intervention led to a 26 % enhancement.', 'The data indicated a 26 % growth rate.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Test for correct coreference recognition\n",
      "Test cases:      1712\n",
      "Fails (rate):    35 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "['O', 'O', 'O', 'O', 'B-intervention', 'O', 'O', 'O'] ('This refers to the behaviors.', 'Such instances of behaviors were noted.', 'As mentioned earlier, the behaviors plays a crucial role.', 'This is similar to the behaviors discussed before.', 'The case of behaviors is particularly interesting.', 'In light of the behaviors, further analysis is required.', 'This aligns with the behaviors we observed.', 'The behaviors under discussion was pivotal.', 'Reflecting on the behaviors, it becomes clear.', 'Given the behaviors, the results are unsurprising.')\n",
      "\n",
      "----\n",
      "['O', 'O', 'O', 'O', 'B-outcome', 'O', 'O', 'O'] ('This refers to the enrollment.', 'Such instances of enrollment were noted.', 'As mentioned earlier, the enrollment plays a crucial role.', 'This is similar to the enrollment discussed before.', 'The case of enrollment is particularly interesting.', 'In light of the enrollment, further analysis is required.', 'This aligns with the enrollment we observed.', 'The enrollment under discussion was pivotal.', 'Reflecting on the enrollment, it becomes clear.', 'Given the enrollment, the results are unsurprising.')\n",
      "\n",
      "----\n",
      "['O', 'O', 'O', 'O', 'O', 'B-coreference', 'O', 'B-intervention', 'O', 'O', 'O', 'O', 'O'] ('This refers to the both types of microcredit.', 'Such instances of both types of microcredit were noted.', 'As mentioned earlier, the both types of microcredit plays a crucial role.', 'This is similar to the both types of microcredit discussed before.', 'The case of both types of microcredit is particularly interesting.', 'In light of the both types of microcredit, further analysis is required.', 'This aligns with the both types of microcredit we observed.', 'The both types of microcredit under discussion was pivotal.', 'Reflecting on the both types of microcredit, it becomes clear.', 'Given the both types of microcredit, the results are unsurprising.')\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "145560d2-1713-4c5a-86b3-6c6b5ea0d7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d2781737ec4ded9547e4bf069733ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Test for correct pop"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12afd3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d3a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d36369356684e6aa06b7ada70e96ce0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11461a73263241bd8e2ad35a92e0c2dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "163bff609cfa453abc5879732e2220f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7343c5bf56714623a01c5594bb9a9aa0",
      "placeholder": "",
      "style": "IPY_MODEL_59cffec0648542bf98578314858763bb",
      "value": "tokenizer_config.json:100%"
     }
    },
    "1ad64543adeb474ebb9411511dde951a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb0b7eeec1814e6ab5a7e8c0c701105e",
      "max": 608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24a67c04e0824c1baed82a66396223b6",
      "value": 608
     }
    },
    "225124f7f60c49a4bc218b0299701752": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24a67c04e0824c1baed82a66396223b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e20ca46d0334a0ab3f2f2dc60a005ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31abb00576474a3b9a11ea0f06d41d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8cb3e628e0c64da392f635d25c68be6b",
       "IPY_MODEL_1ad64543adeb474ebb9411511dde951a",
       "IPY_MODEL_f2c1f53924a7409c816b01308ccb9336"
      ],
      "layout": "IPY_MODEL_2e20ca46d0334a0ab3f2f2dc60a005ca"
     }
    },
    "3ad2d7515dee4ca4ac5d8d2f335adb33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6eda298aaf44b9b914ef35a6a123531",
      "placeholder": "",
      "style": "IPY_MODEL_11461a73263241bd8e2ad35a92e0c2dc",
      "value": "2.46M/2.46M[00:00&lt;00:00,27.0MB/s]"
     }
    },
    "4a7b1395942142918447f45464dcd3ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56706f8aac024e13846308140c44006d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59721f7c8561408c8fea78b29ad6be3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87aeb22ec9164278b1f1e2b23b959299",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c5108fe496048d39e8a14345c5f5d65",
      "value": 52
     }
    },
    "59cffec0648542bf98578314858763bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c26711cce0d49d6a401b9b5c6823345": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1e82949a1042b1b831bd86137f1375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_163bff609cfa453abc5879732e2220f0",
       "IPY_MODEL_59721f7c8561408c8fea78b29ad6be3d",
       "IPY_MODEL_7f2924ef022647f48f1c7e7be7700402"
      ],
      "layout": "IPY_MODEL_fd07562db6144a71a9910d3e343eceae"
     }
    },
    "5e389d23cc6b4642b289e7d9f933c9cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c5108fe496048d39e8a14345c5f5d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e62eee804a54b298728d6f6a21b9f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7343c5bf56714623a01c5594bb9a9aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f2924ef022647f48f1c7e7be7700402": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d5aed0313247339c19e9c75d548396",
      "placeholder": "",
      "style": "IPY_MODEL_225124f7f60c49a4bc218b0299701752",
      "value": "52.0/52.0[00:00&lt;00:00,3.40kB/s]"
     }
    },
    "87aeb22ec9164278b1f1e2b23b959299": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a972e443ff9481d896cac5bca478664": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcea801bb91048a68bd1dfbefd8b0b93",
      "max": 2464616,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2ea734058bf4fc9a00cef248b73b9ab",
      "value": 2464616
     }
    },
    "8cb3e628e0c64da392f635d25c68be6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a7b1395942142918447f45464dcd3ce",
      "placeholder": "",
      "style": "IPY_MODEL_5e389d23cc6b4642b289e7d9f933c9cb",
      "value": "config.json:100%"
     }
    },
    "95e1a33c031e434bbd30fb0315ea8e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2c593b085534f8d8b148ab14be27b58",
       "IPY_MODEL_8a972e443ff9481d896cac5bca478664",
       "IPY_MODEL_3ad2d7515dee4ca4ac5d8d2f335adb33"
      ],
      "layout": "IPY_MODEL_0d36369356684e6aa06b7ada70e96ce0"
     }
    },
    "a4d5aed0313247339c19e9c75d548396": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb0b7eeec1814e6ab5a7e8c0c701105e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcea801bb91048a68bd1dfbefd8b0b93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e177f9d5aa7f4cd990ed6d81cff20cbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2ea734058bf4fc9a00cef248b73b9ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6eda298aaf44b9b914ef35a6a123531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2c1f53924a7409c816b01308ccb9336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e177f9d5aa7f4cd990ed6d81cff20cbf",
      "placeholder": "",
      "style": "IPY_MODEL_6e62eee804a54b298728d6f6a21b9f98",
      "value": "608/608[00:00&lt;00:00,39.3kB/s]"
     }
    },
    "f2c593b085534f8d8b148ab14be27b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c26711cce0d49d6a401b9b5c6823345",
      "placeholder": "",
      "style": "IPY_MODEL_56706f8aac024e13846308140c44006d",
      "value": "spm.model:100%"
     }
    },
    "fd07562db6144a71a9910d3e343eceae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
